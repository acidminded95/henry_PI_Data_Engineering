{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este notebook se exploran los datos de los archivos proporcionados y se tratan de encontrar las mejores soluciones para los problemas que presentan. Una vez obtenidas estas soluciones, se generará el scrip 'pipeline.py' donde todo el proceso quedará resumido y se podrá correr desde la terminal tanto en dispositivos windows como unix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos importando las librerías que usaremos para la preparación de los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import sqlite3 as db\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----EXTRACCIÓN-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El propósito de esta sección es importar los datasets de diferentes formatos contenidos en el directorio 'datasets' a DataFrames de pandas de manera automatizada, organizándolos en un diccionario para facilitar su acceso y limpieza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los DataFrames en pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precios_semanas_20200419_20200426.xlsx', 'precios_semana_20200413.csv', 'precios_semana_20200503.json', 'precios_semana_20200518.txt', 'precios_semana_20200618.txt', 'producto.parquet', 'sucursal.csv']\n",
      "win\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos una lista de los archivos dentro del directorio 'datasets'\n",
    "try:\n",
    "    file_names = listdir('.\\datasets')\n",
    "    os = \"win\"\n",
    "except FileNotFoundError:\n",
    "    file_names = listdir('./datasets')\n",
    "    os = \"unix\"\n",
    "\n",
    "print(file_names)\n",
    "print(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: precios_semanas_20200419_20200426.xlsx\n",
      "Value: ['precios_semanas_20200419_20200426', 'xlsx']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200413.csv\n",
      "Value: ['precios_semana_20200413', 'csv']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200503.json\n",
      "Value: ['precios_semana_20200503', 'json']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200518.txt\n",
      "Value: ['precios_semana_20200518', 'txt']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200618.txt\n",
      "Value: ['precios_semana_20200618', 'txt']\n",
      "\n",
      "\n",
      "Key: producto.parquet\n",
      "Value: ['producto', 'parquet']\n",
      "\n",
      "\n",
      "Key: sucursal.csv\n",
      "Value: ['sucursal', 'csv']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un diccionario con los nombres de cada archivo y su extensión\n",
    "datasets_extensions = {}\n",
    "for x in file_names:\n",
    "    datasets_extensions[x] = x.split('.')\n",
    "\n",
    "for x in datasets_extensions:\n",
    "    print(f'\\nKey: {x}\\nValue: {datasets_extensions[x]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos las extensiones y los nombres de los archivos para importar los datasets en objetos 'DataFrame' de pandas.\n",
    "\n",
    "Habiendo estudiado un poco la naturaleza de los datasets antes de importarlos, se pudo observar que los registros\n",
    "o *tablas de hecho* son las que llevan por nombre 'precios_...', mientras que las *dimensiones* son los datasets de \n",
    "'producto' y 'sucursal', pues proveen información adicional a las primeras tablas.\n",
    "\n",
    "Así, los datasets de precios serán organizados en el diccionario 'ps_2020' (precio semanal 2020) y los otros dos en el \n",
    "diccionario 'dims' (dimensiones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los diccionarios y automatizamos la importación de los archivos contenidos en el directorio 'datasets'\n",
    "ps_2020 = {}\n",
    "dims = {}\n",
    "for x in datasets_extensions:\n",
    "    if os == \"win\":\n",
    "        path = f'datasets/{x}'\n",
    "    elif os == \"unix\":\n",
    "        path = f'datasets/{x}'\n",
    "    if x[:7] == 'precios':\n",
    "        if datasets_extensions[x][1] in ['xlsx', 'xls']:\n",
    "            xl_dict = pd.read_excel(path, sheet_name=None, date_parser=None)\n",
    "            for sheet in xl_dict:\n",
    "                name = f'{sheet[-8:-4]}-{sheet[-4:-2]}-{sheet[-2:]}'\n",
    "                ps_2020[name] = pd.DataFrame(xl_dict[sheet])\n",
    "        else:\n",
    "            name = f'{datasets_extensions[x][0][-8:-4]}-{datasets_extensions[x][0][-4:-2]}-{datasets_extensions[x][0][-2:]}'\n",
    "            if datasets_extensions[x][1] == 'csv':\n",
    "                ps_2020[name] = pd.read_csv(path, encoding='UTF-16 LE')\n",
    "            elif datasets_extensions[x][1] == 'json':\n",
    "                ps_2020[name] = pd.read_json(path)\n",
    "            elif datasets_extensions[x][1] == 'txt':\n",
    "                ps_2020[name] = pd.read_csv(path, delimiter='|')\n",
    "    else:\n",
    "        name = datasets_extensions[x][0]\n",
    "        if datasets_extensions[x][1] == 'csv':\n",
    "            dims[name] = pd.read_csv(path)\n",
    "        elif datasets_extensions[x][1] == 'parquet':\n",
    "            dims[name] = pd.read_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame: 2020-04-26\n",
      "\tShape: (478909, 3)\n",
      "\tColumnas: Index(['precio', 'sucursal_id', 'producto_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-19\n",
      "\tShape: (458543, 3)\n",
      "\tColumnas: Index(['precio', 'sucursal_id', 'producto_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-13\n",
      "\tShape: (472166, 3)\n",
      "\tColumnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-03\n",
      "\tShape: (397734, 3)\n",
      "\tColumnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-18\n",
      "\tShape: (415293, 3)\n",
      "\tColumnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-06-18\n",
      "\tShape: (415293, 3)\n",
      "\tColumnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: producto\n",
      "\tShape: (72038, 7)\n",
      "\tColumnas: Index(['id', 'marca', 'nombre', 'presentacion', 'categoria1', 'categoria2',\n",
      "       'categoria3'],\n",
      "      dtype='object')\n",
      "\n",
      "• DataFrame: sucursal\n",
      "\tShape: (2333, 12)\n",
      "\tColumnas: Index(['id', 'comercioId', 'banderaId', 'banderaDescripcion',\n",
      "       'comercioRazonSocial', 'provincia', 'localidad', 'direccion', 'lat',\n",
      "       'lng', 'sucursalNombre', 'sucursalTipo'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ps_2020:\n",
    "    print(f'• DataFrame: {x}\\n\\tShape: {ps_2020[x].shape}\\n\\tColumnas: {ps_2020[x].columns}\\n')\n",
    "for x in dims:\n",
    "    print(f'• DataFrame: {x}\\n\\tShape: {dims[x].shape}\\n\\tColumnas: {dims[x].columns}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- TRANSFORMACIÓN -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de limpieza de datos\n",
    "Una vez creadas las tablas podemos empezar el trabajo de limpieza de los datos, comenzando por buscar los registros duplicados y valores faltantes.\n",
    "\n",
    "El propósito de esta sección es dejar los DataFrames listos para su carga en una base de datos SQL. Esto se logrará cumpliendo con 2 tareas:\n",
    "1) Dejar todas las columnas de las tablas de 'precios' con el mismo tipo de dato y mismo formato de registros en las diferentes tablas para poder concatenarlas después y subirlas a una base de datos SQL.\n",
    "2) Asegurarnos de que todos los valores de las columnas 'producto_id' y 'sucursal_id' puedan relacionarse a algún valor de las columnas 'id' en las dimensiones 'producto' y 'sucursal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------2020-04-26----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-04-19----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-04-13----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-05-03----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-05-18----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-06-18----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Organizamos las columnas de los dataframes para que coincidan entre sí y facilitar la visualización\n",
    "# Además agregamos la columna 'fecha' que nos permitirá distinguir a qué dataset pertenece cada registro una vez sean concatenados\n",
    "cols = ['precio', 'producto_id', 'sucursal_id']\n",
    "for x in ps_2020:\n",
    "    ps_2020[x] = ps_2020[x][cols]\n",
    "    ps_2020[x]['fecha'] = datetime.strptime(x, '%Y-%m-%d')\n",
    "    print(f'----------------{x}----------------\\n{ps_2020[x].columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "• DataFrame: 2020-04-26\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478909 entries, 0 to 478908\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       477173 non-null  float64       \n",
      " 1   producto_id  465390 non-null  float64       \n",
      " 2   sucursal_id  478909 non-null  object        \n",
      " 3   fecha        478909 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 14.6+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: 2020-04-19\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 458543 entries, 0 to 458542\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       456736 non-null  float64       \n",
      " 1   producto_id  458543 non-null  object        \n",
      " 2   sucursal_id  458543 non-null  object        \n",
      " 3   fecha        458543 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 14.0+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: 2020-04-13\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 472166 entries, 0 to 472165\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       472153 non-null  float64       \n",
      " 1   producto_id  472151 non-null  object        \n",
      " 2   sucursal_id  472151 non-null  object        \n",
      " 3   fecha        472166 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: 2020-05-03\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397734 entries, 0 to 397733\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       397734 non-null  object        \n",
      " 1   producto_id  397734 non-null  object        \n",
      " 2   sucursal_id  397734 non-null  object        \n",
      " 3   fecha        397734 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 12.1+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: 2020-05-18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415293 entries, 0 to 415292\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       413333 non-null  float64       \n",
      " 1   producto_id  415287 non-null  object        \n",
      " 2   sucursal_id  415287 non-null  object        \n",
      " 3   fecha        415293 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 12.7+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: 2020-06-18\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415293 entries, 0 to 415292\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       413333 non-null  float64       \n",
      " 1   producto_id  415287 non-null  object        \n",
      " 2   sucursal_id  415287 non-null  object        \n",
      " 3   fecha        415293 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 12.7+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: producto\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72038 entries, 0 to 72037\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72038 non-null  object\n",
      " 1   marca         72036 non-null  object\n",
      " 2   nombre        72036 non-null  object\n",
      " 3   presentacion  72036 non-null  object\n",
      " 4   categoria1    4 non-null      object\n",
      " 5   categoria2    4 non-null      object\n",
      " 6   categoria3    4 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "\n",
      "\n",
      "• DataFrame: sucursal\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2333 entries, 0 to 2332\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2333 non-null   object \n",
      " 1   comercioId           2333 non-null   int64  \n",
      " 2   banderaId            2333 non-null   int64  \n",
      " 3   banderaDescripcion   2333 non-null   object \n",
      " 4   comercioRazonSocial  2333 non-null   object \n",
      " 5   provincia            2333 non-null   object \n",
      " 6   localidad            2333 non-null   object \n",
      " 7   direccion            2333 non-null   object \n",
      " 8   lat                  2333 non-null   float64\n",
      " 9   lng                  2333 non-null   float64\n",
      " 10  sucursalNombre       2333 non-null   object \n",
      " 11  sucursalTipo         2333 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 218.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la información de los diferentes datasets para tener presente el tipo de dato de cada columna\n",
    "for x in ps_2020:\n",
    "    print(f\"\\n\\n• DataFrame: {x}\")\n",
    "    print(ps_2020[x].info())\n",
    "for x in dims:\n",
    "    print(f\"\\n\\n• DataFrame: {x}\")\n",
    "    print(dims[x].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que casi todas las tablas tienen valores faltantes, a excepción de la tabla \"sucursal\" y el DataFrame \"2020-05-03\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----DataFrame: 2020-04-26-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio          1736\n",
      "producto_id    13519\n",
      "sucursal_id        0\n",
      "fecha              0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    474692\n",
      "True       4217\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-19-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         1807\n",
      "producto_id       0\n",
      "sucursal_id       0\n",
      "fecha             0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    458543\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-13-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         13\n",
      "producto_id    15\n",
      "sucursal_id    15\n",
      "fecha           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    472134\n",
      "True         32\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-03-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "fecha          0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    397734\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-18-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         1960\n",
      "producto_id       6\n",
      "sucursal_id       6\n",
      "fecha             0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    415104\n",
      "True        189\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-06-18-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         1960\n",
      "producto_id       6\n",
      "sucursal_id       6\n",
      "fecha             0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    415104\n",
      "True        189\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: producto-----\n",
      "\n",
      "• Valores nulos:\n",
      "id                  0\n",
      "marca               2\n",
      "nombre              2\n",
      "presentacion        2\n",
      "categoria1      72034\n",
      "categoria2      72034\n",
      "categoria3      72034\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    72038\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: sucursal-----\n",
      "\n",
      "• Valores nulos:\n",
      "id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2333\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos un ciclo para obtener información sobre valores nulos y registros duplicados de todos los DataFrames\n",
    "for x in ps_2020:\n",
    "    semana = ps_2020[x]\n",
    "    print(f'\\n-----DataFrame: {x}-----\\n\\n• Valores nulos:\\n{semana.isnull().sum()}\\n\\n• Registros duplicados:\\n{semana.duplicated().value_counts()}\\n')\n",
    "for x in dims:\n",
    "    dim = dims[x]\n",
    "    print(f'\\n-----DataFrame: {x}-----\\n\\n• Valores nulos:\\n{dim.isnull().sum()}\\n\\n• Registros duplicados:\\n{dim.duplicated().value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habiendo detectado registros duplicados en los datasets de 'ps_2020' procedemos a eliminarlos\n",
    "for x in ps_2020:\n",
    "    ps_2020[x].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DataFrame: 2020-04-26-----\n",
      "     precio  producto_id sucursal_id      fecha\n",
      "0     399.0       2288.0     2-1-092 2020-04-26\n",
      "1     299.0       2288.0     2-1-206 2020-04-26\n",
      "2     399.0       2288.0     2-2-241 2020-04-26\n",
      "3   49999.0     205870.0     9-1-430 2020-04-26\n",
      "4   53999.0     205870.0       9-2-4 2020-04-26\n",
      "5   53999.0     205870.0    9-3-5218 2020-04-26\n",
      "6   58999.0     205894.0     9-1-430 2020-04-26\n",
      "7   18999.0     205955.0     9-1-430 2020-04-26\n",
      "8   10499.0     205979.0     9-1-430 2020-04-26\n",
      "9    2290.0     206020.0     9-1-430 2020-04-26\n",
      "10  27999.0     206044.0     9-1-430 2020-04-26\n",
      "11   2190.0     206044.0     9-1-691 2020-04-26\n",
      "12  22999.0     206051.0     9-1-430 2020-04-26\n",
      "13  45999.0     206105.0     9-1-430 2020-04-26\n",
      "14  38999.0     206136.0     9-1-430 2020-04-26\n",
      "-----DataFrame: 2020-04-19-----\n",
      "    precio producto_id          sucursal_id      fecha\n",
      "0    29.90        2288              2-1-184 2020-04-19\n",
      "1    39.90        2288              2-1-206 2020-04-19\n",
      "2   499.99      205870              9-1-430 2020-04-19\n",
      "3   539.99      205870              9-2-107 2020-04-19\n",
      "4   539.99      205870  5218-03-09 00:00:00 2020-04-19\n",
      "5   589.99      205894              9-1-430 2020-04-19\n",
      "6   189.99      205955              9-1-430 2020-04-19\n",
      "7   104.99      205979              9-1-430 2020-04-19\n",
      "8   229.00      206020              9-1-430 2020-04-19\n",
      "9   279.99      206044              9-1-430 2020-04-19\n",
      "10  229.99      206051              9-1-430 2020-04-19\n",
      "11  459.99      206105              9-1-430 2020-04-19\n",
      "12  389.99      206136              9-1-430 2020-04-19\n",
      "13  299.99      206143              9-1-430 2020-04-19\n",
      "14  339.99      206181              9-1-430 2020-04-19\n",
      "-----DataFrame: 2020-04-13-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0    29.90  0000000001663     2-1-014 2020-04-13\n",
      "1    29.90  0000000002288     2-1-032 2020-04-13\n",
      "2    39.90  0000000002288     2-1-096 2020-04-13\n",
      "3   499.99  0000000205870     9-1-686 2020-04-13\n",
      "4   519.99  0000000205870     9-2-248 2020-04-13\n",
      "5   539.99  0000000205870      9-2-42 2020-04-13\n",
      "6   539.99  0000000205870     9-3-628 2020-04-13\n",
      "7   589.99  0000000205894     9-1-686 2020-04-13\n",
      "8   189.99  0000000205955     9-1-686 2020-04-13\n",
      "9   104.99  0000000205979     9-1-686 2020-04-13\n",
      "10  259.99  0000000206020     9-1-686 2020-04-13\n",
      "11  279.99  0000000206044     9-1-686 2020-04-13\n",
      "12  229.99  0000000206051     9-1-686 2020-04-13\n",
      "13  459.99  0000000206105     9-1-686 2020-04-13\n",
      "14  389.99  0000000206136     9-1-686 2020-04-13\n",
      "-----DataFrame: 2020-05-03-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0     29.9  0000000002288     2-1-187 2020-05-03\n",
      "1     39.9  0000000002288     2-3-247 2020-05-03\n",
      "2   499.99  0000000205870     9-1-685 2020-05-03\n",
      "3   539.99  0000000205870      9-2-22 2020-05-03\n",
      "4   519.99  0000000205870      9-2-59 2020-05-03\n",
      "5   539.99  0000000205870     9-3-138 2020-05-03\n",
      "6   589.99  0000000205894     9-1-685 2020-05-03\n",
      "7   189.99  0000000205955     9-1-685 2020-05-03\n",
      "8   104.99  0000000205979     9-1-685 2020-05-03\n",
      "9      229  0000000206020     9-1-685 2020-05-03\n",
      "10  279.99  0000000206044     9-1-685 2020-05-03\n",
      "11  229.99  0000000206051     9-1-685 2020-05-03\n",
      "12  459.99  0000000206105     9-1-685 2020-05-03\n",
      "13  389.99  0000000206136     9-1-685 2020-05-03\n",
      "14  299.99  0000000206143     9-1-685 2020-05-03\n",
      "-----DataFrame: 2020-05-18-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0    29.90  0000000002288     2-1-009 2020-05-18\n",
      "1    32.90  0000000002288     2-1-037 2020-05-18\n",
      "2    36.90  0000000002288     2-1-090 2020-05-18\n",
      "3    39.90  0000000002288     2-3-247 2020-05-18\n",
      "4   499.99  0000000205870     9-1-430 2020-05-18\n",
      "5   539.99  0000000205870       9-2-4 2020-05-18\n",
      "6   539.99  0000000205870    9-3-5205 2020-05-18\n",
      "7   589.99  0000000205894     9-1-430 2020-05-18\n",
      "8   189.99  0000000205955     9-1-430 2020-05-18\n",
      "9   104.99  0000000205979     9-1-430 2020-05-18\n",
      "10  259.99  0000000206020     9-1-430 2020-05-18\n",
      "11  279.99  0000000206044     9-1-430 2020-05-18\n",
      "12  229.99  0000000206051     9-1-430 2020-05-18\n",
      "13  459.99  0000000206105     9-1-430 2020-05-18\n",
      "14  389.99  0000000206136     9-1-430 2020-05-18\n",
      "-----DataFrame: 2020-06-18-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0    29.90  0000000002288     2-1-009 2020-06-18\n",
      "1    32.90  0000000002288     2-1-037 2020-06-18\n",
      "2    36.90  0000000002288     2-1-090 2020-06-18\n",
      "3    39.90  0000000002288     2-3-247 2020-06-18\n",
      "4   499.99  0000000205870     9-1-430 2020-06-18\n",
      "5   539.99  0000000205870       9-2-4 2020-06-18\n",
      "6   539.99  0000000205870    9-3-5205 2020-06-18\n",
      "7   589.99  0000000205894     9-1-430 2020-06-18\n",
      "8   189.99  0000000205955     9-1-430 2020-06-18\n",
      "9   104.99  0000000205979     9-1-430 2020-06-18\n",
      "10  259.99  0000000206020     9-1-430 2020-06-18\n",
      "11  279.99  0000000206044     9-1-430 2020-06-18\n",
      "12  229.99  0000000206051     9-1-430 2020-06-18\n",
      "13  459.99  0000000206105     9-1-430 2020-06-18\n",
      "14  389.99  0000000206136     9-1-430 2020-06-18\n",
      "-----DataFrame: producto-----\n",
      "               id       marca                                   nombre  \\\n",
      "0   0000000001663  LA ANÓNIMA          Radicheta Atada La Anonima 1 Un   \n",
      "1   0000000002288  LA ANÓNIMA            Perejil Atado La Anonima 1 Un   \n",
      "2   0000000205870   SIN MARCA                         Ojo de Bife 1 Kg   \n",
      "3   0000000205894   SIN MARCA        Milanesa de Peceto Novillito 1 Kg   \n",
      "4   0000000205955   SIN MARCA               Chiquizuela Novillito 1 Kg   \n",
      "5   0000000205979   SIN MARCA               Espinazo de Novillito 1 Kg   \n",
      "6   0000000206020   SIN MARCA           Carnanza Comun de Novillo 1 Kg   \n",
      "7   0000000206044   SIN MARCA  Falda Deshuesada Novillito Bandeja 1 Kg   \n",
      "8   0000000206051   SIN MARCA                  Carne Picada Comun 1 Kg   \n",
      "9   0000000206105   SIN MARCA               Entraña de Novillito 1 Kg   \n",
      "10  0000000206136   SIN MARCA             Bife Ancho de Novillito 1 Kg   \n",
      "11  0000000206143   SIN MARCA     Rost Beef en Trozo de Novillito 1 Kg   \n",
      "12  0000000206181   SIN MARCA               Palomita de Novillito 1 Kg   \n",
      "13  0000000206198   SIN MARCA                Tortuguita Novillito 1 Kg   \n",
      "14  0000000206235   SIN MARCA           Paleta en Trozo Novillito 1 Kg   \n",
      "\n",
      "   presentacion categoria1 categoria2 categoria3  \n",
      "0        1.0 un       None       None       None  \n",
      "1        1.0 un       None       None       None  \n",
      "2        1.0 kg       None       None       None  \n",
      "3        1.0 kg       None       None       None  \n",
      "4        1.0 kg       None       None       None  \n",
      "5        1.0 kg       None       None       None  \n",
      "6        1.0 kg       None       None       None  \n",
      "7        1.0 kg       None       None       None  \n",
      "8        1.0 kg       None       None       None  \n",
      "9        1.0 kg       None       None       None  \n",
      "10       1.0 kg       None       None       None  \n",
      "11       1.0 kg       None       None       None  \n",
      "12       1.0 kg       None       None       None  \n",
      "13       1.0 kg       None       None       None  \n",
      "14       1.0 kg       None       None       None  \n",
      "-----DataFrame: sucursal-----\n",
      "          id  comercioId  banderaId      banderaDescripcion  \\\n",
      "0      1-1-7           1          1              Super MAMI   \n",
      "1     10-1-1          10          1  Hipermercado Carrefour   \n",
      "2    10-1-10          10          1  Hipermercado Carrefour   \n",
      "3    10-1-11          10          1  Hipermercado Carrefour   \n",
      "4   10-1-112          10          1  Hipermercado Carrefour   \n",
      "5    10-1-12          10          1  Hipermercado Carrefour   \n",
      "6   10-1-123          10          1  Hipermercado Carrefour   \n",
      "7   10-1-128          10          1  Hipermercado Carrefour   \n",
      "8   10-1-136          10          1  Hipermercado Carrefour   \n",
      "9   10-1-139          10          1  Hipermercado Carrefour   \n",
      "10  10-1-142          10          1  Hipermercado Carrefour   \n",
      "11  10-1-147          10          1  Hipermercado Carrefour   \n",
      "12  10-1-149          10          1  Hipermercado Carrefour   \n",
      "13   10-1-15          10          1  Hipermercado Carrefour   \n",
      "14  10-1-156          10          1  Hipermercado Carrefour   \n",
      "\n",
      "   comercioRazonSocial provincia            localidad  \\\n",
      "0      Dinosaurio S.A.      AR-X          SALSIPUEDES   \n",
      "1             INC S.A.      AR-B           San Isidro   \n",
      "2             INC S.A.      AR-B           Hurlingham   \n",
      "3             INC S.A.      AR-B  Malvinas Argentinas   \n",
      "4             INC S.A.      AR-A                Salta   \n",
      "5             INC S.A.      AR-B            San Justo   \n",
      "6             INC S.A.      AR-J             San Juan   \n",
      "7             INC S.A.      AR-U   Comodoro Rivadavia   \n",
      "8             INC S.A.      AR-R         General Roca   \n",
      "9             INC S.A.      AR-B            Olavarría   \n",
      "10            INC S.A.      AR-V           Río Grande   \n",
      "11            INC S.A.      AR-L           Santa Rosa   \n",
      "12            INC S.A.      AR-R            Bariloche   \n",
      "13            INC S.A.      AR-B           San Martín   \n",
      "14            INC S.A.      AR-B          San Nicolás   \n",
      "\n",
      "                    direccion        lat        lng       sucursalNombre  \\\n",
      "0               E53 1011 None -31.126667 -64.295250         Super Mami 4   \n",
      "1   Bernardo De Irigoyen 2647 -34.491345 -58.589025           San Isidro   \n",
      "2            Av. Vergara 1910 -34.620610 -58.633769          Villa Tesei   \n",
      "3       Av. Arturo Illia 3770 -34.528883 -58.701631  Malvinas Argentinas   \n",
      "4            20 De Febrero 37 -24.789072 -65.413699                Salta   \n",
      "5          Av. Don Bosco 2680 -34.664628 -58.597356            San Justo   \n",
      "6               Gral. Acha 32 -31.534016 -68.524744             San Juan   \n",
      "7              Pellegrini 851 -45.861562 -67.479968   Comodoro Rivadavia   \n",
      "8              25 De Mayo 622 -39.030326 -67.573775         General Roca   \n",
      "9              Rivadavia 2846 -36.893694 -60.321650            Olavarría   \n",
      "10         Av. San Martín 685 -53.785009 -67.702990           Río Grande   \n",
      "11             Avellaneda 151 -36.618338 -64.291249           Santa Rosa   \n",
      "12                 Moreno 909 -41.136201 -71.296792            Bariloche   \n",
      "13         Av. San Martín 420 -34.586322 -58.519449           San Martín   \n",
      "14        Bartolomé Mitre 264 -33.331816 -60.220188          San Nicolás   \n",
      "\n",
      "    sucursalTipo  \n",
      "0   Hipermercado  \n",
      "1   Hipermercado  \n",
      "2   Hipermercado  \n",
      "3   Hipermercado  \n",
      "4   Hipermercado  \n",
      "5   Hipermercado  \n",
      "6   Supermercado  \n",
      "7   Hipermercado  \n",
      "8   Supermercado  \n",
      "9   Hipermercado  \n",
      "10  Supermercado  \n",
      "11  Hipermercado  \n",
      "12  Hipermercado  \n",
      "13  Hipermercado  \n",
      "14  Hipermercado  \n"
     ]
    }
   ],
   "source": [
    "# Ahora podemos generar una visualización preliminar de las tablas para continuar con el proceso de limpieza y lidiar con los valores nulos\n",
    "for x in ps_2020:\n",
    "    print(f'-----DataFrame: {x}-----\\n{ps_2020[x].head(15)}')\n",
    "for x in dims:\n",
    "    print(f'-----DataFrame: {x}-----\\n{dims[x].head(15)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Primeros problemas con el formato de los datos:\n",
    "Con la anterior visualización preliminar y la información de los DataFrames se pueden ver varias cuestiones a tener en cuenta y que se abordarán a continuación:\n",
    "1) En uno de los DataFrames de precios (2020-05-03), el tipo de data de la columna 'precio' no es *float64* como en los demás.\n",
    "2) El formato de la columna 'producto_id' es diferente en varios DataFrames.\n",
    "3) Algunos valores de la columna 'sucursal_id' de al menos la tabla '2020-04-19' son interpretados en como de tipo 'datetime'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) El tipo de dato en la columna 'precio' no es *float64* en todos los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\n",
      "{\"<class 'float'>\", \"<class 'int'>\", \"<class 'str'>\"}\n",
      "\n",
      "• Valores que encontramos para los strings de esta columna:\n",
      "{''}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ahora exploramos un poco los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "# Obtenemos 1) los tipos de datos que se encuentran en la columna\n",
    "#           2) el valor de los datos tipo 'str'\n",
    "#           3) la cantidad de ceros en esta columna\n",
    "precio_dtype = set()\n",
    "strings = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if type(x) == str:\n",
    "        #print(x)\n",
    "        strings.add(x)\n",
    "    elif x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Valores que encontramos para los strings de esta columna:\\n{strings}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### • Ya que detectamos que no hay registros en la columna con valor de '0', éste es un buen candidato para remplazar los valores faltantes de 'precio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: 2020-04-26\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-19\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-13\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-03\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-18\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-06-18\n",
      "Está 0 en la columna 'precio': False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Procedemos a detectar si en los demás DataFrames hay valores de '0' en la columna precio\n",
    "has_zeros = {}\n",
    "for x in ps_2020:\n",
    "    has_zeros[x] = (0 in ps_2020[x].precio.unique())\n",
    "for x in has_zeros:\n",
    "    print(f\"DataFrame: {x}\\nEstá 0 en la columna 'precio': {has_zeros[x]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que ningún DataFrame tiene el dato '0' en la columna 'precio', procedemos a remplazar los valores faltantes con '0'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['precio_ok'] = ps_2020[x]['precio'].replace('', np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios_ok del DataFrame 2020-05-03:\n",
      "{\"<class 'float'>\"}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "2124\n"
     ]
    }
   ],
   "source": [
    "# Volvemos a explorar los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "precio_dtype = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio_ok:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios_ok del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior test podemos corroborar que la nueva columna ('precio_ok') ya no tiene valores del tipo *str* en la única tabla que había valores que no eran \"float\" en esta columna. \n",
    "\n",
    "Así, ésta es la columna que usaremos en el dataset final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Unificar el formato de las columnas 'producto_id', dejándolo como un *str*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'float'>}\n",
      "• DataFrame 2020-04-19:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'int'>}\n",
      "• DataFrame 2020-04-13:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'float'>}\n",
      "• DataFrame 2020-05-03:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'int'>}\n",
      "• DataFrame 2020-05-18:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'float'>}\n",
      "• DataFrame 2020-06-18:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'float'>}\n"
     ]
    }
   ],
   "source": [
    "# Primero nos cercioramos del tipo de dato que hay en cada una de las columnas 'producto_id'\n",
    "producto_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    producto_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].producto_id:\n",
    "        producto_id_dtypes[x].add(type(y))\n",
    "for x in producto_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\n  Tipos de dato en la columna 'producto_id': {producto_id_dtypes[x]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• DataFrame 2020-04-26:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 63925\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 0\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 1\n",
      "    El único valor float encontrado fue: {nan}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 0\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 1\n",
      "    El único valor float encontrado fue: {nan}\n",
      "\n",
      "• DataFrame 2020-06-18:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 1\n",
      "    El único valor float encontrado fue: {nan}\n",
      "\n",
      "• Cantidad de ceros en las columnas 'producto_id': 0\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la cantidad de valores de tipo 'float' en las tablas 2020-04-26, 2020-04-13 y 2020-05-18\n",
    "# Además revisamos si encontramos '0' entre estos valores\n",
    "valores_float = {}\n",
    "pid_zeros = 0\n",
    "for x in ps_2020:\n",
    "    valores_float[x] = set()\n",
    "    for y in ps_2020[x].producto_id:\n",
    "        if type(y) == float:\n",
    "            valores_float[x].add(y)\n",
    "        if y in [0,'0']:\n",
    "            pid_zeros += 1\n",
    "for x in valores_float:\n",
    "    print(f\"\\n• DataFrame {x}:\\n  Cantidad de valores 'float' en la columna 'producto_id': {len(valores_float[x])}\")\n",
    "    if len(valores_float[x]) ==1:\n",
    "        print(f\"    El único valor float encontrado fue: {valores_float[x]}\")\n",
    "print(f\"\\n• Cantidad de ceros en las columnas 'producto_id': {pid_zeros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del anterior chequeo podemos deducir que sólo el DataFrame 2020-04-26 tiene valores 'float' distintos de 'nan', además de que ninguno de los DataFrames tiene el valor '0' en la columna 'producto_id'. \n",
    "\n",
    "Por lo anterior, procederemos a remplazar los valores faltantes con 0 y, posteriormente, a convertir los valores 'float' en 'int' (para quitar el decimal) y luego en 'str' (para homogeneizar las claves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Revisamos si todavía hay valores nulos\\nfor x in ps_2020:\\n    print(f'\\n• DataFrame: {x}')\\n    print(ps_2020[x].isnull().sum())\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remplazamos los valores faltantes con 0\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id2'] = (ps_2020[x]['producto_id'].replace('', np.nan).fillna(0))\n",
    "\n",
    "'''\n",
    "# Revisamos si todavía hay valores nulos\n",
    "for x in ps_2020:\n",
    "    print(f'\\n• DataFrame: {x}')\n",
    "    print(ps_2020[x].isnull().sum())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para cambiar los valores 'float' e 'int' a 'str'\n",
    "def pid_num2str(val):\n",
    "    if type(val) == float:\n",
    "        return str(int(val))\n",
    "    elif type(val) == int:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "# Aplicamos la función a la columna sin valores nulos (producto_id2) y guardamos el resultado en otra columna (producto_id3)\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id3'] = ps_2020[x]['producto_id2'].apply(pid_num2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-04-19:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-04-13:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-05-03:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-05-18:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-06-18:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# Ahora revisamos el tipo de dato que hay en cada una de las columnas 'producto_id3'\n",
    "sucursal_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].producto_id3:\n",
    "        sucursal_id_dtypes[x].add(type(y))\n",
    "for x in sucursal_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\n  Tipos de dato en la columna 'producto_id3': {sucursal_id_dtypes[x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ya que tenemos el 'producto_id' en todas las tablas de 'precios' en formato 'str', nos aseguraremos ahora de que estos valores correspondan a un valor en la tabla 'producto', recordando que los datos faltantes fueron remplazados por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Revisamos el formato del 'id' en la tabla producto a la que las columnas 'precio.producto_id' harán referencia\n",
    "# Para esto vemos primero los tipos de dato almacenados en esta columna\n",
    "pid_dtypes = set()\n",
    "for x in dims['producto'].id:\n",
    "    pid_dtypes.add(type(x))\n",
    "for x in pid_dtypes:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'id' de la tabla 'producto' encontramos valores de las siguientes longitudes: {17, 18, 13}\n"
     ]
    }
   ],
   "source": [
    "# Al confirmar que todos los valores de la columna 'id' en la tabla 'producto' son str, obtenemos la longitud de estos valores\n",
    "pid_lengths = set()\n",
    "\n",
    "for x in dims['producto'].id.unique():\n",
    "    pid_lengths.add(len(x))\n",
    "\n",
    "print(f\"En la columna 'id' de la tabla 'producto' encontramos valores de las siguientes longitudes: {pid_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Algunos ejemplos de los valores en la columna 'id' de la tabla 'producto' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "17: ['6-1-0000000013099', '9-3-0000000202985', '7-1-0023069700000', '9-1-0000000465748', '7-1-0021036800000']\n",
      "18: ['16-1-0000000271433', '45-1-0000000064045', '10-2-2302838000008', '14-1-0000000084219', '44-1-0000000097087']\n",
      "13: ['7794626009310', '7791720002957', '7794000596085', '7791130683678', '7790580346607']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos ahora en qué consisten las diferencias de los códigos de distintas longitudes\n",
    "pid_lengths_examples = {}\n",
    "for x in pid_lengths:\n",
    "    pid_lengths_examples[str(x)] = []\n",
    "for x in dims['producto'].id:\n",
    "    len_x = str(len(x))\n",
    "    pid_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\n• Algunos ejemplos de los valores en la columna 'id' de la tabla 'producto' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in pid_lengths_examples:\n",
    "    print(f'{x}: {sample(pid_lengths_examples[x],5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que los códigos de 'id' en la tabla 'producto' con más de 13 caracteres se diferencian de aquellos con 13 caracteres porque tienen un prefijo compuesto de la siguiente manera:\n",
    "\n",
    "(Número de uno o dos dígitos)+(guión)+(Número de un dígito)+(guión)\n",
    "\n",
    "Dado que hay diferentes longitudes en los códigos de la columna 'id' de la tabla 'producto', revisaremos ahora si:\n",
    "1) Estos códigos son únicos por registro\n",
    "2) Los códigos siguen siendo únicos si los reducimos todos a tener sólo 13 caracteres (los últimos 13, para evitar la parte que contiene guiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'producto': 72038\n",
      "Cantidad de valores únicos en la columna 'id' original: 72038\n",
      "\n",
      "• Los valores originales de la columna 'id' son únicos por registro: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Se verifica que los ids originales sean únicos por registro\n",
    "\n",
    "tot_reg_producto = len(dims['producto'])\n",
    "id_uniq_producto = dims['producto'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'producto': {tot_reg_producto}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' original: {id_uniq_producto}\")\n",
    "print(f\"\\n• Los valores originales de la columna 'id' son únicos por registro: {tot_reg_producto==id_uniq_producto}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['marca', 'nombre', 'presentacion', 'categoria1', 'categoria2',\n",
      "       'categoria3', 'id'],\n",
      "      dtype='object')\n",
      "\n",
      "-----DataFrame: 'producto2'-----\n",
      "\n",
      "• Valores nulos:\n",
      "marca               2\n",
      "nombre              2\n",
      "presentacion        2\n",
      "categoria1      68194\n",
      "categoria2      68194\n",
      "categoria3      68194\n",
      "id                  0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    68198\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un nuevo DataFrame a partir de 'producto' y remplazamos la columna 'id' por su versión reducida (pid2)\n",
    "pid2 = []\n",
    "for x in dims['producto'].id:\n",
    "    if len(x)>13:\n",
    "        y = x[-13:]\n",
    "        pid2.append(y)\n",
    "    else:\n",
    "        pid2.append(x)\n",
    "pid2_array = pd.Series(pid2)\n",
    "\n",
    "# Creamos un DataFrame nuevo con los ids reducidos y dropeando los duplicados\n",
    "dims['producto2'] = dims['producto'].drop('id', axis=1)\n",
    "\n",
    "dims['producto2']['id'] = pid2_array\n",
    "\n",
    "dims['producto2'].drop_duplicates(inplace=True)\n",
    "\n",
    "print(dims['producto2'].columns)\n",
    "\n",
    "print(f\"\\n-----DataFrame: 'producto2'-----\\n\\n• Valores nulos:\\n{dims['producto2'].isnull().sum()}\\n\\n• Registros duplicados:\\n{dims['producto2'].duplicated().value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'producto2': 68198\n",
      "Cantidad de valores únicos en la columna 'id' reducida: 67943\n",
      "\n",
      "• Los valores reducidos de la columna 'id' son únicos por registro: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Verificamos si el nuevo DataFrame con ids reducidos ('producto2') sigue teniendo un id único para cada registro\n",
    "tot_reg_producto2 = len(dims['producto2'])\n",
    "id_uniq_producto2 = dims['producto2'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'producto2': {tot_reg_producto2}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' reducida: {id_uniq_producto2}\")\n",
    "print(f\"\\n• Los valores reducidos de la columna 'id' son únicos por registro: {tot_reg_producto2==id_uniq_producto2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con el código de las últimas 3 celdas se logró verificar que es necesario conservar los ids originales de la tabla 'producto' puesto que, si tomamos sólo los últimos 13 caracteres de cada código, entonces tendremos códigos repetidos para diferentes productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que no se puede reducir la longitud de los códigos de 'id' largos sin comprometer la unicidad de cada código para los registros de la tabla 'producto', procederemos a modificar las columnas 'producto_id' de las tablas 'precios' para que se ajusten a alguno de los valores de 13, 17 o 18 dígitos de la columna 'id' de la tabla 'producto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Cantidades de caracteres en los distintos valores de las columnas producto_id3:\n",
      "\n",
      "\tDataFrame2020-04-26: {1, 4, 6, 7, 8, 9, 10, 11, 12, 13}\n",
      "\n",
      "\tDataFrame2020-04-19: {4, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18}\n",
      "\n",
      "\tDataFrame2020-04-13: {17, 18, 13, 1}\n",
      "\n",
      "\tDataFrame2020-05-03: {17, 18, 13}\n",
      "\n",
      "\tDataFrame2020-05-18: {17, 18, 13, 1}\n",
      "\n",
      "\tDataFrame2020-06-18: {17, 18, 13, 1}\n",
      "\n",
      "• Casos más excepcionales (con valores de 1 o 4 caracteres):\n",
      "\n",
      "\tValores de 1 caracter por DataFrame (df, valor): [['2020-04-26', '0'], ['2020-04-13', '0'], ['2020-05-18', '0'], ['2020-06-18', '0']]\n",
      "\n",
      "\tValores de 4 caracteres por DataFrame (df, valor): [['2020-04-26', '2288'], ['2020-04-19', '2288']]\n"
     ]
    }
   ],
   "source": [
    "# Empezamos por revisar las diferentes longitudes de los valores de las columnas 'producto_id' en las tablas de 'precios' \n",
    "# Posteriormente visualizamos los valores más excepcionales (1 y 4)\n",
    "ps_pid_lengths = {}\n",
    "id_1_car = []\n",
    "id_4_car = []\n",
    "for x in ps_2020:\n",
    "    ps_pid_lengths[x] = set()\n",
    "    for y in ps_2020[x]['producto_id3'].unique():\n",
    "        ps_pid_lengths[x].add(len(str(y)))\n",
    "        if len(str(y)) == 1:\n",
    "            id_1_car.append([x,y])\n",
    "        elif len(str(y)) == 4:\n",
    "            id_4_car.append([x,y])\n",
    "\n",
    "print('\\n• Cantidades de caracteres en los distintos valores de las columnas producto_id3:\\n')\n",
    "for x in ps_pid_lengths:\n",
    "    print(f'\\tDataFrame{x}: {ps_pid_lengths[x]}\\n')\n",
    "\n",
    "print('• Casos más excepcionales (con valores de 1 o 4 caracteres):\\n')\n",
    "print(f'\\tValores de 1 caracter por DataFrame (df, valor): {id_1_car}\\n')\n",
    "print(f'\\tValores de 4 caracteres por DataFrame (df, valor): {id_4_car}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el caso más extremo corresponde al de los valores nulos, que fueron remplazados por 0.\n",
    "\n",
    "Mientras que el siguiente caso de valores con pocos caracteres es '2288', valor que s epodría corresponder con el id '0000000002288' de la tabla 'producto'.\n",
    "\n",
    "Por esta razón, procederemos a llenar los valores con menos de 13 caracteres de las columnas 'producto_id3' en las tablas 'precios' con 0's a la izquierda hasta tener un valor con 13 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de códigos en las columnas 'producto_id3' con menos de 13 caracteres por DataFrame:\n",
      "\n",
      "• DataFrame 2020-04-26:20736\n",
      "\n",
      "• DataFrame 2020-04-19:11125\n",
      "\n",
      "• DataFrame 2020-04-13:3\n",
      "\n",
      "• DataFrame 2020-05-03:0\n",
      "\n",
      "• DataFrame 2020-05-18:3\n",
      "\n",
      "• DataFrame 2020-06-18:3\n"
     ]
    }
   ],
   "source": [
    "# Primero vemos la cantidad de registros con menos de 13 caracteres en cada uno de los DataFrames de 'precios'\n",
    "pid_short_codes = {}\n",
    "for x in ps_2020:\n",
    "    pid_short_codes[x] = []\n",
    "    for y in ps_2020[x].producto_id3:\n",
    "        if len(y)<13:\n",
    "            pid_short_codes[x].append(x)\n",
    "print(\"Cantidad de códigos en las columnas 'producto_id3' con menos de 13 caracteres por DataFrame:\")\n",
    "for x in pid_short_codes:\n",
    "    print(f'\\n• DataFrame {x}:{len(pid_short_codes[x])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que nos regrese un valor de 13 caracteres con 0 a la izquierda si el argumento pasado (str) tiene menos de 13\n",
    "def fill_id(str):\n",
    "    if len(str)<13:\n",
    "        return str.zfill(13)\n",
    "    else:\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a las columnas 'producto_id3' de los DataFrames de 'precios'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id4'] = ps_2020[x]['producto_id3'].apply(fill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17, 18, 13}\n"
     ]
    }
   ],
   "source": [
    "# Revisamos las longitudes de los valores de la columna 'producto_id4'\n",
    "pid4_lengths = set()\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].producto_id4:\n",
    "        pid4_lengths.add(len(y))\n",
    "print(pid4_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### • Una vez transformados los datos de la columna 'producto_id' de los DataFrames de 'precios' a su forma final en la columna 'producto_id4', procedemos a revisar que todos estos sí hagan referencia a algún valor de la columna 'id' en la tabla 'producto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72038\n",
      "72038\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista (pid) con los valores de la columna 'id' de la tabla producto\n",
    "pid = []\n",
    "\n",
    "for x in dims['producto'].id.unique():\n",
    "    pid.append(x)\n",
    "print(len(pid))\n",
    "print(dims['producto'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Output (8m 30.2s):\\nChecking 2020-04-26... 54624 values to check..\\nChecking 2020-04-19... 62393 values to check..\\nChecking 2020-04-13... 66532 values to check..\\nChecking 2020-05-03... 61505 values to check..\\nChecking 2020-05-18... 60745 values to check..\\n\\n\\nRESULTS:\\n\\n• DataFrame 2020-04-26:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-19:\\n\\tFound problems: True (Amount: 7)\\n• DataFrame 2020-04-13:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-03:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-18:\\n\\tFound problems: False (Amount: 0)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El siguiente código revisa, para todas los DataFrames de precios, si los valores de 'producto_id4' se encuentran en la lista 'pid' recién creada.\n",
    "# La ejecución puede llegar a tardar varios minutos así que el código está comentado para que no se ejecute automáticamente al correr todas las celdas.\n",
    "'''\n",
    "pid_checklist = {}\n",
    "pid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = len(ps_2020[x].producto_id4.unique())\n",
    "    print(f'Checking DataFrame {x}... {len_x} values to check..')\n",
    "    pid_checklist[x] = False\n",
    "    pid_problems_found[x] = []\n",
    "    for y in ps_2020[x].producto_id4.unique():\n",
    "        if (y != '0000000000000'):\n",
    "            if y not in pid:\n",
    "                pid_checklist[x] = True\n",
    "                pid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "print('\\n\\nRESULTS:\\n')\n",
    "for x in pid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {pid_checklist[x]} (Amount: {len(pid_problems_found[x])})\")\n",
    "'''\n",
    "\n",
    "''' Output (8m 30.2s):\n",
    "Checking 2020-04-26... 54624 values to check..\n",
    "Checking 2020-04-19... 62393 values to check..\n",
    "Checking 2020-04-13... 66532 values to check..\n",
    "Checking 2020-05-03... 61505 values to check..\n",
    "Checking 2020-05-18... 60745 values to check..\n",
    "\n",
    "\n",
    "RESULTS:\n",
    "\n",
    "• DataFrame 2020-04-26:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-19:\n",
    "\tFound problems: True (Amount: 7)\n",
    "• DataFrame 2020-04-13:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-03:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-18:\n",
    "\tFound problems: False (Amount: 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Output:\\n2020-04-26: []\\n2020-04-19: ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\\n2020-04-13: []\\n2020-05-03: []\\n2020-05-18: []\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for x in pid_problems_found:\n",
    "    print(f'{x}: {pid_problems_found[x]}')\n",
    "'''\n",
    "\n",
    "''' Output:\n",
    "2020-04-26: []\n",
    "2020-04-19: ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\n",
    "2020-04-13: []\n",
    "2020-05-03: []\n",
    "2020-05-18: []\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Con las últimas tres celdas pudimos corroborar que no todos los valores de 'producto_id4' corresponden a un id de la tabla 'producto'.\n",
    "\n",
    "Un problema del que habrá que informar al cliente. Sin embargo, al ser pocos (7) los valores de 'producto_id' problemáticos y en una sola tabla, se optará por remplazarlos por un valor alternativo del que usamos en donde los datos faltaban ('0000000000000') : '1111111111111'.\n",
    "\n",
    "Por lo pronto, todos los 'producto_id4' son  del tipo 'str' y de estructura más o menos uniforme (salvo por la variación en las longitudes) así que se subirán así a la base de datos, una vez hecho el remplazo que se acaba de mencionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Confirmamos si el código a usar para notificar de este error no está ya en los valores 'id' del DataFrame 'producto'\n",
    "print(('1111111111111' in dims['producto'].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de productos a remplazar en los 6 DataFrames es de 7, de un total de 2633311 (0.00027%).\n"
     ]
    }
   ],
   "source": [
    "# Definimos los registros a remplazar (pid_a_remplazar) y vemos cual es el total de registros en las columnas 'producto_id4' a remplazar\n",
    "pid_a_remplazar = ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\n",
    "# Aquí podemos ver que el total de registros remplazados fueron 7\n",
    "pid_ar_count = 0\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].producto_id4:\n",
    "        if y in pid_a_remplazar:\n",
    "            pid_ar_count += 1\n",
    "tot_reg = 0\n",
    "for x in ps_2020:\n",
    "    tot_reg += ps_2020[x].shape[0]\n",
    "print(f'El total de productos a remplazar en los {len(ps_2020.keys())} DataFrames es de {pid_ar_count}, de un total de {tot_reg} ({round(100*(pid_ar_count/tot_reg),5)}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver que la cantidad de registros a modificar es nimia, llevamos a cabo el remplazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creamos una función que cambie estos registros por el código elegido\n",
    "def nxcode2err111(registro):\n",
    "    if registro in pid_a_remplazar:\n",
    "        return '1111111111111'\n",
    "    else:\n",
    "        return registro\n",
    "# Aplicamos la función y creamos la columna 'producto_id_ok':\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id_ok'] = ps_2020[x]['producto_id4'].apply(nxcode2err111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Output (9m 37.8s):\\nRESULTS:\\n\\n• DataFrame 2020-04-26:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-19:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-13:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-03:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-18:\\n\\tFound problems: False (Amount: 0)\\n' Output (8m 4.8s):\\n\\n'\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volvemos a hacer la verificación de las referencias de producto_id_ok' a 'producto.id'\n",
    "'''\n",
    "pid_checklist = {}\n",
    "pid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = len(ps_2020[x].producto_id_ok.unique())\n",
    "    #print(f'Checking DataFrame {x}... {len_x} values to check..')\n",
    "    pid_checklist[x] = False\n",
    "    pid_problems_found[x] = []\n",
    "    for y in ps_2020[x].producto_id_ok.unique():\n",
    "        if (y != '0000000000000') and (y != '1111111111111'):\n",
    "            if y not in pid:\n",
    "                pid_checklist[x] = True\n",
    "                pid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "print('\\n\\nRESULTS:\\n')\n",
    "for x in pid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {pid_checklist[x]} (Amount: {len(pid_problems_found[x])})\")\n",
    "'''\n",
    "\n",
    "''' Output (9m 37.8s):\n",
    "RESULTS:\n",
    "\n",
    "• DataFrame 2020-04-26:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-19:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-13:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-03:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-18:\n",
    "\tFound problems: False (Amount: 0)\n",
    "' Output (8m 4.8s):\\n\\n'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Corregir los valores de las columnas 'sucursal_id' que se hayan remplazado por valores tipo *datetime*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'datetime.datetime'>, <class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>, <class 'float'>}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>, <class 'float'>}\n",
      "\n",
      "• DataFrame 2020-06-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>, <class 'float'>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Primero nos cercioramos del tipo de dato que hay en cada una de las columnas 'sucursal_id'\n",
    "sucursal_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].sucursal_id:\n",
    "        sucursal_id_dtypes[x].add(type(y))\n",
    "for x in sucursal_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\nTipos de datos encontrados en la columna 'sucursal_id': {sucursal_id_dtypes[x]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que además de los valores datetime (que sólo están en el DataFrame 2020-04-19) también hay valores 'float' en los DataFrames 2020-04-13 y 2020-05-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores que no son de tipo 'str': 140452\n",
      "\n",
      "• Tipo datetime: 140443\n",
      "\t2020-04-26:0\n",
      "\t2020-04-19:140443\n",
      "\t2020-04-13:0\n",
      "\t2020-05-03:0\n",
      "\t2020-05-18:0\n",
      "\t2020-06-18:0\n",
      "• Tipo float: 9\n",
      "\t2020-04-26:0 -- values: []\n",
      "\t2020-04-19:0 -- values: []\n",
      "\t2020-04-13:3 -- values: [nan, nan, nan]\n",
      "\t2020-05-03:0 -- values: []\n",
      "\t2020-05-18:3 -- values: [nan, nan, nan]\n",
      "\t2020-06-18:3 -- values: [nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos qué tantos valores encontramos para cada tipo y si son pocos los visualizamos\n",
    "count = 0\n",
    "dt_count = 0\n",
    "dt_values = {}\n",
    "fl_count = 0\n",
    "fl_values = {}\n",
    "\n",
    "for x in ps_2020:\n",
    "    dt_values[x] = []\n",
    "    fl_values[x] = []\n",
    "    for y in ps_2020[x].sucursal_id:\n",
    "        if type(y) != str:\n",
    "            count += 1\n",
    "            if type(y) == datetime:\n",
    "                dt_count += 1\n",
    "                dt_values[x].append(y)\n",
    "            elif type(y) == float:\n",
    "                fl_count += 1\n",
    "                fl_values[x].append(y)\n",
    "print(f\"\\nValores que no son de tipo 'str': {count}\\n\")\n",
    "print(f\"• Tipo datetime: {dt_count}\")\n",
    "for x in dt_values:\n",
    "    print(f\"\\t{x}:{len(dt_values[x])}\")\n",
    "print(f\"• Tipo float: {fl_count}\")\n",
    "for x in fl_values:\n",
    "    print(f\"\\t{x}:{len(fl_values[x])} -- values: {fl_values[x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior testeo podemos ver que los valores de tipo 'float' que se registran en los DataFrames 2020-04-13 y 2020-05-18 son valores faltantes. En lo siguiente serán remplazados por el str '0' para que todas las columnas sean de tipo str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que se pueda aplicar a la columna 'sucursal_id' y nos regrese cada valor como un str en el formato deseado\n",
    "def sucursal_id_2str(registro):\n",
    "    if type(registro) == datetime:\n",
    "        spl = registro.strftime('%d-%m-%Y').split('-')\n",
    "        #print(f'{x}:{spl}')\n",
    "        if spl[0][0] == '0':\n",
    "            spl[0] = spl[0][1]\n",
    "        if spl[1][0] == '0':\n",
    "            spl[1] = spl[1][1]\n",
    "        return str(f'{spl[0]}-{spl[1]}-{spl[2]}')\n",
    "    elif type(registro) == float:\n",
    "        return '0'\n",
    "    else:\n",
    "        return str(registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a las columnas de 'sucursal_id' y guardamos los valores en una nueva columna 'sucursal_id2'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['sucursal_id2'] = ps_2020[x].sucursal_id.apply(sucursal_id_2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-06-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los tipos de datos hallados en las columnas recien creadas (sucursal_id2)\n",
    "sucursal_id2_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id2_dtypes[x] = set()\n",
    "    for y in ps_2020[x].sucursal_id2:\n",
    "        sucursal_id2_dtypes[x].add(type(y))\n",
    "for x in sucursal_id2_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\nTipos de datos encontrados en la columna 'sucursal_id2': {sucursal_id2_dtypes[x]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior chequeo podemos corroborar que la nueva columna creada ya no tiene valores del tipo 'datetime' ni 'float'.\n",
    "\n",
    "Ahora revisamos si los valores de las columnas 'sucursal_id' distintos de '0' hacen referencia a algún valor de la columna 'id' de la tabla 'sucursal'. Para esto empezamos por revisar si las longitudes de los strings se corresponden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Revisamos el formato del 'id' en la tabla sucursal a la que las columnas 'precio.sucursal_id' harán referencia\n",
    "# Para esto vemos primero los tipos de dato almacenados en esta columna\n",
    "sid_dtypes = set()\n",
    "for x in dims['sucursal'].id:\n",
    "    sid_dtypes.add(type(x))\n",
    "for x in sid_dtypes:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {5, 6, 7, 8, 9, 10}\n"
     ]
    }
   ],
   "source": [
    "# Al confirmar que todos los valores de la columna 'id' en la tabla 'sucursal' son str, obtenemos la longitud de estos valores\n",
    "sid_lengths = set()\n",
    "\n",
    "for x in dims['sucursal'].id.unique():\n",
    "    sid_lengths.add(len(x))\n",
    "\n",
    "print(f\"En la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {sid_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "5: ['6-1-6', '5-1-5', '9-2-2', '6-2-2', '8-1-6']\n",
      "6: ['47-1-3', '9-1-51', '6-1-11', '10-1-5', '7-1-14']\n",
      "7: ['2-1-204', '15-1-52', '2-1-264', '9-1-887', '9-1-631']\n",
      "8: ['15-1-107', '15-1-183', '10-3-662', '15-1-132', '10-3-538']\n",
      "9: ['11-4-1045', '15-1-8004', '11-2-1080', '15-1-1072', '15-1-5251']\n",
      "10: ['19-1-00421', '19-1-02460', '19-1-02626', '19-1-03228', '19-1-01641']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos ahora en qué consisten las diferencias de los códigos de distintas longitudes\n",
    "sid_lengths_examples = {}\n",
    "for x in sid_lengths:\n",
    "    sid_lengths_examples[str(x)] = []\n",
    "for x in dims['sucursal'].id:\n",
    "    len_x = str(len(x))\n",
    "    sid_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\nAlgunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in sid_lengths_examples:\n",
    "    print(f'{x}: {sample(sid_lengths_examples[x],5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que para todos las longitudes de los códigos, la estructura de estos consiste en 3 números separados por guiones.\n",
    "\n",
    "Cabe destacar que en los códigos más largos (de 10 caracteres) el tercer número parece estar precedido por ceros a la izquierda que, de ser ignorados, podrían hacer que el código se igual a uno de 9 u 8 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'sucursal': 2333\n",
      "Cantidad de valores únicos en la columna 'id' original: 2333\n",
      "\n",
      "• Los valores originales de la columna 'id' son únicos por registro: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que los valores de 'id' en el DataFrame 'sucursal' sean únicos por registro\n",
    "tot_reg_sucursal = len(dims['sucursal'])\n",
    "id_uniq_sucursal = dims['sucursal'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'sucursal': {tot_reg_sucursal}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' original: {id_uniq_sucursal}\")\n",
    "print(f\"\\n• Los valores originales de la columna 'id' son únicos por registro: {tot_reg_sucursal==id_uniq_sucursal}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Total de registros en el DataFrame 'sucursal': 2333\n",
      "• Total de valores únicos en la columna 'id' del DataFrame 'sucursal': 2333\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v3' (tomando únicamente el último número de 'id') del DataFrame 'sucursal':\n",
      "1162\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v1_v3' (tomando la combinación del primer y el último número de 'id') del DataFrame 'sucursal':\n",
      "2323\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v2_v3' (tomando la combinación del segundo y el último número de 'id') del DataFrame 'sucursal':\n",
      "1620\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si podemos tomar el último de los numeros de la columna 'id' (sid_v3) en el DataFrame 'sucursal' para identificar los registros de manera única\n",
    "# O bien la combinación del último valor con el primero (sid_v1_v3) o con el segundo (sid_v2_v3)\n",
    "tot_reg_sucursal = dims['sucursal'].shape[0]\n",
    "sid_v3 = []\n",
    "sid_v1_v3 = []\n",
    "sid_v2_v3 = []\n",
    "for x in dims['sucursal'].id:\n",
    "    sid_split = x.split('-')\n",
    "    sid_v3.append(sid_split[2])\n",
    "    sid_v1_v3.append(sid_split[0]+sid_split[2])\n",
    "    sid_v2_v3.append(sid_split[1]+sid_split[2])\n",
    "sid_v3_Srs = pd.Series(sid_v3)\n",
    "sid_v1_v3_Srs = pd.Series(sid_v1_v3)\n",
    "sid_v2_v3_Srs = pd.Series(sid_v2_v3)\n",
    "\n",
    "print(f\"• Total de registros en el DataFrame 'sucursal': {tot_reg_sucursal}\")\n",
    "print(f\"• Total de valores únicos en la columna 'id' del DataFrame 'sucursal': {len(dims['sucursal'].id.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v3' (tomando únicamente el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v3_Srs.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v1_v3' (tomando la combinación del primer y el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v1_v3_Srs.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v2_v3' (tomando la combinación del segundo y el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v2_v3_Srs.unique())}\")\n",
    "\n",
    "#print(sid_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna de las subcombinaciones de los números en el 'id' de 'sucursal' nos identifica los registros de manera única así que optaremos por conservar el 'id' como viene presentado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a revisar si todos los valores de la columna 'sucursal_id2' de las tablas 'precio' corresponden a un valor en la columna 'id' de 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'sucursal_id2' de las tablas 'precio' encontramos valores de las siguientes longitudes: {1, 5, 6, 7, 8, 9, 10}\n",
      "Los valores de un sólo caracter son: ['0', '0', '0']\n",
      "\n",
      "En la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {5, 6, 7, 8, 9, 10}\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si los valores de la columna 'sucursal_id2' diferentes de '0' hacen referencia a un valor de 'id' en el Dataframe 'sucursal'\n",
    "\n",
    "# Revisamos sus posibles longitudes\n",
    "suc_id2_lengths = set()\n",
    "\n",
    "suc_id2_1car = []\n",
    "\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].sucursal_id2.unique():\n",
    "        suc_id2_lengths.add(len(y))\n",
    "        if len(y) == 1:\n",
    "            suc_id2_1car.append(y)\n",
    "\n",
    "print(f\"En la columna 'sucursal_id2' de las tablas 'precio' encontramos valores de las siguientes longitudes: {suc_id2_lengths}\")\n",
    "print(f'Los valores de un sólo caracter son: {suc_id2_1car}')\n",
    "print(f\"\\nEn la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {sid_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los únicos valores de un solo caracter son los '0', las longitudes se corresponden. Pasamos a revisar si los valores de cada columna 'sucursal_id2' se encuentran en la columna 'id' del DataFrame 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2333\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista (sid) con los valores de la columna 'id' de la tabla sucursal\n",
    "sid = []\n",
    "for x in dims['sucursal'].id.unique():\n",
    "    sid.append(x)\n",
    "print(len(sid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "\tFound problems: False (0)\n",
      "• DataFrame 2020-04-19:\n",
      "\tFound problems: True (39)\n",
      "• DataFrame 2020-04-13:\n",
      "\tFound problems: True (6)\n",
      "• DataFrame 2020-05-03:\n",
      "\tFound problems: True (7)\n",
      "• DataFrame 2020-05-18:\n",
      "\tFound problems: True (4)\n",
      "• DataFrame 2020-06-18:\n",
      "\tFound problems: True (4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "El siguiente código revisa, para todas los DataFrames de precios, \n",
    "si los valores de 'sucursal_id2' se encuentran en la lista 'sid' recién creada,\n",
    "o si por el contrario, tenemos valores problemáticos de 'sucursal_id2' que\n",
    "no hacen referencia a algún valor de la lista 'sid'.\n",
    "\"\"\"\n",
    "\n",
    "sid_checklist = {}\n",
    "sid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = ps_2020[x].shape[0]\n",
    "    sid_checklist[x] = False\n",
    "    sid_problems_found[x] = []\n",
    "    for y in ps_2020[x].sucursal_id2.unique():\n",
    "        if (y != '0'):\n",
    "            if y not in sid:\n",
    "                sid_checklist[x] = True\n",
    "                sid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (pos:{count}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "for x in sid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {sid_checklist[x]} ({len(sid_problems_found[x])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores problemáticos de 'sucursal_id' por DataFrame:\n",
      "\n",
      "• DataFrame 2020-04-26:\n",
      "[]\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "['10-1-2029', '9-2-1939', '25-1-2001', '13-1-1939', '13-1-1962', '6-1-2009', '6-2-2021', '10-1-2006', '10-1-2018', '18-1-2005', '5-1-2003', '7-1-1937', '7-1-1948', '10-1-1946', '10-1-2026', '10-1-1933', '10-1-1948', '10-1-1953', '10-1-1954', '10-1-1944', '13-1-1952', '14-1-2009', '6-1-2004', '6-2-2002', '10-1-1955', '9-2-1950', '6-1-2026', '20-1-2001', '17-1-263', '29-1-2007', '17-1-285', '22-1-2017', '3-1-1962', '7-1-1935', '12-1-1999', '29-1-2005', '17-1-101', '12-1-1940', '65-1-315']\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "['20-1-4', '17-1-254', '17-1-46', '17-1-252', '17-1-198', '17-1-178']\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "['17-1-7', '22-1-11', '65-1-317', '19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977']\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "['1-1-12', '17-1-165', '17-1-122', '22-1-23']\n",
      "\n",
      "• DataFrame 2020-06-18:\n",
      "['1-1-12', '17-1-165', '17-1-122', '22-1-23']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValores problemáticos de 'sucursal_id' por DataFrame:\")\n",
    "for x in sid_problems_found:\n",
    "    print(f'\\n• DataFrame {x}:\\n{sid_problems_found[x]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de productos a remplazar en los 6 DataFrames es de 134188, de un total de 2633311 (5.1%).\n",
      "Claves a remplazar:\n",
      "['10-1-2029', '9-2-1939', '25-1-2001', '13-1-1939', '13-1-1962', '6-1-2009', '6-2-2021', '10-1-2006', '10-1-2018', '18-1-2005', '5-1-2003', '7-1-1937', '7-1-1948', '10-1-1946', '10-1-2026', '10-1-1933', '10-1-1948', '10-1-1953', '10-1-1954', '10-1-1944', '13-1-1952', '14-1-2009', '6-1-2004', '6-2-2002', '10-1-1955', '9-2-1950', '6-1-2026', '20-1-2001', '17-1-263', '29-1-2007', '17-1-285', '22-1-2017', '3-1-1962', '7-1-1935', '12-1-1999', '29-1-2005', '17-1-101', '12-1-1940', '65-1-315', '20-1-4', '17-1-254', '17-1-46', '17-1-252', '17-1-198', '17-1-178', '17-1-7', '22-1-11', '65-1-317', '19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977', '1-1-12', '17-1-165', '17-1-122', '22-1-23', '1-1-12', '17-1-165', '17-1-122', '22-1-23']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cuántas apariciones tienen los valores problemáticos las columnas 'sucursal_id' en los DataFrames de 'precios'\n",
    "sid_a_remplazar = []\n",
    "for x in sid_problems_found:\n",
    "    for y in sid_problems_found[x]:\n",
    "        sid_a_remplazar.append(y)\n",
    "sid_ar_count = 0\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].sucursal_id2:\n",
    "        if y in sid_a_remplazar:\n",
    "            sid_ar_count += 1\n",
    "print(f'El total de productos a remplazar en los {len(ps_2020.keys())} DataFrames es de {sid_ar_count}, de un total de {tot_reg} ({round(100*(sid_ar_count/tot_reg),2)}%).')\n",
    "print('Claves a remplazar:')\n",
    "print(sid_a_remplazar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos una cantidad importante de registros problemáticos buscaremos si algunos de los códigos tienen un problema de formato.\n",
    "\n",
    "En específico, si al último de los 3 números separados por guiones que conforma el id le hace falta uno o dos '0' al comienzo, como anteriormente habíamos visto que estaban algunos de los códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "5: ['7-1-3', '7-1-5', '5-1-6', '3-1-2', '9-2-1']\n",
      "6: ['7-1-37', '14-1-3', '9-2-54', '14-1-4', '18-1-8']\n",
      "7: ['9-1-408', '2-3-248', '9-1-170', '12-1-38', '15-1-60']\n",
      "8: ['10-3-324', '3-1-1158', '10-3-475', '15-1-276', '15-1-463']\n",
      "9: ['23-1-6208', '11-2-1038', '23-1-6215', '15-1-1092', '23-1-6216']\n",
      "10: ['19-1-01641', '19-1-01702', '19-1-03228', '19-1-02697', '19-1-00421']\n",
      "\n",
      "Clasificación de los valores de 'sucursal_id' a remplazar (sidar) (longitud: valores):\n",
      "\n",
      "6: ['20-1-4', '17-1-7', '1-1-12', '1-1-12']\n",
      "7: ['17-1-46', '22-1-11', '22-1-23', '22-1-23']\n",
      "8: ['9-2-1939', '6-1-2009', '6-2-2021', '5-1-2003', '7-1-1937', '7-1-1948', '6-1-2004', '6-2-2002', '9-2-1950', '6-1-2026', '17-1-263', '17-1-285', '3-1-1962', '7-1-1935', '17-1-101', '65-1-315', '17-1-254', '17-1-252', '17-1-198', '17-1-178', '65-1-317', '17-1-165', '17-1-122', '17-1-165', '17-1-122']\n",
      "9: ['10-1-2029', '25-1-2001', '13-1-1939', '13-1-1962', '10-1-2006', '10-1-2018', '18-1-2005', '10-1-1946', '10-1-2026', '10-1-1933', '10-1-1948', '10-1-1953', '10-1-1954', '10-1-1944', '13-1-1952', '14-1-2009', '10-1-1955', '20-1-2001', '29-1-2007', '22-1-2017', '12-1-1999', '29-1-2005', '12-1-1940']\n",
      "10: ['19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977']\n"
     ]
    }
   ],
   "source": [
    "# Comparamos los códigos de sucursal_id problemáticos vs los ejemplos de valores de diferentes longitudes en la columna 'id' de sucursal\n",
    "sidar_lengths = set()\n",
    "for x in sid_a_remplazar:\n",
    "    sidar_lengths.add(len(x))\n",
    "\n",
    "sidar_lengths_examples = {}\n",
    "for x in sidar_lengths:\n",
    "    sidar_lengths_examples[str(x)] = []\n",
    "for x in sid_a_remplazar:\n",
    "    len_x = str(len(x))\n",
    "    sidar_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\nAlgunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in sid_lengths_examples:\n",
    "    print(f'{x}: {sample(sid_lengths_examples[x],5)}')\n",
    "\n",
    "print(\"\\nClasificación de los valores de 'sucursal_id' a remplazar (sidar) (longitud: valores):\\n\")\n",
    "for x in sidar_lengths_examples:\n",
    "    print(f'{x}: {sidar_lengths_examples[x]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregaremos a los valores de 'sid_a_remplazar' que tengan 9 dígitos un 0 a la izquierda del tercer número para ver si de esta manera aparecen en la columna 'id' de la tabla 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-1-02029', '9-2-1939', '25-1-02001', '13-1-01939', '13-1-01962', '6-1-2009', '6-2-2021', '10-1-02006', '10-1-02018', '18-1-02005', '5-1-2003', '7-1-1937', '7-1-1948', '10-1-01946', '10-1-02026', '10-1-01933', '10-1-01948', '10-1-01953', '10-1-01954', '10-1-01944', '13-1-01952', '14-1-02009', '6-1-2004', '6-2-2002', '10-1-01955', '9-2-1950', '6-1-2026', '20-1-02001', '17-1-263', '29-1-02007', '17-1-285', '22-1-02017', '3-1-1962', '7-1-1935', '12-1-01999', '29-1-02005', '17-1-101', '12-1-01940', '65-1-315', '20-1-4', '17-1-254', '17-1-46', '17-1-252', '17-1-198', '17-1-178', '17-1-7', '22-1-11', '65-1-317', '19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977', '1-1-12', '17-1-165', '17-1-122', '22-1-23', '1-1-12', '17-1-165', '17-1-122', '22-1-23']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# Creamos la nueva lista de códigos\n",
    "sidar_new = []\n",
    "for x in sid_a_remplazar:\n",
    "    if len(x) == 9:\n",
    "        split_sidar = x.split('-')\n",
    "        new_sid = split_sidar[0]+'-'+split_sidar[1]+'-0'+split_sidar[2]\n",
    "        sidar_new.append(new_sid)\n",
    "    else:\n",
    "        sidar_new.append(x)\n",
    "print(sidar_new)\n",
    "print(len(sidar_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8, 10, 6, 7}\n"
     ]
    }
   ],
   "source": [
    "# Corroboramos las longitudes de los nuevos códigos (ya no debe haber códigos de 9 caracteres)\n",
    "sidar_new_lengths = set()\n",
    "for x in sidar_new:\n",
    "    sidar_new_lengths.add(len(x))\n",
    "print(sidar_new_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un total de 0 de los nuevos códigos nos sirven para hacer referencia a algún valor de la columna 'id' de la tabla 'sucursal'\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cuántos de los nuevos códigos se encuentran en la columna 'id' de la tabla 'sucursal'\n",
    "good_new_sidar = 0\n",
    "for x in sidar_new:\n",
    "    if x in dims['sucursal'].id.unique():\n",
    "        good_new_sidar += 1\n",
    "print(f\"Un total de {good_new_sidar} de los nuevos códigos nos sirven para hacer referencia a algún valor de la columna 'id' de la tabla 'sucursal'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación de los códigos no nos sirvió para hacer las referencias a la tabla 'sucursal'.\n",
    "\n",
    "Optaremos por notificar de esta situación al cliente y transformar los valores problemáticos de las columnas 'sucursal_id2' a '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función para llevar a cabo la transformación\n",
    "def suc_id_problem_2_zero(registro):\n",
    "    if registro in sid_a_remplazar:\n",
    "        return '0'\n",
    "    else:\n",
    "        return registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos los datos problemáticos de sucursal_id2\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['sucursal_id_ok'] = ps_2020[x]['sucursal_id2'].apply(suc_id_problem_2_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora limpiaremos un poco las tablas *dimensión*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "      <th>categoria1</th>\n",
       "      <th>categoria2</th>\n",
       "      <th>categoria3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72033</th>\n",
       "      <td>9569753142128</td>\n",
       "      <td>DELI-SITAS</td>\n",
       "      <td>Milhojas Cobertura de Chocolate Blanco Deli-Si...</td>\n",
       "      <td>500.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72034</th>\n",
       "      <td>9795403001143</td>\n",
       "      <td>MAYO</td>\n",
       "      <td>Mini Pizzetas Mayo 12 Un</td>\n",
       "      <td>12.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72035</th>\n",
       "      <td>9990385651922</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Negro en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72036</th>\n",
       "      <td>9990385651939</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Verde en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72037</th>\n",
       "      <td>9990385651946</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Yerba Mate Aromatizada Lata Dana 150 Gr</td>\n",
       "      <td>150.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id        marca  \\\n",
       "72033  9569753142128  DELI-SITAS    \n",
       "72034  9795403001143         MAYO   \n",
       "72035  9990385651922         DANA   \n",
       "72036  9990385651939         DANA   \n",
       "72037  9990385651946         DANA   \n",
       "\n",
       "                                                  nombre presentacion  \\\n",
       "72033  Milhojas Cobertura de Chocolate Blanco Deli-Si...     500.0 gr   \n",
       "72034                           Mini Pizzetas Mayo 12 Un      12.0 un   \n",
       "72035                 Te Negro en Hebras Lata Dana 50 Gr      50.0 gr   \n",
       "72036                 Te Verde en Hebras Lata Dana 50 Gr      50.0 gr   \n",
       "72037            Yerba Mate Aromatizada Lata Dana 150 Gr     150.0 gr   \n",
       "\n",
       "      categoria1 categoria2 categoria3  \n",
       "72033       None       None       None  \n",
       "72034       None       None       None  \n",
       "72035       None       None       None  \n",
       "72036       None       None       None  \n",
       "72037       None       None       None  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto'].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borraremos las columnas de categoría de la tabla 'producto' pues no tenemos información para llenarlas. \n",
    "Se trato de buscar si había sido un problema al descomprimir el archivo .parquet pero en todos los visualizadores de archivos parquet en línea utilizados para ver las columnas, éstas seguían saliendo sin datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims['producto_ok'] = dims['producto'].drop(['categoria1','categoria2','categoria3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72038 entries, 0 to 72037\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72038 non-null  object\n",
      " 1   marca         72036 non-null  object\n",
      " 2   nombre        72036 non-null  object\n",
      " 3   presentacion  72036 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dims['producto_ok'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que cada una de las columnas 'marca', 'nombre' y 'presentacion' tiene dos valores faltantes. Procedemos a llenarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims['producto_ok'].marca.fillna('SIN MARCA', inplace=True)\n",
    "dims['producto_ok'].nombre.fillna('SIN NOMBRE', inplace=True)\n",
    "dims['producto_ok'].presentacion.fillna('SIN DATO', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0000000000000\n",
       "marca               SIN MARCA\n",
       "nombre             SIN NOMBRE\n",
       "presentacion         SIN DATO\n",
       "Name: 72038, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos el registro que representa el id faltante en las tablas (producto_id='0')\n",
    "pid_err_val0 = ['0000000000000', 'SIN MARCA', 'SIN NOMBRE', 'SIN DATO']\n",
    "dims['producto_ok'].loc[len(dims['producto_ok'])] = pid_err_val0\n",
    "dims['producto_ok'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72034</th>\n",
       "      <td>9795403001143</td>\n",
       "      <td>MAYO</td>\n",
       "      <td>Mini Pizzetas Mayo 12 Un</td>\n",
       "      <td>12.0 un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72035</th>\n",
       "      <td>9990385651922</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Negro en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72036</th>\n",
       "      <td>9990385651939</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Verde en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72037</th>\n",
       "      <td>9990385651946</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Yerba Mate Aromatizada Lata Dana 150 Gr</td>\n",
       "      <td>150.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72038</th>\n",
       "      <td>0000000000000</td>\n",
       "      <td>SIN MARCA</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      marca                                   nombre  \\\n",
       "72034  9795403001143       MAYO                 Mini Pizzetas Mayo 12 Un   \n",
       "72035  9990385651922       DANA       Te Negro en Hebras Lata Dana 50 Gr   \n",
       "72036  9990385651939       DANA       Te Verde en Hebras Lata Dana 50 Gr   \n",
       "72037  9990385651946       DANA  Yerba Mate Aromatizada Lata Dana 150 Gr   \n",
       "72038  0000000000000  SIN MARCA                               SIN NOMBRE   \n",
       "\n",
       "      presentacion  \n",
       "72034      12.0 un  \n",
       "72035      50.0 gr  \n",
       "72036      50.0 gr  \n",
       "72037     150.0 gr  \n",
       "72038     SIN DATO  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto_ok'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72039 entries, 0 to 72038\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72039 non-null  object\n",
      " 1   marca         72039 non-null  object\n",
      " 2   nombre        72039 non-null  object\n",
      " 3   presentacion  72039 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dims['producto_ok'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    72039\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto_ok'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya no tenemos datos faltantes en la tabla 'producto_ok' y registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comercioId</th>\n",
       "      <th>banderaId</th>\n",
       "      <th>banderaDescripcion</th>\n",
       "      <th>comercioRazonSocial</th>\n",
       "      <th>provincia</th>\n",
       "      <th>localidad</th>\n",
       "      <th>direccion</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>sucursalNombre</th>\n",
       "      <th>sucursalTipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Super MAMI</td>\n",
       "      <td>Dinosaurio S.A.</td>\n",
       "      <td>AR-X</td>\n",
       "      <td>SALSIPUEDES</td>\n",
       "      <td>E53 1011 None</td>\n",
       "      <td>-31.126667</td>\n",
       "      <td>-64.295250</td>\n",
       "      <td>Super Mami 4</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-1-1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>Bernardo De Irigoyen 2647</td>\n",
       "      <td>-34.491345</td>\n",
       "      <td>-58.589025</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-1-10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Hurlingham</td>\n",
       "      <td>Av. Vergara 1910</td>\n",
       "      <td>-34.620610</td>\n",
       "      <td>-58.633769</td>\n",
       "      <td>Villa Tesei</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-1-11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Malvinas Argentinas</td>\n",
       "      <td>Av. Arturo Illia 3770</td>\n",
       "      <td>-34.528883</td>\n",
       "      <td>-58.701631</td>\n",
       "      <td>Malvinas Argentinas</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1-112</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-A</td>\n",
       "      <td>Salta</td>\n",
       "      <td>20 De Febrero 37</td>\n",
       "      <td>-24.789072</td>\n",
       "      <td>-65.413699</td>\n",
       "      <td>Salta</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10-1-12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Justo</td>\n",
       "      <td>Av. Don Bosco 2680</td>\n",
       "      <td>-34.664628</td>\n",
       "      <td>-58.597356</td>\n",
       "      <td>San Justo</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10-1-123</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-J</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Gral. Acha 32</td>\n",
       "      <td>-31.534016</td>\n",
       "      <td>-68.524744</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10-1-128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-U</td>\n",
       "      <td>Comodoro Rivadavia</td>\n",
       "      <td>Pellegrini 851</td>\n",
       "      <td>-45.861562</td>\n",
       "      <td>-67.479968</td>\n",
       "      <td>Comodoro Rivadavia</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10-1-136</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-R</td>\n",
       "      <td>General Roca</td>\n",
       "      <td>25 De Mayo 622</td>\n",
       "      <td>-39.030326</td>\n",
       "      <td>-67.573775</td>\n",
       "      <td>General Roca</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-1-139</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Olavarría</td>\n",
       "      <td>Rivadavia 2846</td>\n",
       "      <td>-36.893694</td>\n",
       "      <td>-60.321650</td>\n",
       "      <td>Olavarría</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10-1-142</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-V</td>\n",
       "      <td>Río Grande</td>\n",
       "      <td>Av. San Martín 685</td>\n",
       "      <td>-53.785009</td>\n",
       "      <td>-67.702990</td>\n",
       "      <td>Río Grande</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10-1-147</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-L</td>\n",
       "      <td>Santa Rosa</td>\n",
       "      <td>Avellaneda 151</td>\n",
       "      <td>-36.618338</td>\n",
       "      <td>-64.291249</td>\n",
       "      <td>Santa Rosa</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10-1-149</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-R</td>\n",
       "      <td>Bariloche</td>\n",
       "      <td>Moreno 909</td>\n",
       "      <td>-41.136201</td>\n",
       "      <td>-71.296792</td>\n",
       "      <td>Bariloche</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10-1-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Martín</td>\n",
       "      <td>Av. San Martín 420</td>\n",
       "      <td>-34.586322</td>\n",
       "      <td>-58.519449</td>\n",
       "      <td>San Martín</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10-1-156</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Nicolás</td>\n",
       "      <td>Bartolomé Mitre 264</td>\n",
       "      <td>-33.331816</td>\n",
       "      <td>-60.220188</td>\n",
       "      <td>San Nicolás</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  comercioId  banderaId      banderaDescripcion  \\\n",
       "0      1-1-7           1          1              Super MAMI   \n",
       "1     10-1-1          10          1  Hipermercado Carrefour   \n",
       "2    10-1-10          10          1  Hipermercado Carrefour   \n",
       "3    10-1-11          10          1  Hipermercado Carrefour   \n",
       "4   10-1-112          10          1  Hipermercado Carrefour   \n",
       "5    10-1-12          10          1  Hipermercado Carrefour   \n",
       "6   10-1-123          10          1  Hipermercado Carrefour   \n",
       "7   10-1-128          10          1  Hipermercado Carrefour   \n",
       "8   10-1-136          10          1  Hipermercado Carrefour   \n",
       "9   10-1-139          10          1  Hipermercado Carrefour   \n",
       "10  10-1-142          10          1  Hipermercado Carrefour   \n",
       "11  10-1-147          10          1  Hipermercado Carrefour   \n",
       "12  10-1-149          10          1  Hipermercado Carrefour   \n",
       "13   10-1-15          10          1  Hipermercado Carrefour   \n",
       "14  10-1-156          10          1  Hipermercado Carrefour   \n",
       "\n",
       "   comercioRazonSocial provincia            localidad  \\\n",
       "0      Dinosaurio S.A.      AR-X          SALSIPUEDES   \n",
       "1             INC S.A.      AR-B           San Isidro   \n",
       "2             INC S.A.      AR-B           Hurlingham   \n",
       "3             INC S.A.      AR-B  Malvinas Argentinas   \n",
       "4             INC S.A.      AR-A                Salta   \n",
       "5             INC S.A.      AR-B            San Justo   \n",
       "6             INC S.A.      AR-J             San Juan   \n",
       "7             INC S.A.      AR-U   Comodoro Rivadavia   \n",
       "8             INC S.A.      AR-R         General Roca   \n",
       "9             INC S.A.      AR-B            Olavarría   \n",
       "10            INC S.A.      AR-V           Río Grande   \n",
       "11            INC S.A.      AR-L           Santa Rosa   \n",
       "12            INC S.A.      AR-R            Bariloche   \n",
       "13            INC S.A.      AR-B           San Martín   \n",
       "14            INC S.A.      AR-B          San Nicolás   \n",
       "\n",
       "                    direccion        lat        lng       sucursalNombre  \\\n",
       "0               E53 1011 None -31.126667 -64.295250         Super Mami 4   \n",
       "1   Bernardo De Irigoyen 2647 -34.491345 -58.589025           San Isidro   \n",
       "2            Av. Vergara 1910 -34.620610 -58.633769          Villa Tesei   \n",
       "3       Av. Arturo Illia 3770 -34.528883 -58.701631  Malvinas Argentinas   \n",
       "4            20 De Febrero 37 -24.789072 -65.413699                Salta   \n",
       "5          Av. Don Bosco 2680 -34.664628 -58.597356            San Justo   \n",
       "6               Gral. Acha 32 -31.534016 -68.524744             San Juan   \n",
       "7              Pellegrini 851 -45.861562 -67.479968   Comodoro Rivadavia   \n",
       "8              25 De Mayo 622 -39.030326 -67.573775         General Roca   \n",
       "9              Rivadavia 2846 -36.893694 -60.321650            Olavarría   \n",
       "10         Av. San Martín 685 -53.785009 -67.702990           Río Grande   \n",
       "11             Avellaneda 151 -36.618338 -64.291249           Santa Rosa   \n",
       "12                 Moreno 909 -41.136201 -71.296792            Bariloche   \n",
       "13         Av. San Martín 420 -34.586322 -58.519449           San Martín   \n",
       "14        Bartolomé Mitre 264 -33.331816 -60.220188          San Nicolás   \n",
       "\n",
       "    sucursalTipo  \n",
       "0   Hipermercado  \n",
       "1   Hipermercado  \n",
       "2   Hipermercado  \n",
       "3   Hipermercado  \n",
       "4   Hipermercado  \n",
       "5   Hipermercado  \n",
       "6   Supermercado  \n",
       "7   Hipermercado  \n",
       "8   Supermercado  \n",
       "9   Hipermercado  \n",
       "10  Supermercado  \n",
       "11  Hipermercado  \n",
       "12  Hipermercado  \n",
       "13  Hipermercado  \n",
       "14  Hipermercado  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['sucursal'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comercioId</th>\n",
       "      <th>banderaId</th>\n",
       "      <th>banderaDescripcion</th>\n",
       "      <th>comercioRazonSocial</th>\n",
       "      <th>provincia</th>\n",
       "      <th>localidad</th>\n",
       "      <th>direccion</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>sucursalNombre</th>\n",
       "      <th>sucursalTipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>9-3-5961</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-C</td>\n",
       "      <td>CIUDAD AUTONOMA BUENOS AIRES</td>\n",
       "      <td>Avenida Santa Fe 4950</td>\n",
       "      <td>-34.5772</td>\n",
       "      <td>-58.4300</td>\n",
       "      <td>Jumbo Av. Santa Fé</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>9-3-628</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>SAN FERNANDO</td>\n",
       "      <td>Avenida Del Libertador Gral San Martin 2271</td>\n",
       "      <td>-34.4469</td>\n",
       "      <td>-58.5457</td>\n",
       "      <td>Jumbo San Fernando</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>9-3-662</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>DEL VISO</td>\n",
       "      <td>Acceso Pilar Norte 0</td>\n",
       "      <td>-34.4360</td>\n",
       "      <td>-58.8080</td>\n",
       "      <td>Jumbo Paseo del Pilar</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  comercioId  banderaId banderaDescripcion  \\\n",
       "2330  9-3-5961           9          3              Jumbo   \n",
       "2331   9-3-628           9          3              Jumbo   \n",
       "2332   9-3-662           9          3              Jumbo   \n",
       "2333         0           0          0           SIN DATO   \n",
       "2334         1           0          0           SIN DATO   \n",
       "\n",
       "              comercioRazonSocial provincia                     localidad  \\\n",
       "2330  Jumbo Retail Argentina S.A.      AR-C  CIUDAD AUTONOMA BUENOS AIRES   \n",
       "2331  Jumbo Retail Argentina S.A.      AR-B                  SAN FERNANDO   \n",
       "2332  Jumbo Retail Argentina S.A.      AR-B                      DEL VISO   \n",
       "2333                     SIN DATO  SIN DATO                      SIN DATO   \n",
       "2334                     SIN DATO  SIN DATO                      SIN DATO   \n",
       "\n",
       "                                        direccion      lat      lng  \\\n",
       "2330                        Avenida Santa Fe 4950 -34.5772 -58.4300   \n",
       "2331  Avenida Del Libertador Gral San Martin 2271 -34.4469 -58.5457   \n",
       "2332                         Acceso Pilar Norte 0 -34.4360 -58.8080   \n",
       "2333                                     SIN DATO   0.0000   0.0000   \n",
       "2334                                     SIN DATO   0.0000   0.0000   \n",
       "\n",
       "             sucursalNombre  sucursalTipo  \n",
       "2330     Jumbo Av. Santa Fé  Supermercado  \n",
       "2331     Jumbo San Fernando  Supermercado  \n",
       "2332  Jumbo Paseo del Pilar  Supermercado  \n",
       "2333             SIN NOMBRE      SIN DATO  \n",
       "2334             SIN NOMBRE      SIN DATO  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos los registros para que los valores faltantes y errados de la columna 'sucursal_id' tengan una referencia\n",
    "sid_err_val0 = ['0',0,0,'SIN DATO','SIN DATO','SIN DATO','SIN DATO','SIN DATO',0,0,'SIN NOMBRE','SIN DATO']\n",
    "sid_err_val1 = ['1',0,0,'SIN DATO','SIN DATO','SIN DATO','SIN DATO','SIN DATO',0,0,'SIN NOMBRE','SIN DATO']\n",
    "\n",
    "dims['sucursal'].loc[len(dims['sucursal'])] = sid_err_val0\n",
    "dims['sucursal'].loc[len(dims['sucursal'])] = sid_err_val1\n",
    "\n",
    "dims['sucursal'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2335 entries, 0 to 2334\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2335 non-null   object \n",
      " 1   comercioId           2335 non-null   int64  \n",
      " 2   banderaId            2335 non-null   int64  \n",
      " 3   banderaDescripcion   2335 non-null   object \n",
      " 4   comercioRazonSocial  2335 non-null   object \n",
      " 5   provincia            2335 non-null   object \n",
      " 6   localidad            2335 non-null   object \n",
      " 7   direccion            2335 non-null   object \n",
      " 8   lat                  2335 non-null   float64\n",
      " 9   lng                  2335 non-null   float64\n",
      " 10  sucursalNombre       2335 non-null   object \n",
      " 11  sucursalTipo         2335 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 237.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dims['sucursal'].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['sucursal'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la tabla 'sucursal' tampoco tiene valores faltantes ni registros duplicados así que procedemos a alistar las tablas para subirlas a la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando los CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo llevado a cabo esta última transformación podemos seguir a concatenar las tablas de 'precios', crando primero una columna con la fecha de los registros para no perder la separación que tenían las tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26:\n",
      "False    474692\n",
      "dtype: int64\n",
      "2020-04-19:\n",
      "False    458543\n",
      "dtype: int64\n",
      "2020-04-13:\n",
      "False    472134\n",
      "dtype: int64\n",
      "2020-05-03:\n",
      "False    397734\n",
      "dtype: int64\n",
      "2020-05-18:\n",
      "False    415104\n",
      "dtype: int64\n",
      "2020-06-18:\n",
      "False    415104\n",
      "dtype: int64\n",
      "(2633311, 11) Index(['precio', 'producto_id', 'sucursal_id', 'fecha', 'precio_ok',\n",
      "       'producto_id2', 'producto_id3', 'producto_id4', 'producto_id_ok',\n",
      "       'sucursal_id2', 'sucursal_id_ok'],\n",
      "      dtype='object')\n",
      "ps_2020_ok:\n",
      "False    2633311\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenamos las tablas de precios en un solo DataFrame (ps_2020_ok)\n",
    "dfs_to_concat = []\n",
    "for x in ps_2020:\n",
    "    print(f'{x}:\\n{ps_2020[x].duplicated().value_counts()}')\n",
    "    dfs_to_concat.append(ps_2020[x])\n",
    "#print(len(dfs_to_concat))\n",
    "ps_2020_ok = pd.concat(dfs_to_concat, axis=0)\n",
    "\n",
    "print(ps_2020_ok.shape, ps_2020_ok.columns)\n",
    "print(f'ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2633311, 4) Index(['fecha', 'precio_ok', 'producto_id_ok', 'sucursal_id_ok'], dtype='object')\n",
      "Valores duplicados en ps_2020_ok:\n",
      "False    2623916\n",
      "True        9395\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos las columnas que no necesitamos del DataFrame final\n",
    "ps_2020_ok.drop(['producto_id','producto_id2','producto_id3','producto_id4','sucursal_id','sucursal_id2','precio',], axis=1, inplace=True)\n",
    "print(ps_2020_ok.shape, ps_2020_ok.columns)\n",
    "print(f'Valores duplicados en ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está muy claro por qué quedan valores repetidos tras eliminar las columnas, pero al ser tan pocos con respecto al total, los eliminaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en ps_2020_ok:\n",
      "False    2623916\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ps_2020_ok.drop_duplicates(inplace=True)\n",
    "print(f'Valores duplicados en ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['precio_ok', 'producto_id_ok', 'sucursal_id_ok', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos el orden de las columnas\n",
    "cols = ['precio_ok', 'producto_id_ok', 'sucursal_id_ok', 'fecha']\n",
    "ps_2020_ok = ps_2020_ok[cols]\n",
    "print(ps_2020_ok.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Renombramos las columnas\n",
    "ps_2020_ok.rename(columns = {'precio_ok':'precio','producto_id_ok':'producto_id','sucursal_id_ok':'sucursal_id'}, inplace = True)\n",
    "print(ps_2020_ok.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los DataFrames a exportar en un diccionario\n",
    "df_2_export = {'precio_semanal_2020':ps_2020_ok, 'producto': dims['producto_ok'], 'sucursal':dims['sucursal']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----precio_semanal_2020-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2623916 entries, 0 to 415292\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   precio       float64       \n",
      " 1   producto_id  object        \n",
      " 2   sucursal_id  object        \n",
      " 3   fecha        datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 100.1+ MB\n",
      "None\n",
      "-----producto-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72039 entries, 0 to 72038\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72039 non-null  object\n",
      " 1   marca         72039 non-null  object\n",
      " 2   nombre        72039 non-null  object\n",
      " 3   presentacion  72039 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "-----sucursal-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2335 entries, 0 to 2334\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2335 non-null   object \n",
      " 1   comercioId           2335 non-null   int64  \n",
      " 2   banderaId            2335 non-null   int64  \n",
      " 3   banderaDescripcion   2335 non-null   object \n",
      " 4   comercioRazonSocial  2335 non-null   object \n",
      " 5   provincia            2335 non-null   object \n",
      " 6   localidad            2335 non-null   object \n",
      " 7   direccion            2335 non-null   object \n",
      " 8   lat                  2335 non-null   float64\n",
      " 9   lng                  2335 non-null   float64\n",
      " 10  sucursalNombre       2335 non-null   object \n",
      " 11  sucursalTipo         2335 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 237.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la información de los DataFrames finales\n",
    "for x in df_2_export:\n",
    "    print(f'-----{x}-----')\n",
    "    print(df_2_export[x].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----DataFrame: precio_semanal_2020-----\n",
      "Shape: (2623916, 4)\n",
      "\n",
      "• Valores nulos:\n",
      "precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "fecha          0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2623916\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: producto-----\n",
      "Shape: (72039, 4)\n",
      "\n",
      "• Valores nulos:\n",
      "id              0\n",
      "marca           0\n",
      "nombre          0\n",
      "presentacion    0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    72039\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: sucursal-----\n",
      "Shape: (2335, 12)\n",
      "\n",
      "• Valores nulos:\n",
      "id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2335\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos la información de los DataFrames finales\n",
    "for x in df_2_export:\n",
    "    print(f'\\n-----DataFrame: {x}-----\\nShape: {df_2_export[x].shape}\\n\\n• Valores nulos:\\n{df_2_export[x].isnull().sum()}\\n\\n• Registros duplicados:\\n{df_2_export[x].duplicated().value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- CARGA ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la conección a la base de datos y el cursor para hacer los queries\n",
    "conn = db.connect(\"sqlite.db\")\n",
    "cn = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x23cd80006c0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos las tablas en la base de datos\n",
    "cn.execute(\"CREATE TABLE IF NOT EXISTS producto (id VARCHAR(24) NOT NULL UNIQUE PRIMARY KEY, marca VARCHAR(24), nombre VARCHAR(24), presentacion VARCHAR(8));\")\n",
    "cn.execute(\"CREATE TABLE IF NOT EXISTS sucursal (id VARCHAR(16) NOT NULL UNIQUE PRIMARY KEY, comercio_id SMALLINT, bandera_id SMALLINT, bandera_descripcion VARCHAR(128), comerio_razon_social VARCHAR(128), provincia VARCHAR(32), localidad VARCHAR(32), direccion VARCHAR(128), lat INT, lng INT, sucursal_nombre VARCHAR(48), sucursal_tipo VARCHAR(16));\")\n",
    "cn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "cn.execute(\"CREATE TABLE IF NOT EXISTS precio_semanal_2020 (precio FLOAT, producto_id VARCHAR(24), sucursal_id VARCHAR(16), fecha TEXT, FOREIGN KEY(producto_id) REFERENCES producto(id),FOREIGN KEY(sucursal_id) REFERENCES sucursal(id));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x23cd80006c0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Botones de emergencia xD\n",
    "'''\n",
    "cn.execute(\"DROP TABLE IF EXISTS producto;\")\n",
    "cn.execute(\"DROP TABLE IF EXISTS sucursal;\")\n",
    "cn.execute(\"DROP TABLE IF EXISTS precio_semanal_2020;\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poblamos las tablas con los datos de nuestros DataFrames de pandas \n",
    "for x in df_2_export:\n",
    "    df_2_export[x].to_sql(x, conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG(p.precio)</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202.128867</td>\n",
       "      <td>9-1-688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVG(p.precio)       id\n",
       "0     202.128867  9-1-688"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el query\n",
    "query = \"\"\"\n",
    "            SELECT   AVG(p.precio),\n",
    "                     s.id \n",
    "            FROM     precio_semanal_2020 p \n",
    "            JOIN     sucursal s \n",
    "            ON       p.sucursal_id=s.id \n",
    "            GROUP BY s.id \n",
    "            HAVING   s.id='9-1-688';\n",
    "        \"\"\"\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos commit a los cambios realizados en la base de datos\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos el cursor y la conección\n",
    "cn.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
