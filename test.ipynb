{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Puntos a tener en cuenta:\n",
    "\n",
    "Los productos tienen más de un código?\n",
    "\n",
    "py arrow -> read parquet\n",
    "\n",
    "el script debe poder recibir nuevas tablas y arrojar un resultado unificado.\n",
    "La carga incremental debe estar administrada por el mismo script.\n",
    "\n",
    "al data engineer no le importan los outliers, eso es cuestión del analista\n",
    "\n",
    "DER: Diagrama de Entidad Relacional\n",
    "\n",
    "La carga: una carga más.. No debe relacionarse al tiempo\n",
    "\n",
    "print shape info() isnull().sum() duplicated().value_counts()\n",
    "\n",
    "precios en excel tienen un decimal corrido\n",
    "\n",
    "producto tiene items con múltiples IDE y también IDE's que se repiten en múltiples productos\n",
    "\n",
    "Los problemas que no se alcancen a solucionar hay que señalarlos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos importando las librerías que usaremos para la limpieza de los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los DataFrames en pandas\n",
    "Importamos los datasets de diferentes formatos a DataFrames de pandas de manera automatizada, organizándolos en un diccionario para facilitar su acceso y limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precios_semanas_20200419_20200426.xlsx', 'precios_semana_20200413.csv', 'precios_semana_20200503.json', 'precios_semana_20200518.txt', 'producto.parquet', 'sucursal.csv']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos una lista de los archivos dentro del directorio 'datasets'\n",
    "file_names = os.listdir('.\\datasets')\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: precios_semanas_20200419_20200426.xlsx\n",
      "Value: ['precios_semanas_20200419_20200426', 'xlsx']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200413.csv\n",
      "Value: ['precios_semana_20200413', 'csv']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200503.json\n",
      "Value: ['precios_semana_20200503', 'json']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200518.txt\n",
      "Value: ['precios_semana_20200518', 'txt']\n",
      "\n",
      "\n",
      "Key: producto.parquet\n",
      "Value: ['producto', 'parquet']\n",
      "\n",
      "\n",
      "Key: sucursal.csv\n",
      "Value: ['sucursal', 'csv']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un diccionario con los nombres de cada archivo y su extensión\n",
    "datasets_extensions = {}\n",
    "for x in file_names:\n",
    "    datasets_extensions[x] = x.split('.')\n",
    "\n",
    "for x in datasets_extensions:\n",
    "    print(f'\\nKey: {x}\\nValue: {datasets_extensions[x]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos las extensiones y los nombres de los archivos para importar los datasets en objetos 'DataFrame' de pandas.\n",
    "\n",
    "Habiendo estudiado un poco la naturaleza de los datasets antes de importarlos, se pudo observar que los registros\n",
    "o *tablas de hecho* son las que llevan por nombre 'precios_...', mientras que las *dimensiones* son los datasets de \n",
    "'producto' y 'sucursal', pues proveen información adicional a las primeras tablas.\n",
    "\n",
    "Así, los datasets de precios serán organizados en el diccionario 'ps_2020' (precio semanal 2020) y los otros dos en el \n",
    "diccionario 'dims' (dimensiones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los diccionarios y automatizamos la importación de los archivos contenidos en el directorio 'datasets'\n",
    "ps_2020 = {}\n",
    "dims = {}\n",
    "for x in datasets_extensions:\n",
    "    path = f'datasets/{x}'\n",
    "    if x[:7] == 'precios':\n",
    "        if datasets_extensions[x][1] in ['xlsx', 'xls']:\n",
    "            xl_dict = pd.read_excel(path, sheet_name=None, date_parser=None)\n",
    "            for sheet in xl_dict:\n",
    "                name = f'{sheet[-8:-4]}-{sheet[-4:-2]}-{sheet[-2:]}'\n",
    "                ps_2020[name] = pd.DataFrame(xl_dict[sheet])\n",
    "        else:\n",
    "            name = f'{datasets_extensions[x][0][-8:-4]}-{datasets_extensions[x][0][-4:-2]}-{datasets_extensions[x][0][-2:]}'\n",
    "            if datasets_extensions[x][1] == 'csv':\n",
    "                ps_2020[name] = pd.read_csv(path, encoding='UTF-16 LE')\n",
    "            elif datasets_extensions[x][1] == 'json':\n",
    "                ps_2020[name] = pd.read_json(path)\n",
    "            elif datasets_extensions[x][1] == 'txt':\n",
    "                ps_2020[name] = pd.read_csv(path, delimiter='|')\n",
    "    else:\n",
    "        name = datasets_extensions[x][0]\n",
    "        if datasets_extensions[x][1] == 'csv':\n",
    "            dims[name] = pd.read_csv(path)\n",
    "        elif datasets_extensions[x][1] == 'parquet':\n",
    "            dims[name] = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame: 2020-04-26\n",
      "• Shape: (474692, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-19\n",
      "• Shape: (458543, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-13\n",
      "• Shape: (472134, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-03\n",
      "• Shape: (397734, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-18\n",
      "• Shape: (415104, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: producto\n",
      "• Shape: (72038, 7)\n",
      "• Columnas: Index(['id', 'marca', 'nombre', 'presentacion', 'categoria1', 'categoria2',\n",
      "       'categoria3'],\n",
      "      dtype='object')\n",
      "\n",
      "• DataFrame: sucursal\n",
      "• Shape: (2333, 12)\n",
      "• Columnas: Index(['id', 'comercioId', 'banderaId', 'banderaDescripcion',\n",
      "       'comercioRazonSocial', 'provincia', 'localidad', 'direccion', 'lat',\n",
      "       'lng', 'sucursalNombre', 'sucursalTipo'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ps_2020:\n",
    "    print(f'• DataFrame: {x}\\n• Shape: {ps_2020[x].shape}\\n• Columnas: {ps_2020[x].columns}\\n')\n",
    "for x in dims:\n",
    "    print(f'• DataFrame: {x}\\n• Shape: {dims[x].shape}\\n• Columnas: {dims[x].columns}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de limpieza de datos\n",
    "Una vez creadas las tablas podemos empezar el trabajo de limpieza de los datos, comenzando por buscar los registros duplicados y valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------2020-04-26----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "----------------2020-04-19----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "----------------2020-04-13----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "----------------2020-05-03----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "----------------2020-05-18----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Organizamos las columnas de los dataframes para que coincidan entre sí y facilitar la visualización\n",
    "cols = ['precio', 'producto_id', 'sucursal_id']\n",
    "for x in ps_2020:\n",
    "    ps_2020[x] = ps_2020[x][cols]\n",
    "    print(f'----------------{x}----------------\\n{ps_2020[x].columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----DataFrame: 2020-04-26-----\n",
      "\n",
      "• Valores nulos:\n",
      "producto_id    9302\n",
      "sucursal_id       0\n",
      "precio            0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    474692\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-19-----\n",
      "\n",
      "• Valores nulos:\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "precio         0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    458543\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-13-----\n",
      "\n",
      "• Valores nulos:\n",
      "producto_id    3\n",
      "sucursal_id    3\n",
      "precio         0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    472134\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-03-----\n",
      "\n",
      "• Valores nulos:\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "precio         0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    397734\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-18-----\n",
      "\n",
      "• Valores nulos:\n",
      "producto_id    3\n",
      "sucursal_id    3\n",
      "precio         0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    415104\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos un ciclo para obtener la información de todos los DataFrames\n",
    "for x in ps_2020:\n",
    "    semana = ps_2020[x]\n",
    "    print(f'\\n-----DataFrame: {x}-----\\n\\n• Valores nulos:\\n{semana.isnull().sum()}\\n\\n• Registros duplicados:\\n{semana.duplicated().value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habiendo detectado registros duplicados procedemos a eliminarlos\n",
    "for x in ps_2020:\n",
    "    ps_2020[x].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DataFrame: 2020-04-26-----\n",
      "     precio  producto_id sucursal_id  precio2\n",
      "0     399.0       2288.0     2-1-092    399.0\n",
      "1     299.0       2288.0     2-1-206    299.0\n",
      "2     399.0       2288.0     2-2-241    399.0\n",
      "3   49999.0     205870.0     9-1-430  49999.0\n",
      "4   53999.0     205870.0       9-2-4  53999.0\n",
      "5   53999.0     205870.0    9-3-5218  53999.0\n",
      "6   58999.0     205894.0     9-1-430  58999.0\n",
      "7   18999.0     205955.0     9-1-430  18999.0\n",
      "8   10499.0     205979.0     9-1-430  10499.0\n",
      "9    2290.0     206020.0     9-1-430   2290.0\n",
      "10  27999.0     206044.0     9-1-430  27999.0\n",
      "11   2190.0     206044.0     9-1-691   2190.0\n",
      "12  22999.0     206051.0     9-1-430  22999.0\n",
      "13  45999.0     206105.0     9-1-430  45999.0\n",
      "14  38999.0     206136.0     9-1-430  38999.0\n",
      "-----DataFrame: 2020-04-19-----\n",
      "    precio producto_id          sucursal_id  precio2\n",
      "0    29.90        2288              2-1-184    29.90\n",
      "1    39.90        2288              2-1-206    39.90\n",
      "2   499.99      205870              9-1-430   499.99\n",
      "3   539.99      205870              9-2-107   539.99\n",
      "4   539.99      205870  5218-03-09 00:00:00   539.99\n",
      "5   589.99      205894              9-1-430   589.99\n",
      "6   189.99      205955              9-1-430   189.99\n",
      "7   104.99      205979              9-1-430   104.99\n",
      "8   229.00      206020              9-1-430   229.00\n",
      "9   279.99      206044              9-1-430   279.99\n",
      "10  229.99      206051              9-1-430   229.99\n",
      "11  459.99      206105              9-1-430   459.99\n",
      "12  389.99      206136              9-1-430   389.99\n",
      "13  299.99      206143              9-1-430   299.99\n",
      "14  339.99      206181              9-1-430   339.99\n",
      "-----DataFrame: 2020-04-13-----\n",
      "    precio    producto_id sucursal_id  precio2\n",
      "0    29.90  0000000001663     2-1-014    29.90\n",
      "1    29.90  0000000002288     2-1-032    29.90\n",
      "2    39.90  0000000002288     2-1-096    39.90\n",
      "3   499.99  0000000205870     9-1-686   499.99\n",
      "4   519.99  0000000205870     9-2-248   519.99\n",
      "5   539.99  0000000205870      9-2-42   539.99\n",
      "6   539.99  0000000205870     9-3-628   539.99\n",
      "7   589.99  0000000205894     9-1-686   589.99\n",
      "8   189.99  0000000205955     9-1-686   189.99\n",
      "9   104.99  0000000205979     9-1-686   104.99\n",
      "10  259.99  0000000206020     9-1-686   259.99\n",
      "11  279.99  0000000206044     9-1-686   279.99\n",
      "12  229.99  0000000206051     9-1-686   229.99\n",
      "13  459.99  0000000206105     9-1-686   459.99\n",
      "14  389.99  0000000206136     9-1-686   389.99\n",
      "-----DataFrame: 2020-05-03-----\n",
      "    precio    producto_id sucursal_id  precio2\n",
      "0     29.9  0000000002288     2-1-187    29.90\n",
      "1     39.9  0000000002288     2-3-247    39.90\n",
      "2   499.99  0000000205870     9-1-685   499.99\n",
      "3   539.99  0000000205870      9-2-22   539.99\n",
      "4   519.99  0000000205870      9-2-59   519.99\n",
      "5   539.99  0000000205870     9-3-138   539.99\n",
      "6   589.99  0000000205894     9-1-685   589.99\n",
      "7   189.99  0000000205955     9-1-685   189.99\n",
      "8   104.99  0000000205979     9-1-685   104.99\n",
      "9      229  0000000206020     9-1-685   229.00\n",
      "10  279.99  0000000206044     9-1-685   279.99\n",
      "11  229.99  0000000206051     9-1-685   229.99\n",
      "12  459.99  0000000206105     9-1-685   459.99\n",
      "13  389.99  0000000206136     9-1-685   389.99\n",
      "14  299.99  0000000206143     9-1-685   299.99\n",
      "-----DataFrame: 2020-05-18-----\n",
      "    precio    producto_id sucursal_id  precio2\n",
      "0    29.90  0000000002288     2-1-009    29.90\n",
      "1    32.90  0000000002288     2-1-037    32.90\n",
      "2    36.90  0000000002288     2-1-090    36.90\n",
      "3    39.90  0000000002288     2-3-247    39.90\n",
      "4   499.99  0000000205870     9-1-430   499.99\n",
      "5   539.99  0000000205870       9-2-4   539.99\n",
      "6   539.99  0000000205870    9-3-5205   539.99\n",
      "7   589.99  0000000205894     9-1-430   589.99\n",
      "8   189.99  0000000205955     9-1-430   189.99\n",
      "9   104.99  0000000205979     9-1-430   104.99\n",
      "10  259.99  0000000206020     9-1-430   259.99\n",
      "11  279.99  0000000206044     9-1-430   279.99\n",
      "12  229.99  0000000206051     9-1-430   229.99\n",
      "13  459.99  0000000206105     9-1-430   459.99\n",
      "14  389.99  0000000206136     9-1-430   389.99\n"
     ]
    }
   ],
   "source": [
    "# Ahora podemos generar una visualización preliminar de las tablas para continuar con el proceso de limpieza y poder lidiar con los valores nulos\n",
    "for x in ps_2020:\n",
    "    print(f'-----DataFrame: {x}-----\\n{ps_2020[x].head(15)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 474692 entries, 0 to 478908\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   precio       473053 non-null  float64\n",
      " 1   producto_id  465390 non-null  float64\n",
      " 2   sucursal_id  474692 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 14.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458543 entries, 0 to 458542\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   precio       456736 non-null  float64\n",
      " 1   producto_id  458543 non-null  object \n",
      " 2   sucursal_id  458543 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 14.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 472134 entries, 0 to 472165\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   precio       472133 non-null  float64\n",
      " 1   producto_id  472131 non-null  object \n",
      " 2   sucursal_id  472131 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 397734 entries, 0 to 397733\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   precio       397734 non-null  object\n",
      " 1   producto_id  397734 non-null  object\n",
      " 2   sucursal_id  397734 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 415104 entries, 0 to 415292\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   precio       413147 non-null  float64\n",
      " 1   producto_id  415101 non-null  object \n",
      " 2   sucursal_id  415101 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 12.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for x in ps_2020:\n",
    "    print(ps_2020[x].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Primeros problemas con el formato de los datos:\n",
    "Con la anterior visualización preliminar se pudieron ver tres cuestiones a tener en cuenta y que se abordarán a continuación:\n",
    "1) En uno de los DataFrames (2020-05-03), el tipo de data de la columna 'precio' no es *float64* como en los demás.\n",
    "2) El formato de la columna 'producto_id' es diferente en varios DataFrames.\n",
    "3) Algunos valores de la columna 'sucursal_id' de al menos la tabla '2020-04-19' son interpretados en como de tipo 'datetime'.\n",
    "4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) El tipo de data de la columna 'precio' no es *float64* en todos los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\n",
      "{\"<class 'str'>\", \"<class 'float'>\", \"<class 'int'>\"}\n",
      "\n",
      "• Valores que encontramos para los strings:\n",
      "{''}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ahora exploramos un poco los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "precio_dtype = set()\n",
    "strings = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if type(x) == str:\n",
    "        #print(x)\n",
    "        strings.add(x)\n",
    "    elif x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Valores que encontramos para los strings:\\n{strings}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### • Ya que detectamos que no hay registros en la columna con valor de '0', éste es un buen candidato para remplazar por ahora los valores faltantes de 'precio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: 2020-04-26\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-19\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-13\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-03\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-18\n",
      "Está 0 en la columna 'precio': False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Procedemos a detectar si en los demás DataFrames hay valores de '0' en la columna precio\n",
    "has_zeros = {}\n",
    "for x in ps_2020:\n",
    "    has_zeros[x] = (0 in ps_2020[x].precio.unique())\n",
    "for x in has_zeros:\n",
    "    print(f\"DataFrame: {x}\\nEstá 0 en la columna 'precio': {has_zeros[x]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que ningún DataFrame tiene el dato '0' en la columna 'precio', procedemos a remplazar los valores faltantes con '0'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['precio2'] = ps_2020[x]['precio'].replace('', np.nan).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios2 del DataFrame 2020-05-03:\n",
      "{\"<class 'float'>\"}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "2124\n"
     ]
    }
   ],
   "source": [
    "# Volvemos a explorar los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "precio_dtype = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio2:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios2 del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior test podemos corroborar que la nueva columna ('precio2') ya no tiene valores del tipo *str* así que podemos borrar la columna original y quedarnos con la nueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    ps_2020[x].drop('precio', axis=1, inplace=True)\n",
    "    ps_2020[x].rename(columns = {'precio2':'precio'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Unificar el formato de las columnas 'producto_id', dejándolo como un *str*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Corregir los valores de las columnas 'sucursal_id' que se hayan remplazado por valores tipo *datetime*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos cuales datasets tienen valores del tipo 'datetime' en la columna sucursal_id\n",
    "datasets_w_datetime = []\n",
    "for x in ps_2020:\n",
    "    checker = False\n",
    "    for y in ps_2020[x].sucursal_id:\n",
    "        if type(y) == datetime:\n",
    "            checker = True\n",
    "    if checker:\n",
    "        datasets_w_datetime.append(x)\n",
    "print(datasets_w_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que se pueda aplicar a la columna 'sucursal_id' y nos regrese cada valor como un str\n",
    "def sucursal_id_2str(registro):\n",
    "    if type(registro) == datetime:\n",
    "        spl = registro.strftime('%d-%m-%Y').split('-')\n",
    "        #print(f'{x}:{spl}')\n",
    "        if spl[0][0] == '0':\n",
    "            spl[0] = spl[0][1]\n",
    "        if spl[1][0] == '0':\n",
    "            spl[1] = spl[1][1]\n",
    "        return str(f'{spl[0]}-{spl[1]}-{spl[2]}')\n",
    "    else:\n",
    "        return str(registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a las columnas de 'sucursal_id' y guardamos los valores en una nueva columna 'sucursal_id2'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['sucursal_id2'] = ps_2020[x].sucursal_id.apply(sucursal_id_2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos cuales datasets tienen valores del tipo 'datetime' en la columna 'sucursal_id2'\n",
    "datasets_w_datetime = []\n",
    "for x in ps_2020:\n",
    "    checker = False\n",
    "    for y in ps_2020[x].sucursal_id2:\n",
    "        if type(y) == datetime:\n",
    "            checker = True\n",
    "    if checker:\n",
    "        datasets_w_datetime.append(x)\n",
    "print(datasets_w_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior chequeo podemos corroborar que la nueva columna creada ya no tiene valores del tipo 'datetime' así que podemos borrar la columna anterior y quedarnos con la nueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    ps_2020[x].drop('sucursal_id', axis=1, inplace=True)\n",
    "    ps_2020[x].rename(columns = {'sucursal_id2':'sucursal_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    print(ps_2020[x].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    print(ps_2020[x].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    semana = ps_2020[x]\n",
    "    print(f'----------------{x}----------------\\nShape: {semana.shape}\\n\\nValores nulos:\\n{semana.isnull().sum()}\\n\\nRegistros duplicados:\\n{semana.duplicated().value_counts()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
