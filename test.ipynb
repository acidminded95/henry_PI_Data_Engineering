{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Puntos a tener en cuenta:\n",
    "\n",
    "El script debe poder recibir nuevas tablas y arrojar un resultado unificado.\n",
    "\n",
    "La carga incremental debe estar administrada por el mismo script.\n",
    "\n",
    "Al data engineer no le importan los outliers, eso es cuestión del analista.\n",
    "\n",
    "DER: Diagrama de Entidad Relacional\n",
    "\n",
    "Sobre la carga: habrá una carga más.. No debe relacionarse al tiempo\n",
    "\n",
    "##### Los problemas que no se alcancen a solucionar hay que señalarlos:\n",
    "\n",
    "- Los precios en una de las hojas de excel tienen un decimal corrido\n",
    "\n",
    "#### Crear tablas en md para mostrar valores nulos y duplicados en tablas originales\n",
    "\n",
    "Entrega: jueves 18hrs argentina (4pm méxico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos importando las librerías que usaremos para la preparación de los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "#import re\n",
    "#import os\n",
    "from os import listdir\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los DataFrames en pandas\n",
    "Importamos los datasets de diferentes formatos a DataFrames de pandas de manera automatizada, organizándolos en un diccionario para facilitar su acceso y limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precios_semanas_20200419_20200426.xlsx', 'precios_semana_20200413.csv', 'precios_semana_20200503.json', 'precios_semana_20200518.txt', 'producto.parquet', 'sucursal.csv']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos una lista de los archivos dentro del directorio 'datasets'\n",
    "file_names = listdir('.\\datasets')\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key: precios_semanas_20200419_20200426.xlsx\n",
      "Value: ['precios_semanas_20200419_20200426', 'xlsx']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200413.csv\n",
      "Value: ['precios_semana_20200413', 'csv']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200503.json\n",
      "Value: ['precios_semana_20200503', 'json']\n",
      "\n",
      "\n",
      "Key: precios_semana_20200518.txt\n",
      "Value: ['precios_semana_20200518', 'txt']\n",
      "\n",
      "\n",
      "Key: producto.parquet\n",
      "Value: ['producto', 'parquet']\n",
      "\n",
      "\n",
      "Key: sucursal.csv\n",
      "Value: ['sucursal', 'csv']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un diccionario con los nombres de cada archivo y su extensión\n",
    "datasets_extensions = {}\n",
    "for x in file_names:\n",
    "    datasets_extensions[x] = x.split('.')\n",
    "\n",
    "for x in datasets_extensions:\n",
    "    print(f'\\nKey: {x}\\nValue: {datasets_extensions[x]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos las extensiones y los nombres de los archivos para importar los datasets en objetos 'DataFrame' de pandas.\n",
    "\n",
    "Habiendo estudiado un poco la naturaleza de los datasets antes de importarlos, se pudo observar que los registros\n",
    "o *tablas de hecho* son las que llevan por nombre 'precios_...', mientras que las *dimensiones* son los datasets de \n",
    "'producto' y 'sucursal', pues proveen información adicional a las primeras tablas.\n",
    "\n",
    "Así, los datasets de precios serán organizados en el diccionario 'ps_2020' (precio semanal 2020) y los otros dos en el \n",
    "diccionario 'dims' (dimensiones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los diccionarios y automatizamos la importación de los archivos contenidos en el directorio 'datasets'\n",
    "ps_2020 = {}\n",
    "dims = {}\n",
    "for x in datasets_extensions:\n",
    "    path = f'datasets/{x}'\n",
    "    if x[:7] == 'precios':\n",
    "        if datasets_extensions[x][1] in ['xlsx', 'xls']:\n",
    "            xl_dict = pd.read_excel(path, sheet_name=None, date_parser=None)\n",
    "            for sheet in xl_dict:\n",
    "                name = f'{sheet[-8:-4]}-{sheet[-4:-2]}-{sheet[-2:]}'\n",
    "                ps_2020[name] = pd.DataFrame(xl_dict[sheet])\n",
    "        else:\n",
    "            name = f'{datasets_extensions[x][0][-8:-4]}-{datasets_extensions[x][0][-4:-2]}-{datasets_extensions[x][0][-2:]}'\n",
    "            if datasets_extensions[x][1] == 'csv':\n",
    "                ps_2020[name] = pd.read_csv(path, encoding='UTF-16 LE')\n",
    "            elif datasets_extensions[x][1] == 'json':\n",
    "                ps_2020[name] = pd.read_json(path)\n",
    "            elif datasets_extensions[x][1] == 'txt':\n",
    "                ps_2020[name] = pd.read_csv(path, delimiter='|')\n",
    "    else:\n",
    "        name = datasets_extensions[x][0]\n",
    "        if datasets_extensions[x][1] == 'csv':\n",
    "            dims[name] = pd.read_csv(path)\n",
    "        elif datasets_extensions[x][1] == 'parquet':\n",
    "            dims[name] = pd.read_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame: 2020-04-26\n",
      "• Shape: (478909, 3)\n",
      "• Columnas: Index(['precio', 'sucursal_id', 'producto_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-19\n",
      "• Shape: (458543, 3)\n",
      "• Columnas: Index(['precio', 'sucursal_id', 'producto_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-04-13\n",
      "• Shape: (472166, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-03\n",
      "• Shape: (397734, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: 2020-05-18\n",
      "• Shape: (415293, 3)\n",
      "• Columnas: Index(['precio', 'producto_id', 'sucursal_id'], dtype='object')\n",
      "\n",
      "• DataFrame: producto\n",
      "• Shape: (72038, 7)\n",
      "• Columnas: Index(['id', 'marca', 'nombre', 'presentacion', 'categoria1', 'categoria2',\n",
      "       'categoria3'],\n",
      "      dtype='object')\n",
      "\n",
      "• DataFrame: sucursal\n",
      "• Shape: (2333, 12)\n",
      "• Columnas: Index(['id', 'comercioId', 'banderaId', 'banderaDescripcion',\n",
      "       'comercioRazonSocial', 'provincia', 'localidad', 'direccion', 'lat',\n",
      "       'lng', 'sucursalNombre', 'sucursalTipo'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ps_2020:\n",
    "    print(f'• DataFrame: {x}\\n• Shape: {ps_2020[x].shape}\\n• Columnas: {ps_2020[x].columns}\\n')\n",
    "for x in dims:\n",
    "    print(f'• DataFrame: {x}\\n• Shape: {dims[x].shape}\\n• Columnas: {dims[x].columns}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de limpieza de datos\n",
    "Una vez creadas las tablas podemos empezar el trabajo de limpieza de los datos, comenzando por buscar los registros duplicados y valores faltantes.\n",
    "\n",
    "El propósito de esta sección es:\n",
    "1) Dejar todas las columnas de las tablas de 'precios' con el mismo tipo de dato y mismo formato de registros en las diferentes tablas para poder concatenarlas después y subirlas a una base de datos SQL.\n",
    "2) Asegurarnos de que todos los valores de las columnas 'producto_id' y 'sucursal_id' puedan relacionarse a algún valor de las columans 'id' en las dimensiones 'producto' y 'sucursal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------2020-04-26----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-04-19----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-04-13----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-05-03----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n",
      "----------------2020-05-18----------------\n",
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Organizamos las columnas de los dataframes para que coincidan entre sí y facilitar la visualización\n",
    "# Además agragamos la columna 'fecha' que nos permitirá distinguir a qué dataset pertenece cada registro una vez sean concatenados\n",
    "cols = ['precio', 'producto_id', 'sucursal_id']\n",
    "for x in ps_2020:\n",
    "    ps_2020[x] = ps_2020[x][cols]\n",
    "    ps_2020[x]['fecha'] = datetime.strptime(x, '%Y-%m-%d')\n",
    "    print(f'----------------{x}----------------\\n{ps_2020[x].columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----DataFrame: 2020-04-26-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio          1736\n",
      "producto_id    13519\n",
      "sucursal_id        0\n",
      "fecha              0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    474692\n",
      "True       4217\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-19-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         1807\n",
      "producto_id       0\n",
      "sucursal_id       0\n",
      "fecha             0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    458543\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-04-13-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         13\n",
      "producto_id    15\n",
      "sucursal_id    15\n",
      "fecha           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    472134\n",
      "True         32\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-03-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         0\n",
      "producto_id    0\n",
      "sucursal_id    0\n",
      "fecha          0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    397734\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: 2020-05-18-----\n",
      "\n",
      "• Valores nulos:\n",
      "precio         1960\n",
      "producto_id       6\n",
      "sucursal_id       6\n",
      "fecha             0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    415104\n",
      "True        189\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: producto-----\n",
      "\n",
      "• Valores nulos:\n",
      "id                  0\n",
      "marca               2\n",
      "nombre              2\n",
      "presentacion        2\n",
      "categoria1      72034\n",
      "categoria2      72034\n",
      "categoria3      72034\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    72038\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: sucursal-----\n",
      "\n",
      "• Valores nulos:\n",
      "id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2333\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos un ciclo para obtener la información de todos los DataFrames\n",
    "for x in ps_2020:\n",
    "    semana = ps_2020[x]\n",
    "    print(f'\\n-----DataFrame: {x}-----\\n\\n• Valores nulos:\\n{semana.isnull().sum()}\\n\\n• Registros duplicados:\\n{semana.duplicated().value_counts()}\\n')\n",
    "for x in dims:\n",
    "    dim = dims[x]\n",
    "    print(f'\\n-----DataFrame: {x}-----\\n\\n• Valores nulos:\\n{dim.isnull().sum()}\\n\\n• Registros duplicados:\\n{dim.duplicated().value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habiendo detectado registros duplicados en los datasets de 'ps_2020' procedemos a eliminarlos\n",
    "for x in ps_2020:\n",
    "    ps_2020[x].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----DataFrame: 2020-04-26-----\n",
      "     precio  producto_id sucursal_id      fecha\n",
      "0     399.0       2288.0     2-1-092 2020-04-26\n",
      "1     299.0       2288.0     2-1-206 2020-04-26\n",
      "2     399.0       2288.0     2-2-241 2020-04-26\n",
      "3   49999.0     205870.0     9-1-430 2020-04-26\n",
      "4   53999.0     205870.0       9-2-4 2020-04-26\n",
      "5   53999.0     205870.0    9-3-5218 2020-04-26\n",
      "6   58999.0     205894.0     9-1-430 2020-04-26\n",
      "7   18999.0     205955.0     9-1-430 2020-04-26\n",
      "8   10499.0     205979.0     9-1-430 2020-04-26\n",
      "9    2290.0     206020.0     9-1-430 2020-04-26\n",
      "10  27999.0     206044.0     9-1-430 2020-04-26\n",
      "11   2190.0     206044.0     9-1-691 2020-04-26\n",
      "12  22999.0     206051.0     9-1-430 2020-04-26\n",
      "13  45999.0     206105.0     9-1-430 2020-04-26\n",
      "14  38999.0     206136.0     9-1-430 2020-04-26\n",
      "-----DataFrame: 2020-04-19-----\n",
      "    precio producto_id          sucursal_id      fecha\n",
      "0    29.90        2288              2-1-184 2020-04-19\n",
      "1    39.90        2288              2-1-206 2020-04-19\n",
      "2   499.99      205870              9-1-430 2020-04-19\n",
      "3   539.99      205870              9-2-107 2020-04-19\n",
      "4   539.99      205870  5218-03-09 00:00:00 2020-04-19\n",
      "5   589.99      205894              9-1-430 2020-04-19\n",
      "6   189.99      205955              9-1-430 2020-04-19\n",
      "7   104.99      205979              9-1-430 2020-04-19\n",
      "8   229.00      206020              9-1-430 2020-04-19\n",
      "9   279.99      206044              9-1-430 2020-04-19\n",
      "10  229.99      206051              9-1-430 2020-04-19\n",
      "11  459.99      206105              9-1-430 2020-04-19\n",
      "12  389.99      206136              9-1-430 2020-04-19\n",
      "13  299.99      206143              9-1-430 2020-04-19\n",
      "14  339.99      206181              9-1-430 2020-04-19\n",
      "-----DataFrame: 2020-04-13-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0    29.90  0000000001663     2-1-014 2020-04-13\n",
      "1    29.90  0000000002288     2-1-032 2020-04-13\n",
      "2    39.90  0000000002288     2-1-096 2020-04-13\n",
      "3   499.99  0000000205870     9-1-686 2020-04-13\n",
      "4   519.99  0000000205870     9-2-248 2020-04-13\n",
      "5   539.99  0000000205870      9-2-42 2020-04-13\n",
      "6   539.99  0000000205870     9-3-628 2020-04-13\n",
      "7   589.99  0000000205894     9-1-686 2020-04-13\n",
      "8   189.99  0000000205955     9-1-686 2020-04-13\n",
      "9   104.99  0000000205979     9-1-686 2020-04-13\n",
      "10  259.99  0000000206020     9-1-686 2020-04-13\n",
      "11  279.99  0000000206044     9-1-686 2020-04-13\n",
      "12  229.99  0000000206051     9-1-686 2020-04-13\n",
      "13  459.99  0000000206105     9-1-686 2020-04-13\n",
      "14  389.99  0000000206136     9-1-686 2020-04-13\n",
      "-----DataFrame: 2020-05-03-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0     29.9  0000000002288     2-1-187 2020-05-03\n",
      "1     39.9  0000000002288     2-3-247 2020-05-03\n",
      "2   499.99  0000000205870     9-1-685 2020-05-03\n",
      "3   539.99  0000000205870      9-2-22 2020-05-03\n",
      "4   519.99  0000000205870      9-2-59 2020-05-03\n",
      "5   539.99  0000000205870     9-3-138 2020-05-03\n",
      "6   589.99  0000000205894     9-1-685 2020-05-03\n",
      "7   189.99  0000000205955     9-1-685 2020-05-03\n",
      "8   104.99  0000000205979     9-1-685 2020-05-03\n",
      "9      229  0000000206020     9-1-685 2020-05-03\n",
      "10  279.99  0000000206044     9-1-685 2020-05-03\n",
      "11  229.99  0000000206051     9-1-685 2020-05-03\n",
      "12  459.99  0000000206105     9-1-685 2020-05-03\n",
      "13  389.99  0000000206136     9-1-685 2020-05-03\n",
      "14  299.99  0000000206143     9-1-685 2020-05-03\n",
      "-----DataFrame: 2020-05-18-----\n",
      "    precio    producto_id sucursal_id      fecha\n",
      "0    29.90  0000000002288     2-1-009 2020-05-18\n",
      "1    32.90  0000000002288     2-1-037 2020-05-18\n",
      "2    36.90  0000000002288     2-1-090 2020-05-18\n",
      "3    39.90  0000000002288     2-3-247 2020-05-18\n",
      "4   499.99  0000000205870     9-1-430 2020-05-18\n",
      "5   539.99  0000000205870       9-2-4 2020-05-18\n",
      "6   539.99  0000000205870    9-3-5205 2020-05-18\n",
      "7   589.99  0000000205894     9-1-430 2020-05-18\n",
      "8   189.99  0000000205955     9-1-430 2020-05-18\n",
      "9   104.99  0000000205979     9-1-430 2020-05-18\n",
      "10  259.99  0000000206020     9-1-430 2020-05-18\n",
      "11  279.99  0000000206044     9-1-430 2020-05-18\n",
      "12  229.99  0000000206051     9-1-430 2020-05-18\n",
      "13  459.99  0000000206105     9-1-430 2020-05-18\n",
      "14  389.99  0000000206136     9-1-430 2020-05-18\n",
      "-----DataFrame: producto-----\n",
      "               id       marca                                   nombre  \\\n",
      "0   0000000001663  LA ANÓNIMA          Radicheta Atada La Anonima 1 Un   \n",
      "1   0000000002288  LA ANÓNIMA            Perejil Atado La Anonima 1 Un   \n",
      "2   0000000205870   SIN MARCA                         Ojo de Bife 1 Kg   \n",
      "3   0000000205894   SIN MARCA        Milanesa de Peceto Novillito 1 Kg   \n",
      "4   0000000205955   SIN MARCA               Chiquizuela Novillito 1 Kg   \n",
      "5   0000000205979   SIN MARCA               Espinazo de Novillito 1 Kg   \n",
      "6   0000000206020   SIN MARCA           Carnanza Comun de Novillo 1 Kg   \n",
      "7   0000000206044   SIN MARCA  Falda Deshuesada Novillito Bandeja 1 Kg   \n",
      "8   0000000206051   SIN MARCA                  Carne Picada Comun 1 Kg   \n",
      "9   0000000206105   SIN MARCA               Entraña de Novillito 1 Kg   \n",
      "10  0000000206136   SIN MARCA             Bife Ancho de Novillito 1 Kg   \n",
      "11  0000000206143   SIN MARCA     Rost Beef en Trozo de Novillito 1 Kg   \n",
      "12  0000000206181   SIN MARCA               Palomita de Novillito 1 Kg   \n",
      "13  0000000206198   SIN MARCA                Tortuguita Novillito 1 Kg   \n",
      "14  0000000206235   SIN MARCA           Paleta en Trozo Novillito 1 Kg   \n",
      "\n",
      "   presentacion categoria1 categoria2 categoria3  \n",
      "0        1.0 un       None       None       None  \n",
      "1        1.0 un       None       None       None  \n",
      "2        1.0 kg       None       None       None  \n",
      "3        1.0 kg       None       None       None  \n",
      "4        1.0 kg       None       None       None  \n",
      "5        1.0 kg       None       None       None  \n",
      "6        1.0 kg       None       None       None  \n",
      "7        1.0 kg       None       None       None  \n",
      "8        1.0 kg       None       None       None  \n",
      "9        1.0 kg       None       None       None  \n",
      "10       1.0 kg       None       None       None  \n",
      "11       1.0 kg       None       None       None  \n",
      "12       1.0 kg       None       None       None  \n",
      "13       1.0 kg       None       None       None  \n",
      "14       1.0 kg       None       None       None  \n",
      "-----DataFrame: sucursal-----\n",
      "          id  comercioId  banderaId      banderaDescripcion  \\\n",
      "0      1-1-7           1          1              Super MAMI   \n",
      "1     10-1-1          10          1  Hipermercado Carrefour   \n",
      "2    10-1-10          10          1  Hipermercado Carrefour   \n",
      "3    10-1-11          10          1  Hipermercado Carrefour   \n",
      "4   10-1-112          10          1  Hipermercado Carrefour   \n",
      "5    10-1-12          10          1  Hipermercado Carrefour   \n",
      "6   10-1-123          10          1  Hipermercado Carrefour   \n",
      "7   10-1-128          10          1  Hipermercado Carrefour   \n",
      "8   10-1-136          10          1  Hipermercado Carrefour   \n",
      "9   10-1-139          10          1  Hipermercado Carrefour   \n",
      "10  10-1-142          10          1  Hipermercado Carrefour   \n",
      "11  10-1-147          10          1  Hipermercado Carrefour   \n",
      "12  10-1-149          10          1  Hipermercado Carrefour   \n",
      "13   10-1-15          10          1  Hipermercado Carrefour   \n",
      "14  10-1-156          10          1  Hipermercado Carrefour   \n",
      "\n",
      "   comercioRazonSocial provincia            localidad  \\\n",
      "0      Dinosaurio S.A.      AR-X          SALSIPUEDES   \n",
      "1             INC S.A.      AR-B           San Isidro   \n",
      "2             INC S.A.      AR-B           Hurlingham   \n",
      "3             INC S.A.      AR-B  Malvinas Argentinas   \n",
      "4             INC S.A.      AR-A                Salta   \n",
      "5             INC S.A.      AR-B            San Justo   \n",
      "6             INC S.A.      AR-J             San Juan   \n",
      "7             INC S.A.      AR-U   Comodoro Rivadavia   \n",
      "8             INC S.A.      AR-R         General Roca   \n",
      "9             INC S.A.      AR-B            Olavarría   \n",
      "10            INC S.A.      AR-V           Río Grande   \n",
      "11            INC S.A.      AR-L           Santa Rosa   \n",
      "12            INC S.A.      AR-R            Bariloche   \n",
      "13            INC S.A.      AR-B           San Martín   \n",
      "14            INC S.A.      AR-B          San Nicolás   \n",
      "\n",
      "                    direccion        lat        lng       sucursalNombre  \\\n",
      "0               E53 1011 None -31.126667 -64.295250         Super Mami 4   \n",
      "1   Bernardo De Irigoyen 2647 -34.491345 -58.589025           San Isidro   \n",
      "2            Av. Vergara 1910 -34.620610 -58.633769          Villa Tesei   \n",
      "3       Av. Arturo Illia 3770 -34.528883 -58.701631  Malvinas Argentinas   \n",
      "4            20 De Febrero 37 -24.789072 -65.413699                Salta   \n",
      "5          Av. Don Bosco 2680 -34.664628 -58.597356            San Justo   \n",
      "6               Gral. Acha 32 -31.534016 -68.524744             San Juan   \n",
      "7              Pellegrini 851 -45.861562 -67.479968   Comodoro Rivadavia   \n",
      "8              25 De Mayo 622 -39.030326 -67.573775         General Roca   \n",
      "9              Rivadavia 2846 -36.893694 -60.321650            Olavarría   \n",
      "10         Av. San Martín 685 -53.785009 -67.702990           Río Grande   \n",
      "11             Avellaneda 151 -36.618338 -64.291249           Santa Rosa   \n",
      "12                 Moreno 909 -41.136201 -71.296792            Bariloche   \n",
      "13         Av. San Martín 420 -34.586322 -58.519449           San Martín   \n",
      "14        Bartolomé Mitre 264 -33.331816 -60.220188          San Nicolás   \n",
      "\n",
      "    sucursalTipo  \n",
      "0   Hipermercado  \n",
      "1   Hipermercado  \n",
      "2   Hipermercado  \n",
      "3   Hipermercado  \n",
      "4   Hipermercado  \n",
      "5   Hipermercado  \n",
      "6   Supermercado  \n",
      "7   Hipermercado  \n",
      "8   Supermercado  \n",
      "9   Hipermercado  \n",
      "10  Supermercado  \n",
      "11  Hipermercado  \n",
      "12  Hipermercado  \n",
      "13  Hipermercado  \n",
      "14  Hipermercado  \n"
     ]
    }
   ],
   "source": [
    "# Ahora podemos generar una visualización preliminar de las tablas para continuar con el proceso de limpieza y poder lidiar con los valores nulos\n",
    "for x in ps_2020:\n",
    "    print(f'-----DataFrame: {x}-----\\n{ps_2020[x].head(15)}')\n",
    "for x in dims:\n",
    "    print(f'-----DataFrame: {x}-----\\n{dims[x].head(15)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 474692 entries, 0 to 478908\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       473053 non-null  float64       \n",
      " 1   producto_id  465390 non-null  float64       \n",
      " 2   sucursal_id  474692 non-null  object        \n",
      " 3   fecha        474692 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 18.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458543 entries, 0 to 458542\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       456736 non-null  float64       \n",
      " 1   producto_id  458543 non-null  object        \n",
      " 2   sucursal_id  458543 non-null  object        \n",
      " 3   fecha        458543 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 17.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 472134 entries, 0 to 472165\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       472133 non-null  float64       \n",
      " 1   producto_id  472131 non-null  object        \n",
      " 2   sucursal_id  472131 non-null  object        \n",
      " 3   fecha        472134 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 18.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 397734 entries, 0 to 397733\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       397734 non-null  object        \n",
      " 1   producto_id  397734 non-null  object        \n",
      " 2   sucursal_id  397734 non-null  object        \n",
      " 3   fecha        397734 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 15.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 415104 entries, 0 to 415292\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   precio       413147 non-null  float64       \n",
      " 1   producto_id  415101 non-null  object        \n",
      " 2   sucursal_id  415101 non-null  object        \n",
      " 3   fecha        415104 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 15.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72038 entries, 0 to 72037\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72038 non-null  object\n",
      " 1   marca         72036 non-null  object\n",
      " 2   nombre        72036 non-null  object\n",
      " 3   presentacion  72036 non-null  object\n",
      " 4   categoria1    4 non-null      object\n",
      " 5   categoria2    4 non-null      object\n",
      " 6   categoria3    4 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2333 entries, 0 to 2332\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2333 non-null   object \n",
      " 1   comercioId           2333 non-null   int64  \n",
      " 2   banderaId            2333 non-null   int64  \n",
      " 3   banderaDescripcion   2333 non-null   object \n",
      " 4   comercioRazonSocial  2333 non-null   object \n",
      " 5   provincia            2333 non-null   object \n",
      " 6   localidad            2333 non-null   object \n",
      " 7   direccion            2333 non-null   object \n",
      " 8   lat                  2333 non-null   float64\n",
      " 9   lng                  2333 non-null   float64\n",
      " 10  sucursalNombre       2333 non-null   object \n",
      " 11  sucursalTipo         2333 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 218.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisamos también la información de los diferentes datasets para tener presente el tipo de dato de cada columna\n",
    "for x in ps_2020:\n",
    "    print(ps_2020[x].info())\n",
    "for x in dims:\n",
    "    print(dims[x].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Primeros problemas con el formato de los datos:\n",
    "Con la anterior visualización preliminar y la información de los DataFrames se pueden ver varias cuestiones a tener en cuenta y que se abordarán a continuación:\n",
    "1) En uno de los DataFrames de precios (2020-05-03), el tipo de data de la columna 'precio' no es *float64* como en los demás.\n",
    "2) El formato de la columna 'producto_id' es diferente en varios DataFrames.\n",
    "3) Algunos valores de la columna 'sucursal_id' de al menos la tabla '2020-04-19' son interpretados en como de tipo 'datetime'.\n",
    "4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) El tipo de data de la columna 'precio' no es *float64* en todos los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\n",
      "{\"<class 'int'>\", \"<class 'float'>\", \"<class 'str'>\"}\n",
      "\n",
      "• Valores que encontramos para los strings:\n",
      "{''}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ahora exploramos un poco los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "# Obtenemos 1) el tipo de datos que encontramos en cada columna\n",
    "#           2) el valor de los datos tipo 'str'\n",
    "#           3) la cantidad de ceros en esta columna\n",
    "precio_dtype = set()\n",
    "strings = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if type(x) == str:\n",
    "        #print(x)\n",
    "        strings.add(x)\n",
    "    elif x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Valores que encontramos para los strings:\\n{strings}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### • Ya que detectamos que no hay registros en la columna con valor de '0', éste es un buen candidato para remplazar por ahora los valores faltantes de 'precio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: 2020-04-26\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-19\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-04-13\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-03\n",
      "Está 0 en la columna 'precio': False\n",
      "\n",
      "DataFrame: 2020-05-18\n",
      "Está 0 en la columna 'precio': False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Procedemos a detectar si en los demás DataFrames hay valores de '0' en la columna precio\n",
    "has_zeros = {}\n",
    "for x in ps_2020:\n",
    "    has_zeros[x] = (0 in ps_2020[x].precio.unique())\n",
    "for x in has_zeros:\n",
    "    print(f\"DataFrame: {x}\\nEstá 0 en la columna 'precio': {has_zeros[x]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que ningún DataFrame tiene el dato '0' en la columna 'precio', procedemos a remplazar los valores faltantes con '0'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['precio_ok'] = ps_2020[x]['precio'].replace('', np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tipos de datos que encontramos en la columna precios_ok del DataFrame 2020-05-03:\n",
      "{\"<class 'float'>\"}\n",
      "\n",
      "• Apariciones de 0 en la columna:\n",
      "2124\n"
     ]
    }
   ],
   "source": [
    "# Volvemos a explorar los datos de '2020-05-03.precio', columna que no era del tipo 'float64'\n",
    "precio_dtype = set()\n",
    "zeros = 0\n",
    "for x in ps_2020['2020-05-03'].precio_ok:\n",
    "    precio_dtype.add(str(type(x)))\n",
    "    if x == 0:\n",
    "        zeros += 1\n",
    "print(f'• Tipos de datos que encontramos en la columna precios_ok del DataFrame 2020-05-03:\\n{precio_dtype}\\n')\n",
    "print(f'• Apariciones de 0 en la columna:\\n{zeros}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior test podemos corroborar que la nueva columna ('precio_ok') ya no tiene valores del tipo *str* así que esta es la columna que usaremos en el dataset final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Unificar el formato de las columnas 'producto_id', dejándolo como un *str*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'float'>}\n",
      "• DataFrame 2020-04-19:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'int'>}\n",
      "• DataFrame 2020-04-13:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'float'>}\n",
      "• DataFrame 2020-05-03:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'int'>}\n",
      "• DataFrame 2020-05-18:\n",
      "  Tipos de dato en la columna 'producto_id': {<class 'str'>, <class 'float'>}\n"
     ]
    }
   ],
   "source": [
    "# Primero nos cercioramos del tipo de dato que hay en cada una de las columnas 'producto_id'\n",
    "producto_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    producto_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].producto_id:\n",
    "        producto_id_dtypes[x].add(type(y))\n",
    "for x in producto_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\n  Tipos de dato en la columna 'producto_id': {producto_id_dtypes[x]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• DataFrame 2020-04-26:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 63925\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 0\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 1\n",
      "    El único valor float encontrado fue: {nan}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 0\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "  Cantidad de valores 'float' en la columna 'producto_id': 1\n",
      "    El único valor float encontrado fue: {nan}\n",
      "\n",
      "• Cantidad de ceros en las columnas 'producto_id': 0\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la cantidad de valores de tipo 'float' en las tablas 2020-04-26, 2020-04-13 y 2020-05-18\n",
    "# Además revisamos si encontramos '0' entre estos valores\n",
    "valores_float = {}\n",
    "pid_zeros = 0\n",
    "for x in ps_2020:\n",
    "    valores_float[x] = set()\n",
    "    for y in ps_2020[x].producto_id:\n",
    "        if type(y) == float:\n",
    "            valores_float[x].add(y)\n",
    "        if y in [0,'0']:\n",
    "            pid_zeros += 1\n",
    "for x in valores_float:\n",
    "    print(f\"\\n• DataFrame {x}:\\n  Cantidad de valores 'float' en la columna 'producto_id': {len(valores_float[x])}\")\n",
    "    if len(valores_float[x]) ==1:\n",
    "        print(f\"    El único valor float encontrado fue: {valores_float[x]}\")\n",
    "print(f\"\\n• Cantidad de ceros en las columnas 'producto_id': {pid_zeros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del anterior chequeo podemos deducir que sólo el DataFrame 2020-04-26 tiene valores 'float' distintos de 'nan', además de que ninguno de los DataFrames tiene el valor '0' en la columna 'producto_id'. \n",
    "\n",
    "Por lo anterior, procederemos a remplazar los valores faltantes con 0 y, posteriormente convertir los valores 'float' en 'int' (para quitar el decimal) y luego en 'str' (para homogeneizar las claves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Revisamos si todavía hay valores nulos\\nfor x in ps_2020:\\n    print(f'\\n• DataFrame: {x}')\\n    print(ps_2020[x].isnull().sum())\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remplazamos los valores faltantes con 0\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id2'] = (ps_2020[x]['producto_id'].replace('', np.nan).fillna(0))\n",
    "\n",
    "'''\n",
    "# Revisamos si todavía hay valores nulos\n",
    "for x in ps_2020:\n",
    "    print(f'\\n• DataFrame: {x}')\n",
    "    print(ps_2020[x].isnull().sum())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para cambiar los valores 'float' e 'int' a 'str'\n",
    "def pid_num2str(val):\n",
    "    if type(val) == float:\n",
    "        return str(int(val))\n",
    "    elif type(val) == int:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "# Aplicamos la función a la columna sin valores nulos (producto_id2) y guardamos el resultado en otra columna (producto_id3)\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id3'] = ps_2020[x]['producto_id2'].apply(pid_num2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-04-19:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-04-13:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-05-03:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n",
      "• DataFrame 2020-05-18:\n",
      "  Tipos de dato en la columna 'producto_id3': {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# Ahora revisamos el tipo de dato que hay en cada una de las columnas 'producto_id3'\n",
    "sucursal_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].producto_id3:\n",
    "        sucursal_id_dtypes[x].add(type(y))\n",
    "for x in sucursal_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\n  Tipos de dato en la columna 'producto_id3': {sucursal_id_dtypes[x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ya que tenemos el 'producto_id' en todas las tablas de 'precios' en formato 'str', nos aseguraremos ahora de que estos valores correspondan a un valor en la tabla 'producto', recordando que los datos faltantes fueron remplazados por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Revisamos el formato del 'id' en la tabla producto a la que las columnas 'precio.producto_id' harán referencia\n",
    "# Para esto vemos primero los tipos de dato almacenados en esta columna\n",
    "pid_dtypes = set()\n",
    "for x in dims['producto'].id:\n",
    "    pid_dtypes.add(type(x))\n",
    "for x in pid_dtypes:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'id' de la tabla 'producto' encontramos valores de las siguientes longitudes: {17, 18, 13}\n"
     ]
    }
   ],
   "source": [
    "# Al confirmar que todos los valores de la columna 'id' en la tabla 'producto' son str, obtenemos la longitud de estos valores\n",
    "pid_lengths = set()\n",
    "\n",
    "for x in dims['producto'].id.unique():\n",
    "    pid_lengths.add(len(x))\n",
    "\n",
    "print(f\"En la columna 'id' de la tabla 'producto' encontramos valores de las siguientes longitudes: {pid_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Algunos ejemplos de los valores en la columna 'id' de la tabla 'producto' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "17: ['9-1-0000000992404', '9-1-0000000969581', '7-1-0024006900000', '9-1-0000000256124', '9-1-0000000206723']\n",
      "18: ['16-1-0000000263091', '46-1-0000000083074', '10-2-2308052000008', '10-2-2307317000005', '65-1-0000000014788']\n",
      "13: ['8480017419538', '7798126290315', '7797470196342', '7798133610557', '7790520009357']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos ahora en qué consisten las diferencias de los códigos de distintas longitudes\n",
    "pid_lengths_examples = {}\n",
    "for x in pid_lengths:\n",
    "    pid_lengths_examples[str(x)] = []\n",
    "for x in dims['producto'].id:\n",
    "    len_x = str(len(x))\n",
    "    pid_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\n• Algunos ejemplos de los valores en la columna 'id' de la tabla 'producto' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in pid_lengths_examples:\n",
    "    print(f'{x}: {sample(pid_lengths_examples[x],5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que los códigos de 'id' en la tabla 'producto' con más de 13 caracteres se diferencian de aquellos con 13 caracteres porque tienen un prefijo compuesto de la siguiente manera:\n",
    "\n",
    "(Número de uno o dos dígitos)+(guión)+(Número de un dígito)+(guión)\n",
    "\n",
    "Dado que hay diferentes longitudes en los códigos de la columna 'id' de la tabla 'producto', revisaremos ahora si:\n",
    "1) Estos códigos son únicos por registro\n",
    "2) Los códigos siguen siendo únicos si los reducimos todos a tener sólo 13 caracteres (los últimos 13, para evitar la parte que contiene guiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'producto': 72038\n",
      "Cantidad de valores únicos en la columna 'id' original: 72038\n",
      "\n",
      "• Los valores originales de la columna 'id' son únicos por registro: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Se verifica que los ids originales sean únicos por registro\n",
    "\n",
    "tot_reg_producto = len(dims['producto'])\n",
    "id_uniq_producto = dims['producto'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'producto': {tot_reg_producto}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' original: {id_uniq_producto}\")\n",
    "print(f\"\\n• Los valores originales de la columna 'id' son únicos por registro: {tot_reg_producto==id_uniq_producto}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['marca', 'nombre', 'presentacion', 'categoria1', 'categoria2',\n",
      "       'categoria3', 'id'],\n",
      "      dtype='object')\n",
      "\n",
      "-----DataFrame: 'producto2'-----\n",
      "\n",
      "• Valores nulos:\n",
      "marca               2\n",
      "nombre              2\n",
      "presentacion        2\n",
      "categoria1      68194\n",
      "categoria2      68194\n",
      "categoria3      68194\n",
      "id                  0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    68198\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos un nuevo DataFrame a partir de 'producto' y remplazamos la columna 'id' por su versión reducida (pid2)\n",
    "pid2 = []\n",
    "for x in dims['producto'].id:\n",
    "    if len(x)>13:\n",
    "        y = x[-13:]\n",
    "        pid2.append(y)\n",
    "    else:\n",
    "        pid2.append(x)\n",
    "pid2_array = pd.Series(pid2)\n",
    "\n",
    "# Creamos un DataFrame nuevo con los ids reducidos y dropeando los duplicados\n",
    "dims['producto2'] = dims['producto'].drop('id', axis=1)\n",
    "\n",
    "dims['producto2']['id'] = pid2_array\n",
    "\n",
    "dims['producto2'].drop_duplicates(inplace=True)\n",
    "\n",
    "print(dims['producto2'].columns)\n",
    "\n",
    "print(f\"\\n-----DataFrame: 'producto2'-----\\n\\n• Valores nulos:\\n{dims['producto2'].isnull().sum()}\\n\\n• Registros duplicados:\\n{dims['producto2'].duplicated().value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'producto2': 68198\n",
      "Cantidad de valores únicos en la columna 'id' reducida: 67943\n",
      "\n",
      "• Los valores reducidos de la columna 'id' son únicos por registro: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Verificamos si el nuevo DataFrame con ids reducidos ('producto2') sigue teniendo un id único para cada registro\n",
    "tot_reg_producto2 = len(dims['producto2'])\n",
    "id_uniq_producto2 = dims['producto2'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'producto2': {tot_reg_producto2}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' reducida: {id_uniq_producto2}\")\n",
    "print(f\"\\n• Los valores reducidos de la columna 'id' son únicos por registro: {tot_reg_producto2==id_uniq_producto2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con el código de las últimas 3 celdas se logró verificar que es necesario conservar los ids originales de la tabla 'producto' puesto que, si tomamos sólo los últimos 13 caracteres de cada código, entonces tendremos códigos repetidos para diferentes productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que no se puede reducir la longitud de los códigos de 'id' largos sin comprometer la unicidad de cada código para los registros de la tabla 'producto', procederemos a modificar las columnas 'producto_id' de las tablas 'precios' para que se ajusten a alguno de los valores de 13, 17 o 18 dígitos de la columna 'id' de la tabla 'producto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Cantidades de caracteres en los distintos valores de las columnas producto_id3:\n",
      "\n",
      "\tDataFrame2020-04-26: {1, 4, 6, 7, 8, 9, 10, 11, 12, 13}\n",
      "\n",
      "\tDataFrame2020-04-19: {4, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18}\n",
      "\n",
      "\tDataFrame2020-04-13: {17, 18, 13, 1}\n",
      "\n",
      "\tDataFrame2020-05-03: {17, 18, 13}\n",
      "\n",
      "\tDataFrame2020-05-18: {17, 18, 13, 1}\n",
      "\n",
      "• Casos más excepcionales (con valores de 1 o 4 caracteres):\n",
      "\n",
      "\tValores de 1 caracter por DataFrame (df, valor): [['2020-04-26', '0'], ['2020-04-13', '0'], ['2020-05-18', '0']]\n",
      "\n",
      "\tValores de 4 caracteres por DataFrame (df, valor): [['2020-04-26', '2288'], ['2020-04-19', '2288']]\n"
     ]
    }
   ],
   "source": [
    "# Empezamos por revisar las diferentes longitudes de los valores de las columnas 'producto_id' en las tablas de 'precios' \n",
    "# Posteriormente visualizamos los valores más excepcionales (1 y 4)\n",
    "ps_pid_lengths = {}\n",
    "id_1_car = []\n",
    "id_4_car = []\n",
    "for x in ps_2020:\n",
    "    ps_pid_lengths[x] = set()\n",
    "    for y in ps_2020[x]['producto_id3'].unique():\n",
    "        ps_pid_lengths[x].add(len(str(y)))\n",
    "        if len(str(y)) == 1:\n",
    "            id_1_car.append([x,y])\n",
    "        elif len(str(y)) == 4:\n",
    "            id_4_car.append([x,y])\n",
    "\n",
    "print('\\n• Cantidades de caracteres en los distintos valores de las columnas producto_id3:\\n')\n",
    "for x in ps_pid_lengths:\n",
    "    print(f'\\tDataFrame{x}: {ps_pid_lengths[x]}\\n')\n",
    "\n",
    "print('• Casos más excepcionales (con valores de 1 o 4 caracteres):\\n')\n",
    "print(f'\\tValores de 1 caracter por DataFrame (df, valor): {id_1_car}\\n')\n",
    "print(f'\\tValores de 4 caracteres por DataFrame (df, valor): {id_4_car}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el caso más extremo corresponde al de los valores nulos, que fueron remplazados por 0.\n",
    "\n",
    "Mientras que el siguiente caso de valores con pocos caracteres es '2288', valor que s epodría corresponder con el id '0000000002288' de la tabla 'producto'.\n",
    "\n",
    "Por esta razón, procederemos a llenar los valores con menos de 13 caracteres de las columnas 'producto_id3' en las tablas 'precios' con 0's a la izquierda hasta tener un valor con 13 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de códigos en las columnas 'producto_id3' con menos de 13 caracteres por DataFrame:\n",
      "\n",
      "• DataFrame 2020-04-26:20736\n",
      "\n",
      "• DataFrame 2020-04-19:11125\n",
      "\n",
      "• DataFrame 2020-04-13:3\n",
      "\n",
      "• DataFrame 2020-05-03:0\n",
      "\n",
      "• DataFrame 2020-05-18:3\n"
     ]
    }
   ],
   "source": [
    "# Primero vemos la cantidad de registros con menos de 13 caracteres en cada uno de los DataFrames de 'precios'\n",
    "pid_short_codes = {}\n",
    "for x in ps_2020:\n",
    "    pid_short_codes[x] = []\n",
    "    for y in ps_2020[x].producto_id3:\n",
    "        if len(y)<13:\n",
    "            pid_short_codes[x].append(x)\n",
    "print(\"Cantidad de códigos en las columnas 'producto_id3' con menos de 13 caracteres por DataFrame:\")\n",
    "for x in pid_short_codes:\n",
    "    print(f'\\n• DataFrame {x}:{len(pid_short_codes[x])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que nos regrese un valor de 13 caracteres con 0 a la izquierda si el valor tiene argumento pasado tiene menos de 13\n",
    "def fill_id(str):\n",
    "    if len(str)<13:\n",
    "        return str.zfill(13)\n",
    "    else:\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a las columnas 'producto_id3' de los DataFrames de 'precios'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id4'] = ps_2020[x]['producto_id3'].apply(fill_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17, 18, 13}\n"
     ]
    }
   ],
   "source": [
    "# Revisamos las longitudes de los valores de la columna 'producto_id4'\n",
    "pid4_lengths = set()\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].producto_id4:\n",
    "        pid4_lengths.add(len(y))\n",
    "print(pid4_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### • Una vez transformados los datos de la columna 'producto_id' de los DataFrames de 'precios' a su forma final en la columna 'producto_id4', procedemos a revisar que todos estos sí hagan referencia a algún valor de la columna 'id' en la tabla 'producto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72038\n",
      "72038\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista (pid) con los valores de la columna 'id' de la tabla producto\n",
    "pid = []\n",
    "\n",
    "for x in dims['producto'].id.unique():\n",
    "    pid.append(x)\n",
    "print(len(pid))\n",
    "print(dims['producto'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Output (8m 30.2s):\\nChecking 2020-04-26... 54624 values to check..\\nChecking 2020-04-19... 62393 values to check..\\nChecking 2020-04-13... 66532 values to check..\\nChecking 2020-05-03... 61505 values to check..\\nChecking 2020-05-18... 60745 values to check..\\n\\n\\nRESULTS:\\n\\n• DataFrame 2020-04-26:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-19:\\n\\tFound problems: True (Amount: 7)\\n• DataFrame 2020-04-13:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-03:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-18:\\n\\tFound problems: False (Amount: 0)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El siguiente código revisa, para todas los DataFrames de precios, si los valores de 'producto_id4' se encuentran en la lista 'pid' recién creada.\n",
    "# La ejecución puede llegar a tardar varios minutos así que el código está comentado para que no se ejecute automáticamente al correr todas las celdas.\n",
    "'''\n",
    "pid_checklist = {}\n",
    "pid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = len(ps_2020[x].producto_id4.unique())\n",
    "    print(f'Checking DataFrame {x}... {len_x} values to check..')\n",
    "    pid_checklist[x] = False\n",
    "    pid_problems_found[x] = []\n",
    "    for y in ps_2020[x].producto_id4.unique():\n",
    "        if (y != '0000000000000'):\n",
    "            if y not in pid:\n",
    "                pid_checklist[x] = True\n",
    "                pid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "print('\\n\\nRESULTS:\\n')\n",
    "for x in pid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {pid_checklist[x]} (Amount: {len(pid_problems_found[x])})\")\n",
    "'''\n",
    "\n",
    "''' Output (8m 30.2s):\n",
    "Checking 2020-04-26... 54624 values to check..\n",
    "Checking 2020-04-19... 62393 values to check..\n",
    "Checking 2020-04-13... 66532 values to check..\n",
    "Checking 2020-05-03... 61505 values to check..\n",
    "Checking 2020-05-18... 60745 values to check..\n",
    "\n",
    "\n",
    "RESULTS:\n",
    "\n",
    "• DataFrame 2020-04-26:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-19:\n",
    "\tFound problems: True (Amount: 7)\n",
    "• DataFrame 2020-04-13:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-03:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-18:\n",
    "\tFound problems: False (Amount: 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Output:\\n2020-04-26: []\\n2020-04-19: ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\\n2020-04-13: []\\n2020-05-03: []\\n2020-05-18: []\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for x in pid_problems_found:\n",
    "    print(f'{x}: {pid_problems_found[x]}')\n",
    "'''\n",
    "\n",
    "''' Output:\n",
    "2020-04-26: []\n",
    "2020-04-19: ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\n",
    "2020-04-13: []\n",
    "2020-05-03: []\n",
    "2020-05-18: []\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Con las últimas tres celdas pudimos corroborar que no todos los valores de 'producto_id4' corresponden a un id de la tabla 'producto'.\n",
    "Un problema del que habrá que informar al cliente. Sin embargo, al ser pocos (7) los valores de 'producto_id' problemáticos y en una sola tabla, se optará por remplazarlos por el un valor alternativo que usamos en donde los datos faltaban '0000000000000' : '1111111111111'.\n",
    "Por lo pronto, todos los 'producto_id4' son  del tipo 'str' y de estructura más o menos uniforme (salvo por la variacion en las longitudes) así que se subirán así a la base de datos, una vez hecho el remplazo que se acaba de mencionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Confirmamos si el código a usar para notificar de este error no está ya en los valores 'id' del DataFrame 'producto'\n",
    "print(('1111111111111' in dims['producto'].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de productos a remplazar en los 5 DataFrames es de 7, de un total de 2218207 (0.00032%).\n"
     ]
    }
   ],
   "source": [
    "# Definimos los registros a remplazar (pid_a_remplazar) y vemos cual es el total de registros en las columnas 'producto_id4' a remplazar\n",
    "pid_a_remplazar = ['10-1-2303809000003', '10-2-2304238000008', '2630399000008', '2920433200007', '7790513005687', '7798037563669', '7798037563683']\n",
    "# Aquí podemos ver que el total de registros remplazados fueron 7\n",
    "pid_ar_count = 0\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].producto_id4:\n",
    "        if y in pid_a_remplazar:\n",
    "            pid_ar_count += 1\n",
    "tot_reg = 0\n",
    "for x in ps_2020:\n",
    "    tot_reg += ps_2020[x].shape[0]\n",
    "print(f'El total de productos a remplazar en los {len(ps_2020.keys())} DataFrames es de {pid_ar_count}, de un total de {tot_reg} ({round(100*(pid_ar_count/tot_reg),5)}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver que la cantidad de registros a modificar es nimia, llevamos a cabo el remplazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creamos una función que cambie estos registros por el código elegido\n",
    "def nxcode2err111(registro):\n",
    "    if registro in pid_a_remplazar:\n",
    "        return '1111111111111'\n",
    "    else:\n",
    "        return registro\n",
    "# Aplicamos la función y creamos la columna 'producto_id_ok':\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['producto_id_ok'] = ps_2020[x]['producto_id4'].apply(nxcode2err111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Output (9m 37.8s):\\nRESULTS:\\n\\n• DataFrame 2020-04-26:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-19:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-04-13:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-03:\\n\\tFound problems: False (Amount: 0)\\n• DataFrame 2020-05-18:\\n\\tFound problems: False (Amount: 0)\\n' Output (8m 4.8s):\\n\\n'\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volvemos a hacer la verificación de las referencias de producto_id_ok' a 'producto.id'\n",
    "'''\n",
    "pid_checklist = {}\n",
    "pid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = len(ps_2020[x].producto_id_ok.unique())\n",
    "    #print(f'Checking DataFrame {x}... {len_x} values to check..')\n",
    "    pid_checklist[x] = False\n",
    "    pid_problems_found[x] = []\n",
    "    for y in ps_2020[x].producto_id_ok.unique():\n",
    "        if (y != '0000000000000') and (y != '1111111111111'):\n",
    "            if y not in pid:\n",
    "                pid_checklist[x] = True\n",
    "                pid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "print('\\n\\nRESULTS:\\n')\n",
    "for x in pid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {pid_checklist[x]} (Amount: {len(pid_problems_found[x])})\")\n",
    "'''\n",
    "\n",
    "''' Output (9m 37.8s):\n",
    "RESULTS:\n",
    "\n",
    "• DataFrame 2020-04-26:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-19:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-04-13:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-03:\n",
    "\tFound problems: False (Amount: 0)\n",
    "• DataFrame 2020-05-18:\n",
    "\tFound problems: False (Amount: 0)\n",
    "' Output (8m 4.8s):\\n\\n'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Corregir los valores de las columnas 'sucursal_id' que se hayan remplazado por valores tipo *datetime*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'datetime.datetime'>, <class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>, <class 'float'>}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id': {<class 'str'>, <class 'float'>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Primero nos cercioramos del tipo de dato que hay en cada una de las columnas 'sucursal_id'\n",
    "sucursal_id_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id_dtypes[x] = set()\n",
    "    for y in ps_2020[x].sucursal_id:\n",
    "        sucursal_id_dtypes[x].add(type(y))\n",
    "for x in sucursal_id_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\nTipos de datos encontrados en la columna 'sucursal_id': {sucursal_id_dtypes[x]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que además de los valores datetime (que sólo están en el DataFrame 2020-04-19) también hay valores 'float' en los DataFrames 2020-04-13 y 2020-05-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores que no son de tipo 'str': 140449\n",
      "\n",
      "• Tipo datetime (5): 140443\n",
      "\t2020-04-26:0\n",
      "\t2020-04-19:140443\n",
      "\t2020-04-13:0\n",
      "\t2020-05-03:0\n",
      "\t2020-05-18:0\n",
      "• Tipo float: 6\n",
      "\t2020-04-26:0 -- values: []\n",
      "\t2020-04-19:0 -- values: []\n",
      "\t2020-04-13:3 -- values: [nan, nan, nan]\n",
      "\t2020-05-03:0 -- values: []\n",
      "\t2020-05-18:3 -- values: [nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos qué tantos valores encontramos para cada tipo y si son pocos los visualizamos\n",
    "count = 0\n",
    "dt_count = 0\n",
    "dt_values = {}\n",
    "fl_count = 0\n",
    "fl_values = {}\n",
    "\n",
    "for x in ps_2020:\n",
    "    dt_values[x] = []\n",
    "    fl_values[x] = []\n",
    "    for y in ps_2020[x].sucursal_id:\n",
    "        if type(y) != str:\n",
    "            count += 1\n",
    "            if type(y) == datetime:\n",
    "                dt_count += 1\n",
    "                dt_values[x].append(y)\n",
    "            elif type(y) == float:\n",
    "                fl_count += 1\n",
    "                fl_values[x].append(y)\n",
    "print(f\"\\nValores que no son de tipo 'str': {count}\\n\")\n",
    "print(f\"• Tipo datetime ({len(dt_values)}): {dt_count}\")\n",
    "for x in dt_values:\n",
    "    print(f\"\\t{x}:{len(dt_values[x])}\")\n",
    "print(f\"• Tipo float: {fl_count}\")\n",
    "for x in fl_values:\n",
    "    print(f\"\\t{x}:{len(fl_values[x])} -- values: {fl_values[x]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior testeo podemos ver que los valores de tipo 'float' que se registran en los DataFrames 2020-04-13 y 2020-05-18 son valores faltantes. En lo siguiente serán remplazados por el str '0' para que todas las columnas sean de tipo str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que se pueda aplicar a la columna 'sucursal_id' y nos regrese cada valor como un str en el formato deseado\n",
    "def sucursal_id_2str(registro):\n",
    "    if type(registro) == datetime:\n",
    "        spl = registro.strftime('%d-%m-%Y').split('-')\n",
    "        #print(f'{x}:{spl}')\n",
    "        if spl[0][0] == '0':\n",
    "            spl[0] = spl[0][1]\n",
    "        if spl[1][0] == '0':\n",
    "            spl[1] = spl[1][1]\n",
    "        return str(f'{spl[0]}-{spl[1]}-{spl[2]}')\n",
    "    elif type(registro) == float:\n",
    "        return '0'\n",
    "    else:\n",
    "        return str(registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a las columnas de 'sucursal_id' y guardamos los valores en una nueva columna 'sucursal_id2'\n",
    "for x in ps_2020:\n",
    "    ps_2020[x]['sucursal_id2'] = ps_2020[x].sucursal_id.apply(sucursal_id_2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "Tipos de datos encontrados en la columna 'sucursal_id2': {<class 'str'>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los tipos de datos hallados en las columnas recien creadas (sucursal_id2)\n",
    "sucursal_id2_dtypes = {}\n",
    "for x in ps_2020:\n",
    "    sucursal_id2_dtypes[x] = set()\n",
    "    for y in ps_2020[x].sucursal_id2:\n",
    "        sucursal_id2_dtypes[x].add(type(y))\n",
    "for x in sucursal_id2_dtypes:\n",
    "    print(f\"• DataFrame {x}:\\nTipos de datos encontrados en la columna 'sucursal_id2': {sucursal_id2_dtypes[x]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el anterior chequeo podemos corroborar que la nueva columna creada ya no tiene valores del tipo 'datetime' ni 'float'.\n",
    "\n",
    "Ahora revisamos si los valores de las columnas 'sucursal_id' distintos de '0' hacen referencia a algún valor de la columna 'id' de la tabla 'sucursal'. Para esto empezamos por revisar si las longitudes de los strings se corresponden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Revisamos el formato del 'id' en la tabla sucursal a la que las columnas 'precio.sucursal_id' harán referencia\n",
    "# Para esto vemos primero los tipos de dato almacenados en esta columna\n",
    "sid_dtypes = set()\n",
    "for x in dims['sucursal'].id:\n",
    "    sid_dtypes.add(type(x))\n",
    "for x in sid_dtypes:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {5, 6, 7, 8, 9, 10}\n"
     ]
    }
   ],
   "source": [
    "# Al confirmar que todos los valores de la columna 'id' en la tabla 'sucursal' son str, obtenemos la longitud de estos valores\n",
    "sid_lengths = set()\n",
    "\n",
    "for x in dims['sucursal'].id.unique():\n",
    "    sid_lengths.add(len(x))\n",
    "\n",
    "print(f\"En la columna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {sid_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "5: ['6-2-1', '8-1-7', '9-1-8', '8-1-9', '7-1-5']\n",
      "6: ['6-2-21', '7-1-47', '9-2-15', '18-1-6', '25-1-1']\n",
      "7: ['12-1-65', '15-1-19', '15-1-89', '9-1-767', '2-1-056']\n",
      "8: ['15-1-412', '15-1-234', '9-3-5225', '10-3-526', '9-3-5276']\n",
      "9: ['15-1-1523', '15-1-1505', '15-1-5242', '15-1-1006', '23-1-6205']\n",
      "10: ['19-1-02697', '19-1-02460', '19-1-03228', '19-1-01317', '19-1-01641']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos ahora en qué consisten las diferencias de los códigos de distintas longitudes\n",
    "sid_lengths_examples = {}\n",
    "for x in sid_lengths:\n",
    "    sid_lengths_examples[str(x)] = []\n",
    "for x in dims['sucursal'].id:\n",
    "    len_x = str(len(x))\n",
    "    sid_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\nAlgunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in sid_lengths_examples:\n",
    "    print(f'{x}: {sample(sid_lengths_examples[x],5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que para todos las longitudes de los códigos, la estructura de estos consiste en 3 números separados por guiones.\n",
    "\n",
    "Cabe destacar que en los códigos más largos (de 10 caracteres) el tercer número parece estar precedido por ceros a la izquierda que, de ser ignorados, podrían hacer que el código se igual a uno de 9 u 8 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros en la tabla 'sucursal': 2333\n",
      "Cantidad de valores únicos en la columna 'id' original: 2333\n",
      "\n",
      "• Los valores originales de la columna 'id' son únicos por registro: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que los valores de 'id' en el DataFrame 'sucursal' sean únicos por registro\n",
    "tot_reg_sucursal = len(dims['sucursal'])\n",
    "id_uniq_sucursal = dims['sucursal'].id.unique().shape[0]\n",
    "print(f\"Cantidad de registros en la tabla 'sucursal': {tot_reg_sucursal}\")\n",
    "print(f\"Cantidad de valores únicos en la columna 'id' original: {id_uniq_sucursal}\")\n",
    "print(f\"\\n• Los valores originales de la columna 'id' son únicos por registro: {tot_reg_sucursal==id_uniq_sucursal}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Total de registros en el DataFrame 'sucursal': 2333\n",
      "• Total de valores únicos en la columna 'id' del DataFrame 'sucursal': 2333\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v3' (tomando únicamente el último número de 'id') del DataFrame 'sucursal':\n",
      "1162\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v1_v3' (tomando la combinación del primer y el último número de 'id') del DataFrame 'sucursal':\n",
      "2323\n",
      "\n",
      "• Totales de valores únicos en la columna hipotética 'id_v2_v3' (tomando la combinación del segundo y el último número de 'id') del DataFrame 'sucursal':\n",
      "1620\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si podemos tomar el último de los numeros de la columna 'id' (sid_v3) en el DataFrame 'sucursal' para identificar los registros de manera única\n",
    "# O bien la combinación del último valor con el primero (sid_v1_v3) o con el segundo (sid_v2_v3)\n",
    "tot_reg_sucursal = dims['sucursal'].shape[0]\n",
    "sid_v3 = []\n",
    "sid_v1_v3 = []\n",
    "sid_v2_v3 = []\n",
    "for x in dims['sucursal'].id:\n",
    "    sid_split = x.split('-')\n",
    "    sid_v3.append(sid_split[2])\n",
    "    sid_v1_v3.append(sid_split[0]+sid_split[2])\n",
    "    sid_v2_v3.append(sid_split[1]+sid_split[2])\n",
    "sid_v3_Srs = pd.Series(sid_v3)\n",
    "sid_v1_v3_Srs = pd.Series(sid_v1_v3)\n",
    "sid_v2_v3_Srs = pd.Series(sid_v2_v3)\n",
    "\n",
    "print(f\"• Total de registros en el DataFrame 'sucursal': {tot_reg_sucursal}\")\n",
    "print(f\"• Total de valores únicos en la columna 'id' del DataFrame 'sucursal': {len(dims['sucursal'].id.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v3' (tomando únicamente el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v3_Srs.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v1_v3' (tomando la combinación del primer y el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v1_v3_Srs.unique())}\")\n",
    "print(f\"\\n• Totales de valores únicos en la columna hipotética 'id_v2_v3' (tomando la combinación del segundo y el último número de 'id') del DataFrame 'sucursal':\\n{len(sid_v2_v3_Srs.unique())}\")\n",
    "\n",
    "#print(sid_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna de las subcombinaciones de los números en el 'id' de 'sucursal' nos identifica los registros de manera única así que optaremos por conservar el 'id' como viene presentado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a revisar si todos los valores de la columna 'sucursal_id2' de las tablas 'precio' corresponden a un valor en la columna 'id' de 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la columna 'sucursal_id2' de las tablas 'precio' encontramos valores de las siguientes longitudes: {1, 5, 6, 7, 8, 9, 10}\n",
      "Los valores de un sólo caracter son: ['0', '0']\n",
      "\n",
      "En la colimna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {5, 6, 7, 8, 9, 10}\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si los valores de la columna 'sucursal_id2' diferentes de '0' hacen referencia a un valor en de 'id' en el Dataframe 'sucursal'\n",
    "\n",
    "# Revisamos sus posibles longitudes\n",
    "suc_id2_lengths = set()\n",
    "\n",
    "suc_id2_1car = []\n",
    "\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].sucursal_id2.unique():\n",
    "        suc_id2_lengths.add(len(y))\n",
    "        if len(y) == 1:\n",
    "            suc_id2_1car.append(y)\n",
    "\n",
    "print(f\"En la columna 'sucursal_id2' de las tablas 'precio' encontramos valores de las siguientes longitudes: {suc_id2_lengths}\")\n",
    "print(f'Los valores de un sólo caracter son: {suc_id2_1car}')\n",
    "print(f\"\\nEn la colimna 'id' de la tabla 'sucursal' encontramos valores de las siguientes longitudes: {sid_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los únicos valores de un solo caracter son los '0', las longitudes se corresponden. Pasamos a revisar si los valores de cada columna 'sucursal_id2' se encuentran en la columna 'id' del DataFrame 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2333\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista (sid) con los valores de la columna 'id' de la tabla sucursal\n",
    "sid = []\n",
    "for x in dims['sucursal'].id.unique():\n",
    "    sid.append(x)\n",
    "print(len(sid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• DataFrame 2020-04-26:\n",
      "\tFound problems: False (0)\n",
      "• DataFrame 2020-04-19:\n",
      "\tFound problems: True (39)\n",
      "• DataFrame 2020-04-13:\n",
      "\tFound problems: True (6)\n",
      "• DataFrame 2020-05-03:\n",
      "\tFound problems: True (7)\n",
      "• DataFrame 2020-05-18:\n",
      "\tFound problems: True (4)\n"
     ]
    }
   ],
   "source": [
    "# El siguiente código revisa, para todas los DataFrames de precios, si los valores de 'sucursal_id2' se encuentran en la lista 'sid' recién creada.\n",
    "\n",
    "sid_checklist = {}\n",
    "sid_problems_found = {}\n",
    "for x in ps_2020:\n",
    "    len_x = ps_2020[x].shape[0]\n",
    "    sid_checklist[x] = False\n",
    "    sid_problems_found[x] = []\n",
    "    for y in ps_2020[x].sucursal_id2.unique():\n",
    "        if (y != '0'):\n",
    "            if y not in sid:\n",
    "                sid_checklist[x] = True\n",
    "                sid_problems_found[x].append(y)\n",
    "                #print(f'Problem found: (df:{x}) (pos:{count}) (value:{y}) (dtype:{type(y)})')\n",
    "\n",
    "for x in sid_checklist:\n",
    "    print(f\"• DataFrame {x}:\\n\\tFound problems: {sid_checklist[x]} ({len(sid_problems_found[x])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores problemáticos de 'sucursal_id' por DataFrame:\n",
      "\n",
      "• DataFrame 2020-04-26:\n",
      "[]\n",
      "\n",
      "• DataFrame 2020-04-19:\n",
      "['10-1-2029', '9-2-1939', '25-1-2001', '13-1-1939', '13-1-1962', '6-1-2009', '6-2-2021', '10-1-2006', '10-1-2018', '18-1-2005', '5-1-2003', '7-1-1937', '7-1-1948', '10-1-1946', '10-1-2026', '10-1-1933', '10-1-1948', '10-1-1953', '10-1-1954', '10-1-1944', '13-1-1952', '14-1-2009', '6-1-2004', '6-2-2002', '10-1-1955', '9-2-1950', '6-1-2026', '20-1-2001', '17-1-263', '29-1-2007', '17-1-285', '22-1-2017', '3-1-1962', '7-1-1935', '12-1-1999', '29-1-2005', '17-1-101', '12-1-1940', '65-1-315']\n",
      "\n",
      "• DataFrame 2020-04-13:\n",
      "['20-1-4', '17-1-254', '17-1-46', '17-1-252', '17-1-198', '17-1-178']\n",
      "\n",
      "• DataFrame 2020-05-03:\n",
      "['17-1-7', '22-1-11', '65-1-317', '19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977']\n",
      "\n",
      "• DataFrame 2020-05-18:\n",
      "['1-1-12', '17-1-165', '17-1-122', '22-1-23']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValores problemáticos de 'sucursal_id' por DataFrame:\")\n",
    "for x in sid_problems_found:\n",
    "    print(f'\\n• DataFrame {x}:\\n{sid_problems_found[x]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de productos a remplazar en los 5 DataFrames es de 124709, de un total de 2218207 (5.62%).\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cuántas apariciones tienen los valores problemáticos las columnas 'sucursal_id' en los DataFrames de 'precios'\n",
    "sid_a_remplazar = []\n",
    "for x in sid_problems_found:\n",
    "    for y in sid_problems_found[x]:\n",
    "        sid_a_remplazar.append(y)\n",
    "sid_ar_count = 0\n",
    "for x in ps_2020:\n",
    "    for y in ps_2020[x].sucursal_id2:\n",
    "        if y in sid_a_remplazar:\n",
    "            sid_ar_count += 1\n",
    "print(f'El total de productos a remplazar en los {len(ps_2020.keys())} DataFrames es de {sid_ar_count}, de un total de {tot_reg} ({round(100*(sid_ar_count/tot_reg),2)}%).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos una cantidad importante de registros problemáticos buscaremos si algunos de los códigos tienen un problema de formato, en específico, si al último de los 3 números separados por guiones le hace falta uno o dos '0' al comienzo, como anteriormente habíamos visto que estaban algunos de los códigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\n",
      "\n",
      "5: ['9-2-1', '3-1-3', '8-1-7', '6-1-7', '6-1-9']\n",
      "6: ['44-1-1', '13-1-2', '13-1-5', '7-1-14', '6-1-12']\n",
      "7: ['2-1-266', '2-2-235', '13-1-97', '15-1-92', '13-1-58']\n",
      "8: ['10-3-419', '10-3-616', '15-1-511', '10-3-481', '10-3-307']\n",
      "9: ['11-2-1039', '11-5-1005', '23-1-6278', '15-1-1525', '15-1-1506']\n",
      "10: ['19-1-03228', '19-1-01317', '19-1-01641', '19-1-02626', '19-1-02697']\n",
      "\n",
      "Clasificación de los valores de 'sucursal_id' a remplazar (sidar) (longitud: valores):\n",
      "\n",
      "6: ['20-1-4', '17-1-7', '1-1-12']\n",
      "7: ['17-1-46', '22-1-11', '22-1-23']\n",
      "8: ['9-2-1939', '6-1-2009', '6-2-2021', '5-1-2003', '7-1-1937', '7-1-1948', '6-1-2004', '6-2-2002', '9-2-1950', '6-1-2026', '17-1-263', '17-1-285', '3-1-1962', '7-1-1935', '17-1-101', '65-1-315', '17-1-254', '17-1-252', '17-1-198', '17-1-178', '65-1-317', '17-1-165', '17-1-122']\n",
      "9: ['10-1-2029', '25-1-2001', '13-1-1939', '13-1-1962', '10-1-2006', '10-1-2018', '18-1-2005', '10-1-1946', '10-1-2026', '10-1-1933', '10-1-1948', '10-1-1953', '10-1-1954', '10-1-1944', '13-1-1952', '14-1-2009', '10-1-1955', '20-1-2001', '29-1-2007', '22-1-2017', '12-1-1999', '29-1-2005', '12-1-1940']\n",
      "10: ['19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977']\n"
     ]
    }
   ],
   "source": [
    "# Recordemos los códigos de sucursal_id problemáticos junto los ejemplos de valores de diferentes longitudes en la columna 'id' de sucursal\n",
    "sidar_lengths = set()\n",
    "for x in sid_a_remplazar:\n",
    "    sidar_lengths.add(len(x))\n",
    "\n",
    "sidar_lengths_examples = {}\n",
    "for x in sidar_lengths:\n",
    "    sidar_lengths_examples[str(x)] = []\n",
    "for x in sid_a_remplazar:\n",
    "    len_x = str(len(x))\n",
    "    sidar_lengths_examples[len_x].append(x)\n",
    "\n",
    "print(\"\\nAlgunos ejemplos de los valores en la columna 'id' de la tabla 'sucursal' con diferentes longitudes  (longitud: ejemplos):\\n\")\n",
    "for x in sid_lengths_examples:\n",
    "    print(f'{x}: {sample(sid_lengths_examples[x],5)}')\n",
    "\n",
    "print(\"\\nClasificación de los valores de 'sucursal_id' a remplazar (sidar) (longitud: valores):\\n\")\n",
    "for x in sidar_lengths_examples:\n",
    "    print(f'{x}: {sidar_lengths_examples[x]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregaremos a los valores de 'sid_a_remplazar' que tengan 9 dígitos un 0 a la izquierda del tercer número para ver si de esta manera aparecen en la columna 'id' de la tabla 'sucursal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-1-02029', '9-2-1939', '25-1-02001', '13-1-01939', '13-1-01962', '6-1-2009', '6-2-2021', '10-1-02006', '10-1-02018', '18-1-02005', '5-1-2003', '7-1-1937', '7-1-1948', '10-1-01946', '10-1-02026', '10-1-01933', '10-1-01948', '10-1-01953', '10-1-01954', '10-1-01944', '13-1-01952', '14-1-02009', '6-1-2004', '6-2-2002', '10-1-01955', '9-2-1950', '6-1-2026', '20-1-02001', '17-1-263', '29-1-02007', '17-1-285', '22-1-02017', '3-1-1962', '7-1-1935', '12-1-01999', '29-1-02005', '17-1-101', '12-1-01940', '65-1-315', '20-1-4', '17-1-254', '17-1-46', '17-1-252', '17-1-198', '17-1-178', '17-1-7', '22-1-11', '65-1-317', '19-1-01201', '19-1-02903', '19-1-03235', '19-1-30977', '1-1-12', '17-1-165', '17-1-122', '22-1-23']\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# Creamos la nueva lista de códigos\n",
    "sidar_new = []\n",
    "for x in sid_a_remplazar:\n",
    "    if len(x) == 9:\n",
    "        split_sidar = x.split('-')\n",
    "        new_sid = split_sidar[0]+'-'+split_sidar[1]+'-0'+split_sidar[2]\n",
    "        sidar_new.append(new_sid)\n",
    "    else:\n",
    "        sidar_new.append(x)\n",
    "print(sidar_new)\n",
    "print(len(sidar_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8, 10, 6, 7}\n"
     ]
    }
   ],
   "source": [
    "# Corroboramos las longitudes de los nuevos códigos (ya no debe haber códigos de 9 caracteres)\n",
    "sidar_new_lengths = set()\n",
    "for x in sidar_new:\n",
    "    sidar_new_lengths.add(len(x))\n",
    "print(sidar_new_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un total de 0 de los nuevos códigos nos sirven para hacer referencia a algún valor de la columna 'id' de la tabla 'sucursal'\n"
     ]
    }
   ],
   "source": [
    "# Revisamos cuántos de los nuevos códigos se encuentran en la columna 'id' de la tabla 'sucursal'\n",
    "good_new_sidar = 0\n",
    "for x in sidar_new:\n",
    "    if x in dims['sucursal'].id.unique():\n",
    "        good_new_sidar += 1\n",
    "print(f\"Un total de {good_new_sidar} de los nuevos códigos nos sirven para hacer referencia a algún valor de la columna 'id' de la tabla 'sucursal'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación de los códigos no nos sirvió para hacer las referencias a la tabla 'sucursal'.\n",
    "\n",
    "Optaremos por notificar de esta situación al cliente y transformar los valores problemáticos de las columnas 'sucursal_id2' a '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función para llevar a cabo la transformación\n",
    "def suc_id_problem_2_zero(registro):\n",
    "    if registro in sid_a_remplazar:\n",
    "        return '0'\n",
    "    else:\n",
    "        return registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ps_2020:\n",
    "    ps_2020[x]['sucursal_id_ok'] = ps_2020[x]['sucursal_id2'].apply(suc_id_problem_2_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora limpiaremos un poco las tablas *dimensión*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "      <th>categoria1</th>\n",
       "      <th>categoria2</th>\n",
       "      <th>categoria3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72023</th>\n",
       "      <td>9006234000107</td>\n",
       "      <td>SPEED</td>\n",
       "      <td>Bebida Energizante Speed Unlimited 250 Ml</td>\n",
       "      <td>250.0 ml</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72024</th>\n",
       "      <td>9006234000114</td>\n",
       "      <td>SPEED</td>\n",
       "      <td>Bebida Energizante Speed Unlimited Pack 4 Un 1 Lt</td>\n",
       "      <td>1.0 lt</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72025</th>\n",
       "      <td>9012200001245</td>\n",
       "      <td>MILKA</td>\n",
       "      <td>Chocolate Milka Noisette 300 Gr</td>\n",
       "      <td>300.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72026</th>\n",
       "      <td>9012200872739</td>\n",
       "      <td>MILKA</td>\n",
       "      <td>Chocolate Milka Choco swing 300 Gr</td>\n",
       "      <td>300.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72027</th>\n",
       "      <td>9044400841000</td>\n",
       "      <td>PEZ</td>\n",
       "      <td>Pastillero Lheritier Pez en Blister 4 Un</td>\n",
       "      <td>4.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72028</th>\n",
       "      <td>9044400841017</td>\n",
       "      <td>SIN MARCA</td>\n",
       "      <td>Pastillas Nenas Pez 25.5 Gr</td>\n",
       "      <td>25.5 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72029</th>\n",
       "      <td>9044400841024</td>\n",
       "      <td>PEZ</td>\n",
       "      <td>Pastillero y Recarga Pez Cars 1 Un</td>\n",
       "      <td>1.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72030</th>\n",
       "      <td>9312631127591</td>\n",
       "      <td>DILMAH</td>\n",
       "      <td>Te en Saquitos Variety Pack Dilmah 25 Un</td>\n",
       "      <td>25.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72031</th>\n",
       "      <td>9312631143560</td>\n",
       "      <td>DILMAH</td>\n",
       "      <td>Te en Saquitos Variety Frutal Dilmah 20 Un</td>\n",
       "      <td>20.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72032</th>\n",
       "      <td>9312631144451</td>\n",
       "      <td>DILMAH</td>\n",
       "      <td>Te Green en Saquitos Variety Pack Dilmah 20 Un</td>\n",
       "      <td>20.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72033</th>\n",
       "      <td>9569753142128</td>\n",
       "      <td>DELI-SITAS</td>\n",
       "      <td>Milhojas Cobertura de Chocolate Blanco Deli-Si...</td>\n",
       "      <td>500.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72034</th>\n",
       "      <td>9795403001143</td>\n",
       "      <td>MAYO</td>\n",
       "      <td>Mini Pizzetas Mayo 12 Un</td>\n",
       "      <td>12.0 un</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72035</th>\n",
       "      <td>9990385651922</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Negro en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72036</th>\n",
       "      <td>9990385651939</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Verde en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72037</th>\n",
       "      <td>9990385651946</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Yerba Mate Aromatizada Lata Dana 150 Gr</td>\n",
       "      <td>150.0 gr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id        marca  \\\n",
       "72023  9006234000107        SPEED   \n",
       "72024  9006234000114        SPEED   \n",
       "72025  9012200001245        MILKA   \n",
       "72026  9012200872739        MILKA   \n",
       "72027  9044400841000          PEZ   \n",
       "72028  9044400841017    SIN MARCA   \n",
       "72029  9044400841024          PEZ   \n",
       "72030  9312631127591       DILMAH   \n",
       "72031  9312631143560       DILMAH   \n",
       "72032  9312631144451       DILMAH   \n",
       "72033  9569753142128  DELI-SITAS    \n",
       "72034  9795403001143         MAYO   \n",
       "72035  9990385651922         DANA   \n",
       "72036  9990385651939         DANA   \n",
       "72037  9990385651946         DANA   \n",
       "\n",
       "                                                  nombre presentacion  \\\n",
       "72023          Bebida Energizante Speed Unlimited 250 Ml     250.0 ml   \n",
       "72024  Bebida Energizante Speed Unlimited Pack 4 Un 1 Lt       1.0 lt   \n",
       "72025                    Chocolate Milka Noisette 300 Gr     300.0 gr   \n",
       "72026                 Chocolate Milka Choco swing 300 Gr     300.0 gr   \n",
       "72027           Pastillero Lheritier Pez en Blister 4 Un       4.0 un   \n",
       "72028                        Pastillas Nenas Pez 25.5 Gr      25.5 gr   \n",
       "72029                 Pastillero y Recarga Pez Cars 1 Un       1.0 un   \n",
       "72030           Te en Saquitos Variety Pack Dilmah 25 Un      25.0 un   \n",
       "72031         Te en Saquitos Variety Frutal Dilmah 20 Un      20.0 un   \n",
       "72032     Te Green en Saquitos Variety Pack Dilmah 20 Un      20.0 un   \n",
       "72033  Milhojas Cobertura de Chocolate Blanco Deli-Si...     500.0 gr   \n",
       "72034                           Mini Pizzetas Mayo 12 Un      12.0 un   \n",
       "72035                 Te Negro en Hebras Lata Dana 50 Gr      50.0 gr   \n",
       "72036                 Te Verde en Hebras Lata Dana 50 Gr      50.0 gr   \n",
       "72037            Yerba Mate Aromatizada Lata Dana 150 Gr     150.0 gr   \n",
       "\n",
       "      categoria1 categoria2 categoria3  \n",
       "72023       None       None       None  \n",
       "72024       None       None       None  \n",
       "72025       None       None       None  \n",
       "72026       None       None       None  \n",
       "72027       None       None       None  \n",
       "72028       None       None       None  \n",
       "72029       None       None       None  \n",
       "72030       None       None       None  \n",
       "72031       None       None       None  \n",
       "72032       None       None       None  \n",
       "72033       None       None       None  \n",
       "72034       None       None       None  \n",
       "72035       None       None       None  \n",
       "72036       None       None       None  \n",
       "72037       None       None       None  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto'].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borraremos las columnas de categoría de la tabla 'producto' pues no tenemos información para llenarlas. \n",
    "Se trato de buscar si había sido un problema al descomprimir el archivo .parquet pero en todos los visualizadores de archivos parquet en línea utilizados para ver las columnas, éstas seguían saliendo sin datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims['producto_ok'] = dims['producto'].drop(['categoria1','categoria2','categoria3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72038 entries, 0 to 72037\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72038 non-null  object\n",
      " 1   marca         72036 non-null  object\n",
      " 2   nombre        72036 non-null  object\n",
      " 3   presentacion  72036 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dims['producto_ok'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que cada una de las columnas 'marca', 'nombre' y 'presentacion' tiene dos valores faltantes. Procedemos a llenarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72038 entries, 0 to 72037\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72038 non-null  object\n",
      " 1   marca         72038 non-null  object\n",
      " 2   nombre        72038 non-null  object\n",
      " 3   presentacion  72038 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dims['producto_ok'].marca.fillna('SIN MARCA', inplace=True)\n",
    "dims['producto_ok'].nombre.fillna('SIN NOMBRE', inplace=True)\n",
    "dims['producto_ok'].presentacion.fillna('SIN DATO', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0000000000000\n",
       "marca               SIN MARCA\n",
       "nombre             SIN NOMBRE\n",
       "presentacion         SIN DATO\n",
       "Name: 72038, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos el registro que representa el id faltante en las tablas (producto_id='0')\n",
    "pid_err_val0 = ['0000000000000', 'SIN MARCA', 'SIN NOMBRE', 'SIN DATO']\n",
    "dims['producto_ok'].loc[len(dims['producto_ok'])] = pid_err_val0\n",
    "dims['producto_ok'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>marca</th>\n",
       "      <th>nombre</th>\n",
       "      <th>presentacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72034</th>\n",
       "      <td>9795403001143</td>\n",
       "      <td>MAYO</td>\n",
       "      <td>Mini Pizzetas Mayo 12 Un</td>\n",
       "      <td>12.0 un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72035</th>\n",
       "      <td>9990385651922</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Negro en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72036</th>\n",
       "      <td>9990385651939</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Te Verde en Hebras Lata Dana 50 Gr</td>\n",
       "      <td>50.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72037</th>\n",
       "      <td>9990385651946</td>\n",
       "      <td>DANA</td>\n",
       "      <td>Yerba Mate Aromatizada Lata Dana 150 Gr</td>\n",
       "      <td>150.0 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72038</th>\n",
       "      <td>0000000000000</td>\n",
       "      <td>SIN MARCA</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      marca                                   nombre  \\\n",
       "72034  9795403001143       MAYO                 Mini Pizzetas Mayo 12 Un   \n",
       "72035  9990385651922       DANA       Te Negro en Hebras Lata Dana 50 Gr   \n",
       "72036  9990385651939       DANA       Te Verde en Hebras Lata Dana 50 Gr   \n",
       "72037  9990385651946       DANA  Yerba Mate Aromatizada Lata Dana 150 Gr   \n",
       "72038  0000000000000  SIN MARCA                               SIN NOMBRE   \n",
       "\n",
       "      presentacion  \n",
       "72034      12.0 un  \n",
       "72035      50.0 gr  \n",
       "72036      50.0 gr  \n",
       "72037     150.0 gr  \n",
       "72038     SIN DATO  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto_ok'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72039 entries, 0 to 72038\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72039 non-null  object\n",
      " 1   marca         72039 non-null  object\n",
      " 2   nombre        72039 non-null  object\n",
      " 3   presentacion  72039 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dims['producto_ok'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    72039\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['producto_ok'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya no tenemos datos faltantes en la tabla 'producto_ok' y registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comercioId</th>\n",
       "      <th>banderaId</th>\n",
       "      <th>banderaDescripcion</th>\n",
       "      <th>comercioRazonSocial</th>\n",
       "      <th>provincia</th>\n",
       "      <th>localidad</th>\n",
       "      <th>direccion</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>sucursalNombre</th>\n",
       "      <th>sucursalTipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Super MAMI</td>\n",
       "      <td>Dinosaurio S.A.</td>\n",
       "      <td>AR-X</td>\n",
       "      <td>SALSIPUEDES</td>\n",
       "      <td>E53 1011 None</td>\n",
       "      <td>-31.126667</td>\n",
       "      <td>-64.295250</td>\n",
       "      <td>Super Mami 4</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-1-1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>Bernardo De Irigoyen 2647</td>\n",
       "      <td>-34.491345</td>\n",
       "      <td>-58.589025</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-1-10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Hurlingham</td>\n",
       "      <td>Av. Vergara 1910</td>\n",
       "      <td>-34.620610</td>\n",
       "      <td>-58.633769</td>\n",
       "      <td>Villa Tesei</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-1-11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Malvinas Argentinas</td>\n",
       "      <td>Av. Arturo Illia 3770</td>\n",
       "      <td>-34.528883</td>\n",
       "      <td>-58.701631</td>\n",
       "      <td>Malvinas Argentinas</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-1-112</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-A</td>\n",
       "      <td>Salta</td>\n",
       "      <td>20 De Febrero 37</td>\n",
       "      <td>-24.789072</td>\n",
       "      <td>-65.413699</td>\n",
       "      <td>Salta</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10-1-12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Justo</td>\n",
       "      <td>Av. Don Bosco 2680</td>\n",
       "      <td>-34.664628</td>\n",
       "      <td>-58.597356</td>\n",
       "      <td>San Justo</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10-1-123</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-J</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Gral. Acha 32</td>\n",
       "      <td>-31.534016</td>\n",
       "      <td>-68.524744</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10-1-128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-U</td>\n",
       "      <td>Comodoro Rivadavia</td>\n",
       "      <td>Pellegrini 851</td>\n",
       "      <td>-45.861562</td>\n",
       "      <td>-67.479968</td>\n",
       "      <td>Comodoro Rivadavia</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10-1-136</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-R</td>\n",
       "      <td>General Roca</td>\n",
       "      <td>25 De Mayo 622</td>\n",
       "      <td>-39.030326</td>\n",
       "      <td>-67.573775</td>\n",
       "      <td>General Roca</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10-1-139</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>Olavarría</td>\n",
       "      <td>Rivadavia 2846</td>\n",
       "      <td>-36.893694</td>\n",
       "      <td>-60.321650</td>\n",
       "      <td>Olavarría</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10-1-142</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-V</td>\n",
       "      <td>Río Grande</td>\n",
       "      <td>Av. San Martín 685</td>\n",
       "      <td>-53.785009</td>\n",
       "      <td>-67.702990</td>\n",
       "      <td>Río Grande</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10-1-147</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-L</td>\n",
       "      <td>Santa Rosa</td>\n",
       "      <td>Avellaneda 151</td>\n",
       "      <td>-36.618338</td>\n",
       "      <td>-64.291249</td>\n",
       "      <td>Santa Rosa</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10-1-149</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-R</td>\n",
       "      <td>Bariloche</td>\n",
       "      <td>Moreno 909</td>\n",
       "      <td>-41.136201</td>\n",
       "      <td>-71.296792</td>\n",
       "      <td>Bariloche</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10-1-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Martín</td>\n",
       "      <td>Av. San Martín 420</td>\n",
       "      <td>-34.586322</td>\n",
       "      <td>-58.519449</td>\n",
       "      <td>San Martín</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10-1-156</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Hipermercado Carrefour</td>\n",
       "      <td>INC S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>San Nicolás</td>\n",
       "      <td>Bartolomé Mitre 264</td>\n",
       "      <td>-33.331816</td>\n",
       "      <td>-60.220188</td>\n",
       "      <td>San Nicolás</td>\n",
       "      <td>Hipermercado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  comercioId  banderaId      banderaDescripcion  \\\n",
       "0      1-1-7           1          1              Super MAMI   \n",
       "1     10-1-1          10          1  Hipermercado Carrefour   \n",
       "2    10-1-10          10          1  Hipermercado Carrefour   \n",
       "3    10-1-11          10          1  Hipermercado Carrefour   \n",
       "4   10-1-112          10          1  Hipermercado Carrefour   \n",
       "5    10-1-12          10          1  Hipermercado Carrefour   \n",
       "6   10-1-123          10          1  Hipermercado Carrefour   \n",
       "7   10-1-128          10          1  Hipermercado Carrefour   \n",
       "8   10-1-136          10          1  Hipermercado Carrefour   \n",
       "9   10-1-139          10          1  Hipermercado Carrefour   \n",
       "10  10-1-142          10          1  Hipermercado Carrefour   \n",
       "11  10-1-147          10          1  Hipermercado Carrefour   \n",
       "12  10-1-149          10          1  Hipermercado Carrefour   \n",
       "13   10-1-15          10          1  Hipermercado Carrefour   \n",
       "14  10-1-156          10          1  Hipermercado Carrefour   \n",
       "\n",
       "   comercioRazonSocial provincia            localidad  \\\n",
       "0      Dinosaurio S.A.      AR-X          SALSIPUEDES   \n",
       "1             INC S.A.      AR-B           San Isidro   \n",
       "2             INC S.A.      AR-B           Hurlingham   \n",
       "3             INC S.A.      AR-B  Malvinas Argentinas   \n",
       "4             INC S.A.      AR-A                Salta   \n",
       "5             INC S.A.      AR-B            San Justo   \n",
       "6             INC S.A.      AR-J             San Juan   \n",
       "7             INC S.A.      AR-U   Comodoro Rivadavia   \n",
       "8             INC S.A.      AR-R         General Roca   \n",
       "9             INC S.A.      AR-B            Olavarría   \n",
       "10            INC S.A.      AR-V           Río Grande   \n",
       "11            INC S.A.      AR-L           Santa Rosa   \n",
       "12            INC S.A.      AR-R            Bariloche   \n",
       "13            INC S.A.      AR-B           San Martín   \n",
       "14            INC S.A.      AR-B          San Nicolás   \n",
       "\n",
       "                    direccion        lat        lng       sucursalNombre  \\\n",
       "0               E53 1011 None -31.126667 -64.295250         Super Mami 4   \n",
       "1   Bernardo De Irigoyen 2647 -34.491345 -58.589025           San Isidro   \n",
       "2            Av. Vergara 1910 -34.620610 -58.633769          Villa Tesei   \n",
       "3       Av. Arturo Illia 3770 -34.528883 -58.701631  Malvinas Argentinas   \n",
       "4            20 De Febrero 37 -24.789072 -65.413699                Salta   \n",
       "5          Av. Don Bosco 2680 -34.664628 -58.597356            San Justo   \n",
       "6               Gral. Acha 32 -31.534016 -68.524744             San Juan   \n",
       "7              Pellegrini 851 -45.861562 -67.479968   Comodoro Rivadavia   \n",
       "8              25 De Mayo 622 -39.030326 -67.573775         General Roca   \n",
       "9              Rivadavia 2846 -36.893694 -60.321650            Olavarría   \n",
       "10         Av. San Martín 685 -53.785009 -67.702990           Río Grande   \n",
       "11             Avellaneda 151 -36.618338 -64.291249           Santa Rosa   \n",
       "12                 Moreno 909 -41.136201 -71.296792            Bariloche   \n",
       "13         Av. San Martín 420 -34.586322 -58.519449           San Martín   \n",
       "14        Bartolomé Mitre 264 -33.331816 -60.220188          San Nicolás   \n",
       "\n",
       "    sucursalTipo  \n",
       "0   Hipermercado  \n",
       "1   Hipermercado  \n",
       "2   Hipermercado  \n",
       "3   Hipermercado  \n",
       "4   Hipermercado  \n",
       "5   Hipermercado  \n",
       "6   Supermercado  \n",
       "7   Hipermercado  \n",
       "8   Supermercado  \n",
       "9   Hipermercado  \n",
       "10  Supermercado  \n",
       "11  Hipermercado  \n",
       "12  Hipermercado  \n",
       "13  Hipermercado  \n",
       "14  Hipermercado  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['sucursal'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comercioId</th>\n",
       "      <th>banderaId</th>\n",
       "      <th>banderaDescripcion</th>\n",
       "      <th>comercioRazonSocial</th>\n",
       "      <th>provincia</th>\n",
       "      <th>localidad</th>\n",
       "      <th>direccion</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>sucursalNombre</th>\n",
       "      <th>sucursalTipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>9-3-5961</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-C</td>\n",
       "      <td>CIUDAD AUTONOMA BUENOS AIRES</td>\n",
       "      <td>Avenida Santa Fe 4950</td>\n",
       "      <td>-34.5772</td>\n",
       "      <td>-58.4300</td>\n",
       "      <td>Jumbo Av. Santa Fé</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>9-3-628</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>SAN FERNANDO</td>\n",
       "      <td>Avenida Del Libertador Gral San Martin 2271</td>\n",
       "      <td>-34.4469</td>\n",
       "      <td>-58.5457</td>\n",
       "      <td>Jumbo San Fernando</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>9-3-662</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Jumbo</td>\n",
       "      <td>Jumbo Retail Argentina S.A.</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>DEL VISO</td>\n",
       "      <td>Acceso Pilar Norte 0</td>\n",
       "      <td>-34.4360</td>\n",
       "      <td>-58.8080</td>\n",
       "      <td>Jumbo Paseo del Pilar</td>\n",
       "      <td>Supermercado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>SIN DATO</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>SIN DATO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  comercioId  banderaId banderaDescripcion  \\\n",
       "2330  9-3-5961           9          3              Jumbo   \n",
       "2331   9-3-628           9          3              Jumbo   \n",
       "2332   9-3-662           9          3              Jumbo   \n",
       "2333         0           0          0           SIN DATO   \n",
       "2334         1           0          0           SIN DATO   \n",
       "\n",
       "              comercioRazonSocial provincia                     localidad  \\\n",
       "2330  Jumbo Retail Argentina S.A.      AR-C  CIUDAD AUTONOMA BUENOS AIRES   \n",
       "2331  Jumbo Retail Argentina S.A.      AR-B                  SAN FERNANDO   \n",
       "2332  Jumbo Retail Argentina S.A.      AR-B                      DEL VISO   \n",
       "2333                     SIN DATO  SIN DATO                      SIN DATO   \n",
       "2334                     SIN DATO  SIN DATO                      SIN DATO   \n",
       "\n",
       "                                        direccion      lat      lng  \\\n",
       "2330                        Avenida Santa Fe 4950 -34.5772 -58.4300   \n",
       "2331  Avenida Del Libertador Gral San Martin 2271 -34.4469 -58.5457   \n",
       "2332                         Acceso Pilar Norte 0 -34.4360 -58.8080   \n",
       "2333                                     SIN DATO   0.0000   0.0000   \n",
       "2334                                     SIN DATO   0.0000   0.0000   \n",
       "\n",
       "             sucursalNombre  sucursalTipo  \n",
       "2330     Jumbo Av. Santa Fé  Supermercado  \n",
       "2331     Jumbo San Fernando  Supermercado  \n",
       "2332  Jumbo Paseo del Pilar  Supermercado  \n",
       "2333             SIN NOMBRE      SIN DATO  \n",
       "2334             SIN NOMBRE      SIN DATO  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos los registros para que los valores faltantes y errados de la coluna 'sucursal_id' tengan una referencia\n",
    "sid_err_val0 = ['0',0,0,'SIN DATO','SIN DATO','SIN DATO','SIN DATO','SIN DATO',0,0,'SIN NOMBRE','SIN DATO']\n",
    "sid_err_val1 = ['1',0,0,'SIN DATO','SIN DATO','SIN DATO','SIN DATO','SIN DATO',0,0,'SIN NOMBRE','SIN DATO']\n",
    "\n",
    "dims['sucursal'].loc[len(dims['sucursal'])] = sid_err_val0\n",
    "dims['sucursal'].loc[len(dims['sucursal'])] = sid_err_val1\n",
    "\n",
    "dims['sucursal'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2335 entries, 0 to 2334\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2335 non-null   object \n",
      " 1   comercioId           2335 non-null   int64  \n",
      " 2   banderaId            2335 non-null   int64  \n",
      " 3   banderaDescripcion   2335 non-null   object \n",
      " 4   comercioRazonSocial  2335 non-null   object \n",
      " 5   provincia            2335 non-null   object \n",
      " 6   localidad            2335 non-null   object \n",
      " 7   direccion            2335 non-null   object \n",
      " 8   lat                  2335 non-null   float64\n",
      " 9   lng                  2335 non-null   float64\n",
      " 10  sucursalNombre       2335 non-null   object \n",
      " 11  sucursalTipo         2335 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 237.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dims['sucursal'].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims['sucursal'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la tabla 'sucursal' tampoco tiene valores faltantes ni registros duplicados así que procedemos a alistar las tablas para subirlas a la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando los CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo llevado a cabo esta última transformación podemos seguir a concatenar las tablas de 'precios', crando primero una columna con la fecha de los registros para no perder la separación que tenían las tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26:\n",
      "False    474692\n",
      "dtype: int64\n",
      "2020-04-19:\n",
      "False    458543\n",
      "dtype: int64\n",
      "2020-04-13:\n",
      "False    472134\n",
      "dtype: int64\n",
      "2020-05-03:\n",
      "False    397734\n",
      "dtype: int64\n",
      "2020-05-18:\n",
      "False    415104\n",
      "dtype: int64\n",
      "(2218207, 11) Index(['precio', 'producto_id', 'sucursal_id', 'fecha', 'precio_ok',\n",
      "       'producto_id2', 'producto_id3', 'producto_id4', 'producto_id_ok',\n",
      "       'sucursal_id2', 'sucursal_id_ok'],\n",
      "      dtype='object')\n",
      "ps_2020_ok:\n",
      "False    2218207\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenamos las tablas de precios en un solo DataFrame (ps_2020_ok)\n",
    "dfs_to_concat = []\n",
    "for x in ps_2020:\n",
    "    print(f'{x}:\\n{ps_2020[x].duplicated().value_counts()}')\n",
    "    dfs_to_concat.append(ps_2020[x])\n",
    "#print(len(dfs_to_concat))\n",
    "ps_2020_ok = pd.concat(dfs_to_concat, axis=0)\n",
    "\n",
    "print(ps_2020_ok.shape, ps_2020_ok.columns)\n",
    "print(f'ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2218207, 4) Index(['fecha', 'precio_ok', 'producto_id_ok', 'sucursal_id_ok'], dtype='object')\n",
      "ps_2020_ok:\n",
      "False    2208830\n",
      "True        9377\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos las columnas que no necesitamos del DataFrame final\n",
    "ps_2020_ok.drop(['producto_id','producto_id2','producto_id3','producto_id4','sucursal_id','sucursal_id2','precio',], axis=1, inplace=True)\n",
    "print(ps_2020_ok.shape, ps_2020_ok.columns)\n",
    "print(f'Valores duplicados en ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está muy claro por qué quedan valores repetidos tras eliminar las columnas, pero al ser tan pocos con respecto al total, los eliminaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores duplicados en ps_2020_ok:\n",
      "False    2208830\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ps_2020_ok.drop_duplicates(inplace=True)\n",
    "print(f'Valores duplicados en ps_2020_ok:\\n{ps_2020_ok.duplicated().value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['precio_ok', 'producto_id_ok', 'sucursal_id_ok', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos el orden de las columnas\n",
    "cols = ['precio_ok', 'producto_id_ok', 'sucursal_id_ok', 'fecha']\n",
    "ps_2020_ok = ps_2020_ok[cols]\n",
    "print(ps_2020_ok.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['precio', 'producto_id', 'sucursal_id', 'fecha'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Renombramos las columnas\n",
    "ps_2020_ok.rename(columns = {'precio_ok':'precio','producto_id_ok':'producto_id','sucursal_id_ok':'sucursal_id'}, inplace = True)\n",
    "print(ps_2020_ok.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los DataFrames a exportar en un diccionario\n",
    "df_2_export = {'precio_semanal_2020':ps_2020_ok, 'producto': dims['producto_ok'], 'sucursal':dims['sucursal']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----precio_semanal_2020-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2208830 entries, 0 to 415292\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   fecha           datetime64[ns]\n",
      " 1   precio_ok       float64       \n",
      " 2   producto_id_ok  object        \n",
      " 3   sucursal_id_ok  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 84.3+ MB\n",
      "None\n",
      "-----producto-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72039 entries, 0 to 72038\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            72039 non-null  object\n",
      " 1   marca         72039 non-null  object\n",
      " 2   nombre        72039 non-null  object\n",
      " 3   presentacion  72039 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "-----sucursal-----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2335 entries, 0 to 2334\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   2335 non-null   object \n",
      " 1   comercioId           2335 non-null   int64  \n",
      " 2   banderaId            2335 non-null   int64  \n",
      " 3   banderaDescripcion   2335 non-null   object \n",
      " 4   comercioRazonSocial  2335 non-null   object \n",
      " 5   provincia            2335 non-null   object \n",
      " 6   localidad            2335 non-null   object \n",
      " 7   direccion            2335 non-null   object \n",
      " 8   lat                  2335 non-null   float64\n",
      " 9   lng                  2335 non-null   float64\n",
      " 10  sucursalNombre       2335 non-null   object \n",
      " 11  sucursalTipo         2335 non-null   object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 237.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la información de los DataFrames finales\n",
    "for x in df_2_export:\n",
    "    print(f'-----{x}-----')\n",
    "    print(df_2_export[x].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----DataFrame: precio_semanal_2020-----\n",
      "Shape: (2208830, 4)\n",
      "\n",
      "• Valores nulos:\n",
      "fecha             0\n",
      "precio_ok         0\n",
      "producto_id_ok    0\n",
      "sucursal_id_ok    0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2208830\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: producto-----\n",
      "Shape: (72039, 4)\n",
      "\n",
      "• Valores nulos:\n",
      "id              0\n",
      "marca           0\n",
      "nombre          0\n",
      "presentacion    0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    72039\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "-----DataFrame: sucursal-----\n",
      "Shape: (2335, 12)\n",
      "\n",
      "• Valores nulos:\n",
      "id                     0\n",
      "comercioId             0\n",
      "banderaId              0\n",
      "banderaDescripcion     0\n",
      "comercioRazonSocial    0\n",
      "provincia              0\n",
      "localidad              0\n",
      "direccion              0\n",
      "lat                    0\n",
      "lng                    0\n",
      "sucursalNombre         0\n",
      "sucursalTipo           0\n",
      "dtype: int64\n",
      "\n",
      "• Registros duplicados:\n",
      "False    2335\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos la información de los DataFrames finales\n",
    "for x in df_2_export:\n",
    "    print(f'\\n-----DataFrame: {x}-----\\nShape: {df_2_export[x].shape}\\n\\n• Valores nulos:\\n{df_2_export[x].isnull().sum()}\\n\\n• Registros duplicados:\\n{df_2_export[x].duplicated().value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:9\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(str(e))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#De mysql a data frame\n",
    "try:\n",
    "    mydb = connection.connect(host=\"localhost\", database = '',user=\"root\", passwd=\"root\",use_pure=True)\n",
    "    query = \"Select * from studentdetails;\"\n",
    "    result_dataFrame = pd.read_sql(query,mydb)\n",
    "    mydb.close() #close the connection\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
